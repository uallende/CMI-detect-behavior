{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5a8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 09:19:54.525213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757146794.721344 1934972 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757146794.781828 1934972 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757146795.422333 1934972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757146795.422399 1934972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757146795.422402 1934972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757146795.422404 1934972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-06 09:19:55.481087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow import shape, minimum\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import pad_sequences, Sequence, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate,\n",
    "    BatchNormalization, GRU, Dropout, add, Activation, Multiply, Reshape,\n",
    "    LayerNormalization, Add, Bidirectional, LSTM, UpSampling1D, Lambda, GaussianNoise, MultiHeadAttention\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler,StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from src.nn_blocks import tof_block, residual_se_cnn_block, TransformerBlock, tof_block_2, features_processing, unet_se_cnn\n",
    "\n",
    "NUM_CLASSES = 18\n",
    "\n",
    "\n",
    "# --- Gated Model 1: Based on CNN-RNN Hybrid ---\n",
    "def create_gated_cnn_rnn(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd) # Output: (None, 64, 64)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output: (None, 32, 128)\n",
    "    x1 = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(x1) # Output: (None, 32, 256)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "\n",
    "    # --- FIX: Project x2 to match x1's feature dimension before processing ---\n",
    "    x2_projected = Dense(256, activation='relu')(x2)\n",
    "\n",
    "    # Now both inputs to features_processing have shape (None, 32, 256)\n",
    "    x = features_processing(x1, x2_projected)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Gated Model 2: Based on UNet_Style ---\n",
    "def create_gated_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU branch\n",
    "    x1 = unet_se_cnn(imu, unet_depth=4, base_filters=64, kernel_size=5, drop=0.3) # Output: (None, 128, 64)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "\n",
    "    # We will use a simpler approach for this model.\n",
    "    x1_pooled = GlobalAveragePooling1D()(x1)\n",
    "    x2_pooled = GlobalAveragePooling1D()(x2)\n",
    "    x = Concatenate()([x1_pooled, x2_pooled])\n",
    "    \n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Gated Model 3: Based on CNN_Transformer ---\n",
    "def create_gated_cnn_transformer(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd) # Output: (None, 64, 64)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output: (None, 32, 128)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=128, rate=0.3)(x1) # Output: (None, 32, 128)\n",
    "    x1 = residual_se_cnn_block(x1, 64, 3, drop=0.2, wd=wd) # Output: (None, 16, 64)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output: (None, 8, 128)    \n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=128, rate=0.3)(x1) # Output: (None, 8, 128)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(4)(x2)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def best_unet_1(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def best_unet_2(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b248ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# 5 NEW ADVANCED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import match_time_steps, wave_block, res_se_cnn_decoder_block\n",
    "\n",
    "# --- Advanced Model 2: Stacked Transformer Tower ---\n",
    "def create_advanced_model_2_transformer_tower(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Strong CNN backbone to create rich features for the Transformer\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output shape: (None, 32, 128)\n",
    "    \n",
    "    # Stacked Transformer Tower\n",
    "    # Each block attends to the output of the previous one, building deeper context.\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output shape: (None, 32, 128)\n",
    "\n",
    "    # Merge and classify\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model 3: Hybrid UNet + WaveNet ---\n",
    "def create_advanced_model_3_unet_wave(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1_unet = unet_se_cnn(imu, unet_depth=3, base_filters=64, kernel_size=5)\n",
    "    x1_wave = wave_block(imu, 64, 3, n=5, dropout_rate=0.3) # n=5 -> dilations up to 16\n",
    "    \n",
    "    x1_unet_matched, x1_wave_matched = match_time_steps(x1_unet, x1_wave)\n",
    "    x1 = Concatenate()([x1_unet_matched, x1_wave_matched])\n",
    "    \n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_wave_net(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = wave_block(imu, 128, 3, n=4, dropout_rate=0.3) \n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model 4: Triple Stacked Block Design ---\n",
    "def cnn_gru_block(x, filters, kernel_size, wd=1e-4):\n",
    "    # A self-contained block combining CNN and GRU\n",
    "    x_cnn = residual_se_cnn_block(x, filters, kernel_size, wd=wd)\n",
    "    x_gru = Bidirectional(GRU(filters // 2, return_sequences=True))(x_cnn)\n",
    "    return x_gru\n",
    "\n",
    "def cnn_gru_block(x, filters, kernel_size, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A simplified and robust block that first applies a CNN, then a GRU.\n",
    "    \"\"\"\n",
    "    # 1. CNN part for feature extraction and downsampling\n",
    "    x = residual_se_cnn_block(x, filters, kernel_size, wd=wd)\n",
    "    \n",
    "    # 2. GRU part for sequence processing\n",
    "    x = Bidirectional(GRU(filters, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_advanced_model_4_stacked_blocks(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Apply the hybrid block three times\n",
    "    x1 = cnn_gru_block(imu, 64, 3)  # Output: (None, 64, 128)\n",
    "    x1 = cnn_gru_block(x1, 128, 5) # Output: (None, 32, 256)\n",
    "    \n",
    "    # The final block will not return sequences to simplify the final merge\n",
    "    x1 = Bidirectional(GRU(128, return_sequences=False))(x1) # Output: (None, 256)\n",
    "    \n",
    "    # Standard ToF branch, but we need to aggregate it to match x1\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "    x2 = GlobalAveragePooling1D()(x2) # Output: (None, 128)\n",
    "\n",
    "    # Merge the two aggregated feature vectors\n",
    "    x = Concatenate()([x1, x2]) # Output: (None, 256 + 128) = (None, 384)\n",
    "    \n",
    "    # Final classifier MLP\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model 5: UNet with BiLSTM Bottleneck ---\n",
    "def unet_se_cnn_bilstm(x, unet_depth=3, base_filters=64, kernel_size=3, drop=0.3):\n",
    "    filters = base_filters\n",
    "    skips = []\n",
    "    for _ in range(unet_depth):\n",
    "        x = residual_se_cnn_block(x, filters, kernel_size, drop=drop)\n",
    "        skips.append(x)\n",
    "        filters *= 2\n",
    "    \n",
    "    # --- BiLSTM Bottleneck ---\n",
    "    # Process the most compressed representation sequentially\n",
    "    x = Bidirectional(LSTM(filters // 2, return_sequences=True))(x)\n",
    "    \n",
    "    for skip in reversed(skips):\n",
    "        filters //= 2\n",
    "        x = res_se_cnn_decoder_block(x, filters, kernel_size, drop=drop, skip_connection=skip)\n",
    "    return x\n",
    "\n",
    "def create_advanced_model_1_deep_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branches ---\n",
    "    x1_unet = unet_se_cnn(imu, unet_depth=4, base_filters=128, kernel_size=5, drop=0.3)\n",
    "    x1_conv_k3 = residual_se_cnn_block(imu, 64, 3)\n",
    "    x1_conv_k7 = residual_se_cnn_block(imu, 64, 7)\n",
    "    \n",
    "    # --- FIX: Aggregate each branch BEFORE merging ---\n",
    "    # This creates a fixed-size vector from each branch, avoiding shape conflicts.\n",
    "    p1 = GlobalAveragePooling1D()(x1_unet)\n",
    "    p2 = GlobalAveragePooling1D()(x1_conv_k3)\n",
    "    p3 = GlobalAveragePooling1D()(x1_conv_k7)\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "    p4 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "    # Concatenate the aggregated feature vectors\n",
    "    x = Concatenate()([p1, p2, p3, p4])\n",
    "    \n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_advanced_model_5_unet_bilstm(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Use the UNet with the BiLSTM bottleneck\n",
    "    x1 = unet_se_cnn_bilstm(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # --- FIX: Use the robust aggregation strategy instead of features_processing ---\n",
    "    x1_pooled = GlobalAveragePooling1D()(x1)\n",
    "    x2_pooled = GlobalAveragePooling1D()(x2)\n",
    "    x = Concatenate()([x1_pooled, x2_pooled])\n",
    "\n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699bc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# 3 NEW ADVANCED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "from src.nn_blocks import attention_layer\n",
    "\n",
    "def create_advanced_model_A_dual_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Branch 1: A deep U-Net for the IMU data\n",
    "    x1_raw = unet_se_cnn(imu, unet_depth=4, base_filters=128, kernel_size=5, drop=0.3)\n",
    "    \n",
    "    # Branch 2: A parallel, slightly lighter U-Net for the ToF/Thermal data\n",
    "    x2_raw = unet_se_cnn(tof, unet_depth=3, base_filters=64, kernel_size=5, drop=0.3)\n",
    "\n",
    "    # --- FIX: Project both branches to a common feature dimension (e.g., 128) ---\n",
    "    # This ensures the input to features_processing is consistent.\n",
    "    x1 = Conv1D(128, 1, padding='same', activation='relu', name='imu_projection')(x1_raw)\n",
    "    x2 = Conv1D(128, 1, padding='same', activation='relu', name='tof_projection')(x2_raw)\n",
    "    \n",
    "    # Now both x1 and x2 have shape (None, 128, 128)\n",
    "    # They can be safely passed to the features_processing block.\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model B: Cross-Attention Fusion ---\n",
    "# Hypothesis: Instead of just concatenating the IMU and ToF branches, we can create\n",
    "# richer features by allowing them to \"talk to each other.\" The IMU branch will learn\n",
    "# what to pay attention to in the ToF data, and vice-versa.\n",
    "def create_advanced_model_B_cross_attention(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # 1. Create strong, downsampled feature representations for both branches\n",
    "    # Output Shape for both: (None, 32, 128)\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd)\n",
    "    \n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # 2. Cross-Attention Fusion\n",
    "    # The IMU branch queries the ToF branch for relevant context\n",
    "    imu_attends_tof = tf.keras.layers.Attention()([x1, x2])\n",
    "    # The ToF branch queries the IMU branch for relevant context\n",
    "    tof_attends_imu = tf.keras.layers.Attention()([x2, x1])\n",
    "    \n",
    "    # 3. Create an enriched representation by concatenating all perspectives\n",
    "    # The final tensor contains the original features plus the context-aware features.\n",
    "    # Shape: (None, 32, 128 + 128 + 128 + 128) = (None, 32, 512)\n",
    "    x = Concatenate()([x1, imu_attends_tof, x2, tof_attends_imu])\n",
    "    \n",
    "    # 4. Final Processing\n",
    "    # We use a powerful sequence processor on this ultra-rich tensor\n",
    "    x = Bidirectional(GRU(256, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    x = attention_layer(x)\n",
    "    \n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model C: Stacked Hybrid Blocks ---\n",
    "# Hypothesis: A single block of (CNN -> RNN) is good. Repeatedly stacking this\n",
    "# hybrid block will allow the model to learn progressively more abstract and\n",
    "\n",
    "# powerful spatio-temporal features.\n",
    "def cnn_lstm_block(x, filters, kernel_size, drop=0.2, wd=1e-4):\n",
    "    # A self-contained, reusable block\n",
    "    x = residual_se_cnn_block(x, filters, kernel_size, drop=drop, wd=wd)\n",
    "    x = Bidirectional(LSTM(filters, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    return x\n",
    "\n",
    "def create_advanced_model_C_stacked_hybrid(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Stacked Hybrid Blocks ---\n",
    "    # Each block refines the output of the previous one\n",
    "    # Input: (128, D) -> Block1: (64, 128) -> Block2: (32, 256)\n",
    "    x1 = cnn_lstm_block(imu, 64, 3)\n",
    "    x1 = cnn_lstm_block(x1, 128, 5)\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    # Output: (32, 128)\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "    # Project ToF features to match the final IMU feature dimension (256)\n",
    "    x2_projected = Dense(256, activation='relu')(x2)\n",
    "\n",
    "    # Now both inputs have shape (None, 32, 256) and can be processed\n",
    "    x = features_processing(x1, x2_projected)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66767de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# 3 NEW ADVANCED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "\n",
    "# --- Advanced Model A: BERT-Fusion (Keras Implementation) ---\n",
    "# Hypothesis: Using a Transformer (BERT) as a late-stage fusion layer for features\n",
    "# from three separate, specialized branches will create the most powerful representation.\n",
    "# This is a direct translation of the PyTorch model's core idea.\n",
    "def create_advanced_model_A_bert_fusion(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof_and_thm = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "    \n",
    "    # We need to split ToF and Thermal for separate processing\n",
    "    # Assuming thm_cols are the first 5 in the tof_and_thm tensor\n",
    "    thm = tf.keras.layers.Lambda(lambda t: t[:, :, :5])(tof_and_thm)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, 5:])(tof_and_thm)\n",
    "\n",
    "    # 1. Create three separate feature extraction branches\n",
    "    # IMU Branch\n",
    "    x_imu = residual_se_cnn_block(imu, 128, 3)\n",
    "    x_imu = residual_se_cnn_block(x_imu, 256, 5) # Shape: (None, 32, 256)\n",
    "    \n",
    "    # Thermal Branch\n",
    "    x_thm = residual_se_cnn_block(thm, 64, 3)\n",
    "    x_thm = residual_se_cnn_block(x_thm, 128, 5)\n",
    "    x_thm = Conv1D(256, 1, padding='same', activation='relu')(x_thm) # Project to 256 features\n",
    "    \n",
    "    # ToF Branch\n",
    "    x_tof = residual_se_cnn_block(tof, 128, 3)\n",
    "    x_tof = residual_se_cnn_block(x_tof, 256, 5) # Shape: (None, 32, 256)\n",
    "    \n",
    "    # 2. Concatenate along the feature axis and feed into a Transformer\n",
    "    # Shape: (None, 32, 256+256+256) -> (None, 32, 768)\n",
    "    x = Concatenate()([x_imu, x_thm, x_tof])\n",
    "    \n",
    "    # Transformer (BERT-like) layers for deep fusion\n",
    "    x = TransformerBlock(embed_dim=768, num_heads=8, ff_dim=1024, rate=0.2)(x)\n",
    "    x = TransformerBlock(embed_dim=768, num_heads=8, ff_dim=1024, rate=0.2)(x)\n",
    "    \n",
    "    # 3. Use Global Pooling to aggregate the time dimension\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # 4. Final Classifier MLP\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model B: Hyper-UNet ---\n",
    "# Hypothesis: Since U-Nets are the top performers, an even deeper and wider U-Net\n",
    "# with more filters and a deeper encoder/decoder structure will capture more complex features.\n",
    "def create_advanced_model_B_hyper_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Branch 1: A very deep and wide U-Net for IMU data\n",
    "    # unet_depth=5 creates a very deep model, base_filters=128 makes it wide.\n",
    "    x1 = unet_se_cnn(imu, unet_depth=5, base_filters=128, kernel_size=5, drop=0.3)\n",
    "    \n",
    "    # Branch 2: A standard ToF block\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # Project both branches to a common, large feature dimension before merging\n",
    "    x1_proj = Conv1D(128, 1, padding='same', activation='relu')(x1)\n",
    "    x2_proj = Conv1D(128, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    # Use the standard features_processing block to merge and classify\n",
    "    x = features_processing(x1_proj, x2_proj)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model C: Parallel UNet-Transformer Hybrid ---\n",
    "# Hypothesis: The IMU signal contains both local patterns (best for U-Net) and global\n",
    "# context (best for Transformer). Processing the IMU with both backbones in parallel\n",
    "# and fusing their outputs will create the ultimate feature representation.\n",
    "def create_advanced_model_C_parallel_hybrid(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch is now two parallel streams ---\n",
    "    \n",
    "    # Stream 1: U-Net for multi-resolution analysis\n",
    "    imu_unet = unet_se_cnn(imu, unet_depth=4, base_filters=128, kernel_size=5)\n",
    "    \n",
    "    # Stream 2: CNN -> Transformer Tower for global context\n",
    "    imu_cnn = residual_se_cnn_block(imu, 64, 3)\n",
    "    imu_cnn = residual_se_cnn_block(imu_cnn, 128, 5) # Shape: (None, 32, 128)\n",
    "    imu_transformer = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256)(imu_cnn)\n",
    "    \n",
    "    # --- Fusion of IMU streams ---\n",
    "    imu_unet_matched, imu_transformer_matched = match_time_steps(imu_unet, imu_transformer)\n",
    "    x1 = Concatenate()([imu_unet_matched, imu_transformer_matched]) # Shape: (None, 32, 256)\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    x2 = tof_block_2(tof, wd) # Shape: (None, 32, 128)\n",
    "\n",
    "    # --- FIX: Project both branches to a common, predictable feature dimension ---\n",
    "    # Let's project both to 256 features, so the merged result is 512.\n",
    "    x1_proj = Conv1D(256, 1, padding='same', activation='relu', name='imu_projection')(x1)\n",
    "    x2_proj = Conv1D(256, 1, padding='same', activation='relu', name='tof_projection')(x2)\n",
    "    \n",
    "    # Now both x1_proj and x2_proj have shape (None, 32, 256)\n",
    "    x = features_processing(x1_proj, x2_proj)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5307904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polars as pl\n",
    "# df = pl.read_parquet('output/imu_physics_feats.parquet')\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60244006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Layer, Sequential\n",
    "\n",
    "def ImuFeatureExtractorLayer(imu_input):\n",
    "    \"\"\"A Keras layer to perform on-the-fly feature engineering.\"\"\"\n",
    "    acc = imu_input[:, :, :3]  # Assuming raw acc_x, y, z are the first 3 features\n",
    "    gyro = imu_input[:, :, 3:6] # Assuming raw rot_w,x,y,z -> angular velocity are next\n",
    "    \n",
    "    acc_mag = tf.norm(acc, axis=-1, keepdims=True)\n",
    "    gyro_mag = tf.norm(gyro, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Jerk (diff) requires padding to maintain time dimension\n",
    "    jerk = tf.pad(acc[:, 1:, :] - acc[:, :-1, :], [[0, 0], [1, 0], [0, 0]])\n",
    "    \n",
    "    # Squared values\n",
    "    acc_pow = tf.square(acc)\n",
    "    \n",
    "    # Concatenate all derived features\n",
    "    return Concatenate()([acc, gyro, acc_mag, gyro_mag, jerk, acc_pow])\n",
    "\n",
    "def create_new_model_1_in_model_fe(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    # IMPORTANT: This model expects the RAW acc/rot features, not the engineered ones.\n",
    "    # You will need to adjust your data pipeline to feed the raw features.\n",
    "    imu_raw = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # 1. On-the-fly feature engineering branch\n",
    "    x1 = ImuFeatureExtractorLayer(imu_raw)\n",
    "    \n",
    "    # 2. Standard CNN backbone to process these rich features\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5)\n",
    "    x1 = residual_se_cnn_block(x1, 256, 7)\n",
    "    \n",
    "    # 3. Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # 4. Merge and classify\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# =====================================================================================\n",
    "# 3 NEW ADVANCED PANNs-BASED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "\n",
    "def create_panns_model_A_rnn_head(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Parallel CNNs (PANNs Backbone) ---\n",
    "    # Each branch downsamples time to 32 and outputs 128 features\n",
    "    k3 = residual_se_cnn_block(imu, 128, 3)\n",
    "    k5 = residual_se_cnn_block(imu, 128, 5)\n",
    "    k7 = residual_se_cnn_block(imu, 128, 7)\n",
    "    \n",
    "    # Concatenate the multi-scale features\n",
    "    # Shape: (None, 32, 128 + 128 + 128) = (None, 32, 384)\n",
    "    x1 = Concatenate()([k3, k5, k7])\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    x2 = tof_block(tof, wd) # Shape: (None, 32, 128)\n",
    "\n",
    "    # --- Merge and Process with RNN Head ---\n",
    "    # Project ToF features to match the IMU feature dimension for a cleaner merge\n",
    "    x2_proj = Conv1D(384, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    # Concatenate the full feature set\n",
    "    x = Concatenate()([x1, x2_proj]) # Shape: (None, 32, 384 + 384) = (None, 32, 768)\n",
    "    \n",
    "    # Add a powerful RNN head to learn sequential patterns from the rich features\n",
    "    x = Bidirectional(GRU(384, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    x = attention_layer(x) # Use attention to summarize the sequence\n",
    "    \n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def pann_rnn_head_feat_processing(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Parallel CNNs (PANNs Backbone) ---\n",
    "    # Each branch downsamples time to 32 and outputs 128 features\n",
    "    k3 = residual_se_cnn_block(imu, 128, 3)\n",
    "    k5 = residual_se_cnn_block(imu, 128, 5)\n",
    "    k7 = residual_se_cnn_block(imu, 128, 7)\n",
    "    \n",
    "    # Shape: (None, 32, 128 + 128 + 128) = (None, 32, 384)\n",
    "    x1 = Concatenate()([k3, k5, k7])\n",
    "    x2 = tof_block(tof, wd) # Shape: (None, 32, 128)\n",
    "    x2_proj = Conv1D(384, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    x = features_processing(x1, x2_proj)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c7967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def ImuFeatureExtractorLayer(imu_input, sampling_rate_hz=200):\n",
    "    acc = imu_input[:, :, :3]  # acc_x, acc_y, acc_z\n",
    "    rot = imu_input[:, :, 3:]  # rot_w, rot_x, rot_y, rot_z\n",
    "    \n",
    "    def _calculate_angular_velocity_tf(quats):\n",
    "        # This function will run in eager mode\n",
    "        num_sequences = quats.shape[0]\n",
    "        seq_len = quats.shape[1]\n",
    "        angular_vel = np.zeros((num_sequences, seq_len, 3), dtype=np.float32)\n",
    "        dt = 1.0 / sampling_rate_hz\n",
    "        for i in range(num_sequences):\n",
    "            q_seq = R.from_quat(quats[i, :, [1, 2, 3, 0]]) # Scipy expects (x,y,z,w)\n",
    "            vel = np.diff(quats[i, :, :3], axis=0, prepend=quats[i, :1, :3]) / dt\n",
    "            angular_vel[i, :, :] = vel\n",
    "        return angular_vel\n",
    "\n",
    "    gyro = tf.keras.layers.Lambda(\n",
    "        lambda t: tf.py_function(func=_calculate_angular_velocity_tf, inp=[t], Tout=tf.float32)\n",
    "    )(rot)\n",
    "    \n",
    "    # --- On-the-fly Feature Creation (wrapped in Lambda layers) ---\n",
    "    acc_mag = tf.keras.layers.Lambda(lambda t: tf.norm(t, axis=-1, keepdims=True), name='acc_mag')(acc)\n",
    "    gyro_mag = tf.keras.layers.Lambda(lambda t: tf.norm(t, axis=-1, keepdims=True), name='gyro_mag')(gyro)\n",
    "    jerk = tf.keras.layers.Lambda(\n",
    "        lambda t: tf.pad(t[:, 1:, :] - t[:, :-1, :], [[0, 0], [1, 0], [0, 0]]), name='jerk'\n",
    "    )(acc)\n",
    "    acc_pow = tf.keras.layers.Lambda(tf.square, name='acc_pow')(acc)\n",
    "    \n",
    "    # Concatenate all the resulting KerasTensors\n",
    "    return Concatenate()([acc, gyro, acc_mag, gyro_mag, jerk, acc_pow])\n",
    "\n",
    "def create_stacked_fe_unet(input_shape, raw_imu_dim, engineered_imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    imu_raw = tf.keras.layers.Lambda(lambda t: t[:, :, :raw_imu_dim])(inp)\n",
    "    imu_engineered = tf.keras.layers.Lambda(lambda t: t[:, :, raw_imu_dim : raw_imu_dim + engineered_imu_dim])(inp)\n",
    "    tof_engineered = tf.keras.layers.Lambda(lambda t: t[:, :, raw_imu_dim + engineered_imu_dim :])(inp)\n",
    "\n",
    "\n",
    "    imu_on_the_fly_feats = ImuFeatureExtractorLayer(imu_raw)\n",
    "    imu_on_the_fly_matched, imu_engineered_matched = match_time_steps(imu_on_the_fly_feats, imu_engineered)\n",
    "    imu_final_features = Concatenate()([imu_on_the_fly_matched, imu_engineered_matched])\n",
    "    \n",
    "    x1 = unet_se_cnn(imu_final_features, 3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block(tof_engineered, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4354537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder_block(inputs, head_size, num_heads, ff_dim, dropout=0.0, wd=1e-4):\n",
    "    \"\"\"A standard Transformer Encoder block.\"\"\"\n",
    "    # Attention and Normalization\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
    "        kernel_regularizer=l2(wd)\n",
    "    )(inputs, inputs)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(Add()([inputs, x]))\n",
    "\n",
    "    # Feed Forward Part\n",
    "    ff_outputs = Dense(ff_dim, activation=\"relu\", kernel_regularizer=l2(wd))(x)\n",
    "    ff_outputs = Dense(inputs.shape[-1], kernel_regularizer=l2(wd))(ff_outputs)\n",
    "    ff_outputs = Dropout(dropout)(ff_outputs)\n",
    "    outputs = LayerNormalization(epsilon=1e-6)(Add()([x, ff_outputs]))\n",
    "    return outputs\n",
    "\n",
    "def cross_attention_block(query, value, key_dim, num_heads, dropout=0.1, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A cross-attention block where the query is from one modality and the\n",
    "    value/key is from another.\n",
    "    \"\"\"\n",
    "    attention_output = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=key_dim, dropout=dropout,\n",
    "        kernel_regularizer=l2(wd)\n",
    "    )(query, value)\n",
    "    x = Add()([query, attention_output])\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x\n",
    "\n",
    "def wavenet_residual_block(inputs, filters, kernel_size, dilation_rate, wd=1e-4):\n",
    "    \"\"\"A WaveNet-style residual block with dilated convolutions.\"\"\"\n",
    "    shortcut = inputs\n",
    "    \n",
    "    # Gated activation unit\n",
    "    tanh_out = Conv1D(filters, kernel_size, dilation_rate=dilation_rate,\n",
    "                      padding='causal', activation='tanh', kernel_regularizer=l2(wd))(inputs)\n",
    "    sigmoid_out = Conv1D(filters, kernel_size, dilation_rate=dilation_rate,\n",
    "                         padding='causal', activation='sigmoid', kernel_regularizer=l2(wd))(inputs)\n",
    "    x = Multiply()([tanh_out, sigmoid_out])\n",
    "    \n",
    "    # Projection\n",
    "    x = Conv1D(filters, 1, padding='same', kernel_regularizer=l2(wd))(x)\n",
    "    \n",
    "    # Residual connection\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding='same', kernel_regularizer=l2(wd))(shortcut)\n",
    "        \n",
    "    return Add()([shortcut, x])\n",
    "\n",
    "\n",
    "def create_conv_transformer_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    Architecture: Two-stream CNN feature extractors followed by a Transformer head.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "\n",
    "    x1 = unet_se_cnn(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    fusion_dim = 256\n",
    "    x1_proj = Conv1D(fusion_dim, 1, padding='same', activation='relu')(x1)\n",
    "    x2_proj = Conv1D(fusion_dim, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x1_proj, x2_proj])\n",
    "    \n",
    "    x = transformer_encoder_block(x, head_size=64, num_heads=4, ff_dim=fusion_dim*2, dropout=0.2, wd=wd)\n",
    "    x = transformer_encoder_block(x, head_size=64, num_heads=4, ff_dim=fusion_dim*2, dropout=0.2, wd=wd)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_cross_fusion_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    Architecture: Parallel encoders with a cross-attention fused decoder.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    unet_depth = 3\n",
    "    base_filters = 128\n",
    "    kernel_size = 5\n",
    "\n",
    "    imu_skips, tof_skips = [], []\n",
    "    x_imu, x_tof = imu, tof\n",
    "    \n",
    "    filters = base_filters\n",
    "    for _ in range(unet_depth):\n",
    "        x_imu = residual_se_cnn_block(x_imu, filters, kernel_size, drop=0.3, wd=wd)\n",
    "        imu_skips.append(x_imu)\n",
    "        \n",
    "        # ToF encoder can be simpler\n",
    "        x_tof = residual_se_cnn_block(x_tof, filters // 2, kernel_size, drop=0.3, wd=wd)\n",
    "        tof_skips.append(x_tof)\n",
    "        \n",
    "        filters *= 2\n",
    "\n",
    "    x = residual_se_cnn_block(x_imu, filters, kernel_size, drop=0.3, wd=wd)\n",
    "\n",
    "    for i in reversed(range(unet_depth)):\n",
    "        filters //= 2\n",
    "        # Upsample\n",
    "        x = UpSampling1D(size=2)(x)\n",
    "        x = Conv1D(filters, 2, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = Add()([x, imu_skips[i]])\n",
    "        tof_context = cross_attention_block(x, tof_skips[i], key_dim=64, num_heads=4, wd=wd)\n",
    "        x = Concatenate()([x, tof_context])\n",
    "        \n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_wavenet_style_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    Architecture: Parallel WaveNet-style backbones for efficient sequence modeling.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    embed_dim = 128\n",
    "    num_blocks = 8 \n",
    "\n",
    "    x1 = Conv1D(embed_dim, 1, padding='same')(imu)\n",
    "    x2 = Conv1D(embed_dim, 1, padding='same')(tof)\n",
    "\n",
    "    # --- Parallel WaveNet Backbones ---\n",
    "    skip_connections1, skip_connections2 = [], []\n",
    "    for i in range(num_blocks):\n",
    "        dilation_rate = 2**(i % 4)\n",
    "        x1 = wavenet_residual_block(x1, embed_dim, kernel_size=3, dilation_rate=dilation_rate, wd=wd)\n",
    "        skip_connections1.append(Conv1D(embed_dim, 1, padding='same')(x1)) # Collect skip outputs\n",
    "        \n",
    "        x2 = wavenet_residual_block(x2, embed_dim, kernel_size=3, dilation_rate=dilation_rate, wd=wd)\n",
    "        skip_connections2.append(Conv1D(embed_dim, 1, padding='same')(x2))\n",
    "\n",
    "\n",
    "    x1_fused = Add()(skip_connections1)\n",
    "    x1_fused = Activation('relu')(x1_fused)\n",
    "    x2_fused = Add()(skip_connections2)\n",
    "    x2_fused = Activation('relu')(x2_fused)\n",
    "    \n",
    "    x = Concatenate()([x1_fused, x2_fused])\n",
    "    x = Conv1D(256, 1, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9a226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiscale_unet_model_definitive(input_shape, imu_dim, wd=1e-4):\n",
    "    \n",
    "    # --- Internal Helper Block (local to this function and stable) ---\n",
    "    def _conv_block(x, filters, kernel_size):\n",
    "        # A simple, standard residual block\n",
    "        shortcut = x\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        # Ensure the shortcut can be added if the number of filters changes\n",
    "        if shortcut.shape[-1] != filters:\n",
    "            shortcut = Conv1D(filters, 1, padding='same', use_bias=False, kernel_regularizer=l2(wd))(shortcut)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "        \n",
    "    # --- Model Definition Starts Here ---\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- 1. Multi-Scale IMU Backbone (Built from scratch) ---\n",
    "    filters = 128\n",
    "    skips = []\n",
    "    x = imu\n",
    "    \n",
    "    # --- Encoder ---\n",
    "    for _ in range(3): # unet_depth = 3\n",
    "        x = _conv_block(x, filters, kernel_size=3)\n",
    "        skips.append(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        filters *= 2\n",
    "    \n",
    "    # --- Bottleneck ---\n",
    "    x = _conv_block(x, filters, kernel_size=3)\n",
    "    \n",
    "    # --- Decoder ---\n",
    "    decoder_outputs = []\n",
    "    for i, skip in enumerate(reversed(skips)):\n",
    "        filters //= 2\n",
    "        x = UpSampling1D(size=2)(x)\n",
    "        \n",
    "        # Robustly handle potential off-by-one errors from pooling\n",
    "        if x.shape[1] != skip.shape[1]:\n",
    "             skip = Lambda(lambda s: s[:, :x.shape[1], :])(skip)\n",
    "\n",
    "        x = Concatenate()([x, skip])\n",
    "        x = _conv_block(x, filters, kernel_size=3)\n",
    "        if i >= 3 - 2: # Capture last 2 outputs\n",
    "            decoder_outputs.append(x)\n",
    "\n",
    "    # --- Robust Multi-Scale Combination ---\n",
    "    small_res_out = decoder_outputs[0]\n",
    "    large_res_out = decoder_outputs[1]\n",
    "    small_res_out_upsampled = UpSampling1D(size=2)(small_res_out)\n",
    "\n",
    "    common_dim = 256\n",
    "    proj_small = Conv1D(common_dim, 1, padding='same')(small_res_out_upsampled)\n",
    "    proj_large = Conv1D(common_dim, 1, padding='same')(large_res_out)\n",
    "\n",
    "    # Robustly match time steps after projection\n",
    "    if proj_small.shape[1] != proj_large.shape[1]:\n",
    "        proj_large = Lambda(lambda t: t[:, :proj_small.shape[1], :])(proj_large)\n",
    "\n",
    "    x1 = Concatenate()([proj_small, proj_large])\n",
    "\n",
    "    # --- 2. Standard ToF Backbone ---\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    # --- 3. Your Proven Fusion & RNN Head ---\n",
    "    x_final = features_processing(x1, x2, wd=wd)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x_final)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x_final)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# You will need this building block from the previous response\n",
    "def transformer_encoder_block(inputs, head_size, num_heads, ff_dim, dropout=0.0, wd=1e-4):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout, kernel_regularizer=l2(wd)\n",
    "    )(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = Add()([inputs, x])\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\", kernel_regularizer=l2(wd))(x)\n",
    "    x = Dense(inputs.shape[-1], kernel_regularizer=l2(wd))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return Add()([res, x])\n",
    "\n",
    "def create_transformer_refined_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    This model uses a Transformer stack to refine the U-Net's output before\n",
    "    passing it to your features_processing head.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- 1. Standard U-Net Backbone ---\n",
    "    unet_out = unet_se_cnn(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    \n",
    "    # --- 2. Transformer Refinement Step ---\n",
    "    # This makes the U-Net features context-aware\n",
    "    x1 = transformer_encoder_block(unet_out, head_size=128, num_heads=8, ff_dim=unet_out.shape[-1]*4, dropout=0.1, wd=wd)\n",
    "    x1 = transformer_encoder_block(x1, head_size=128, num_heads=8, ff_dim=x1.shape[-1]*4, dropout=0.1, wd=wd)\n",
    "    x1 = transformer_encoder_block(x1, head_size=128, num_heads=8, ff_dim=x1.shape[-1]*4, dropout=0.1, wd=wd)\n",
    "    x1 = transformer_encoder_block(x1, head_size=128, num_heads=8, ff_dim=x1.shape[-1]*4, dropout=0.1, wd=wd)\n",
    "\n",
    "    # --- 3. Standard ToF Backbone ---\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    # --- 4. Your Proven Fusion & RNN Head ---\n",
    "    x_final = features_processing(x1, x2, wd=wd)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x_final)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x_final)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def gated_fusion_block(x1, x2, wd=1e-4):\n",
    "    \"\"\"\n",
    "    Intelligently fuses two streams using a learned gating mechanism.\n",
    "    \"\"\"\n",
    "    # Ensure both tensors have the same feature dimension\n",
    "    dim = max(x1.shape[-1], x2.shape[-1])\n",
    "    if x1.shape[-1] != dim:\n",
    "        x1 = Dense(dim, kernel_regularizer=l2(wd))(x1)\n",
    "    if x2.shape[-1] != dim:\n",
    "        x2 = Dense(dim, kernel_regularizer=l2(wd))(x2)\n",
    "        \n",
    "    # Match time steps\n",
    "    x1_matched, x2_matched = match_time_steps(x1, x2)\n",
    "    \n",
    "    # Compute the gate from the concatenation of both inputs\n",
    "    gate_input = Concatenate()([x1_matched, x2_matched])\n",
    "    gate = Dense(dim, activation='sigmoid', kernel_regularizer=l2(wd))(gate_input)\n",
    "    \n",
    "    # Apply the gate: gate*x1 + (1-gate)*x2\n",
    "    gated_x1 = Multiply()([gate, x1_matched])\n",
    "    gated_x2 = Multiply()([Lambda(lambda t: 1.0 - t)(gate), x2_matched])\n",
    "    \n",
    "    return Add()([gated_x1, gated_x2])\n",
    "\n",
    "def create_gated_fusion_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    This model uses a gated fusion unit before passing a single, fused tensor\n",
    "    to the RNN/Attention head.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- 1. Standard Backbones ---\n",
    "    x1 = unet_se_cnn(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    # --- 2. Gated Fusion ---\n",
    "    merged = gated_fusion_block(x1, x2, wd=wd)\n",
    "    \n",
    "    # --- 3. Modified Head (no initial fusion needed) ---\n",
    "    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xc = GaussianNoise(0.09)(merged)\n",
    "    xc = Dense(16, activation='elu')(xc)\n",
    "    \n",
    "    x = Concatenate()([xa, xb, xc])\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85fbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dual_refiner_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    Applies the successful Transformer Refiner concept to BOTH the IMU and ToF streams\n",
    "    before the final fusion and RNN head.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- 1. Proven Backbones ---\n",
    "    unet_out = unet_se_cnn(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    tof_out = tof_block(tof, wd)\n",
    "\n",
    "    # --- 2. Dual Transformer Refinement Step ---\n",
    "    # Refine the IMU stream\n",
    "    x1_refined = transformer_encoder_block(unet_out, head_size=64, num_heads=4, ff_dim=unet_out.shape[-1]*4, dropout=0.1, wd=wd)\n",
    "    \n",
    "    # Refine the ToF stream\n",
    "    x2_refined = transformer_encoder_block(tof_out, head_size=32, num_heads=2, ff_dim=tof_out.shape[-1]*4, dropout=0.1, wd=wd)\n",
    "    \n",
    "    # --- 3. Your Proven Fusion & RNN Head ---\n",
    "    x_final = features_processing(x1_refined, x2_refined, wd=wd)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x_final)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x_final)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# You need to add this new building block\n",
    "def conformer_block(inputs, ff_dim, num_heads, kernel_size=3, dropout=0.1, wd=1e-4):\n",
    "    \"\"\"A single Conformer block mixing FFN, Self-Attention, and Convolution.\"\"\"\n",
    "    # Feed Forward 1\n",
    "    x = LayerNormalization()(inputs)\n",
    "    x = Dense(ff_dim, activation='swish', kernel_regularizer=l2(wd))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1], kernel_regularizer=l2(wd))(x)\n",
    "    x = Add()([inputs, x])\n",
    "\n",
    "    # Multi-Head Self-Attention\n",
    "    res = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1]//num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Add()([res, x])\n",
    "\n",
    "    # Convolution Module\n",
    "    res = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Conv1D(filters=inputs.shape[-1]*2, kernel_size=1, activation='swish')(x)\n",
    "    x = Conv1D(filters=inputs.shape[-1], kernel_size=kernel_size, padding='same', groups=inputs.shape[-1])(x) # Depthwise Conv\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Add()([res, x])\n",
    "\n",
    "    # Feed Forward 2\n",
    "    res = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dense(ff_dim, activation='swish', kernel_regularizer=l2(wd))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1], kernel_regularizer=l2(wd))(x)\n",
    "    x = Add()([res, x])\n",
    "    return x\n",
    "\n",
    "def create_conformer_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"Replaces the U-Net backbone with a stack of powerful Conformer blocks.\"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- 1. Initial Projection ---\n",
    "    # Project both streams to a common embedding dimension\n",
    "    embed_dim = 192\n",
    "    x1 = Conv1D(embed_dim, 1, padding='same')(imu)\n",
    "    x2 = Conv1D(embed_dim, 1, padding='same')(tof)\n",
    "\n",
    "    # --- 2. Conformer Backbone ---\n",
    "    # Process each stream with a stack of Conformer blocks\n",
    "    for _ in range(3): # Number of blocks is a hyperparameter\n",
    "        x1 = conformer_block(x1, ff_dim=embed_dim*4, num_heads=4, kernel_size=7)\n",
    "    \n",
    "    for _ in range(2):\n",
    "        x2 = conformer_block(x2, ff_dim=embed_dim*4, num_heads=4, kernel_size=7)\n",
    "\n",
    "    # --- 3. Your Proven Fusion & RNN Head ---\n",
    "    x_final = features_processing(x1, x2, wd=wd)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x_final)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x_final)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_hybrid_head_model(input_shape, imu_dim, wd=1e-4):\n",
    "    \"\"\"\n",
    "    An internal ensemble that processes U-Net features through two parallel paths:\n",
    "    one direct, and one refined by a Transformer.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- 1. Common Backbones ---\n",
    "    # This is the single source of truth for the initial feature extraction\n",
    "    unet_out = unet_se_cnn(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    tof_out = tof_block(tof, wd)\n",
    "\n",
    "    # --- 2. Parallel Processing Paths ---\n",
    "    # Path A: The \"Direct\" path (like Best_unet_1)\n",
    "    head_a_out = features_processing(unet_out, tof_out, wd=wd)\n",
    "    \n",
    "    # Path B: The \"Refined\" path (like transformer_refined_model)\n",
    "    unet_refined = transformer_encoder_block(unet_out, head_size=128, num_heads=8, ff_dim=unet_out.shape[-1]*4, dropout=0.1)\n",
    "    unet_refined = transformer_encoder_block(unet_refined, head_size=128, num_heads=8, ff_dim=unet_out.shape[-1]*4, dropout=0.1)\n",
    "\n",
    "    head_b_out = features_processing(unet_refined, tof_out, wd=wd)\n",
    "\n",
    "    # --- 3. Final Fusion of Heads ---\n",
    "    # Concatenate the outputs of the two parallel heads\n",
    "    x_final = Concatenate()([head_a_out, head_b_out])\n",
    "    x_final = Dense(256, activation='relu')(x_final)\n",
    "    x_final = Dropout(0.4)(x_final)\n",
    "    \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x_final)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x_final)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4ac092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting merge process...\n",
      "  Loading and joining features from: imu_basic_physics_feats.parquet\n",
      "  Loading and joining features from: tof_basic_kaggle_feats.parquet\n",
      "  Loading and joining features from: tof_features_advanced_train_polars.parquet\n",
      "  Loading and joining features from: imu_physics_feats.parquet\n",
      "  Merge complete.\n",
      "  Final merged DataFrame created with shape: (556380, 126)\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4\n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "\n",
    "from src.merge_feats_dynamic import merge_feature_sets\n",
    "from src.functions import create_sequence_dataset, generate_gate_targets, train_model\n",
    "from src.nn_blocks import GatedMixupGenerator\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "FEATURE_DIR = Path('output')\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- Step 1: Define the feature sets to merge for this experiment ---\n",
    "files_to_merge = [\n",
    "    'imu_basic_physics_feats.parquet',\n",
    "    'tof_basic_kaggle_feats.parquet',\n",
    "    'tof_features_advanced_train_polars.parquet',\n",
    "    'imu_physics_feats.parquet'\n",
    "    # 'thermal_features.parquet'\n",
    "]\n",
    "\n",
    "feature_paths = [FEATURE_DIR / f for f in files_to_merge]\n",
    "base_df = pl.read_parquet(FEATURE_DIR / \"cleaned_base_train_data.parquet\")\n",
    "demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "base_df = base_df.join(demographics_df, on='subject', how='left')\n",
    "meta_cols = ['sequence_id', 'sequence_counter', 'subject', 'gesture']\n",
    "imu_raw_cols =['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', ]\n",
    "thm_cols = ['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']\n",
    "base_df = base_df.select(meta_cols + imu_raw_cols + thm_cols)\n",
    "# base_df = base_df.select(meta_cols)\n",
    "\n",
    "le = LabelEncoder()\n",
    "gesture_encoded = le.fit_transform(base_df.get_column('gesture'))\n",
    "base_df = base_df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "final_df = merge_feature_sets(base_df, feature_paths)\n",
    "print(f\"  Final merged DataFrame created with shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fa1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class EMACallback(Callback):\n",
    "    \"\"\"\n",
    "    Callback to update and apply Exponential Moving Average of weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, decay=0.999):\n",
    "        super(EMACallback, self).__init__()\n",
    "        self.decay = decay\n",
    "        self.ema_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"Initialize EMA weights at the beginning of training.\"\"\"\n",
    "        self.ema_weights = [tf.identity(w) for w in self.model.get_weights()]\n",
    "        print(\"EMA Callback: EMA weights initialized.\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Update EMA weights after each training batch.\"\"\"\n",
    "        current_weights = self.model.get_weights()\n",
    "        for i in range(len(self.ema_weights)):\n",
    "            self.ema_weights[i] = (self.decay * self.ema_weights[i]) + ((1 - self.decay) * current_weights[i])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Optionally, you could evaluate with EMA weights at the end of each epoch,\n",
    "        but for this workflow, we'll just apply them at the end of training.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def apply_ema_weights(self):\n",
    "        \"\"\"\n",
    "        Applies the stored EMA weights to the model. This should be called\n",
    "        after training is complete and before evaluation or saving.\n",
    "        \"\"\"\n",
    "        if self.ema_weights is not None:\n",
    "            self.model.set_weights(self.ema_weights)\n",
    "            print(\"EMA Callback: EMA weights have been applied to the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting merge process...\n",
      "  Loading and joining features from: imu_basic_physics_feats.parquet\n",
      "  Loading and joining features from: tof_basic_kaggle_feats.parquet\n",
      "  Loading and joining features from: tof_features_advanced_train_polars.parquet\n",
      "  Loading and joining features from: imu_physics_feats.parquet\n",
      "  Merge complete.\n",
      "  Final merged DataFrame created with shape: (556380, 126)\n",
      "  Training with 106 total features (36 IMU, 70 ToF/Thm).\n",
      "  DataFrame columns have been reordered for the model.\n",
      "\n",
      "============================================================\n",
      " Training and Evaluating Model: hybrid_head_model\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/4 for hybrid_head_model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757146843.041968 1934972 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train: (57, 106)\n",
      "LR Scheduler: 92 steps per epoch, 13800 total decay steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA Callback: EMA weights initialized.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757146883.673650 1935193 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-09-06 09:21:27.602908: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:27.650462: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:27.674472: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:27.734464: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:27.772160: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:27.902541: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:27.979515: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:28.297795: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:28.335562: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-06 09:21:28.648823: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 598ms/step - loss: 3.9721 - main_output_accuracy: 0.1201 - main_output_loss: 2.9605 - tof_gate_loss: 0.4930 - val_loss: 3.4353 - val_main_output_accuracy: 0.2491 - val_main_output_loss: 2.4861 - val_tof_gate_loss: 0.3661\n",
      "Epoch 2/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 519ms/step - loss: 3.3554 - main_output_accuracy: 0.2555 - main_output_loss: 2.4345 - tof_gate_loss: 0.3024 - val_loss: 3.0290 - val_main_output_accuracy: 0.3072 - val_main_output_loss: 2.1886 - val_tof_gate_loss: 0.1326\n",
      "Epoch 3/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 541ms/step - loss: 3.1351 - main_output_accuracy: 0.3149 - main_output_loss: 2.2820 - tof_gate_loss: 0.2784 - val_loss: 2.6899 - val_main_output_accuracy: 0.4096 - val_main_output_loss: 1.9087 - val_tof_gate_loss: 0.1645\n",
      "Epoch 4/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 551ms/step - loss: 2.9325 - main_output_accuracy: 0.3675 - main_output_loss: 2.1470 - tof_gate_loss: 0.2442 - val_loss: 2.3506 - val_main_output_accuracy: 0.5318 - val_main_output_loss: 1.6450 - val_tof_gate_loss: 0.0715\n",
      "Epoch 5/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 542ms/step - loss: 2.7499 - main_output_accuracy: 0.4183 - main_output_loss: 2.0264 - tof_gate_loss: 0.2164 - val_loss: 2.1459 - val_main_output_accuracy: 0.5746 - val_main_output_loss: 1.4919 - val_tof_gate_loss: 0.0741\n",
      "Epoch 6/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 531ms/step - loss: 2.5476 - main_output_accuracy: 0.4669 - main_output_loss: 1.8811 - tof_gate_loss: 0.1826 - val_loss: 2.0312 - val_main_output_accuracy: 0.6032 - val_main_output_loss: 1.4253 - val_tof_gate_loss: 0.0561\n",
      "Epoch 7/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 559ms/step - loss: 2.5467 - main_output_accuracy: 0.5047 - main_output_loss: 1.9151 - tof_gate_loss: 0.2256 - val_loss: 2.0197 - val_main_output_accuracy: 0.5945 - val_main_output_loss: 1.4502 - val_tof_gate_loss: 0.0803\n",
      "Epoch 8/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 557ms/step - loss: 2.3839 - main_output_accuracy: 0.5348 - main_output_loss: 1.7948 - tof_gate_loss: 0.2098 - val_loss: 1.9101 - val_main_output_accuracy: 0.6154 - val_main_output_loss: 1.3794 - val_tof_gate_loss: 0.0594\n",
      "Epoch 9/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 539ms/step - loss: 2.3340 - main_output_accuracy: 0.5502 - main_output_loss: 1.7801 - tof_gate_loss: 0.2061 - val_loss: 1.8636 - val_main_output_accuracy: 0.6551 - val_main_output_loss: 1.3633 - val_tof_gate_loss: 0.0580\n",
      "Epoch 10/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 557ms/step - loss: 2.2361 - main_output_accuracy: 0.5786 - main_output_loss: 1.7164 - tof_gate_loss: 0.1852 - val_loss: 1.8238 - val_main_output_accuracy: 0.6485 - val_main_output_loss: 1.3523 - val_tof_gate_loss: 0.0525\n",
      "Epoch 11/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 2.2786 - main_output_accuracy: 0.5808 - main_output_loss: 1.7760 - tof_gate_loss: 0.2324 - val_loss: 1.7226 - val_main_output_accuracy: 0.6714 - val_main_output_loss: 1.2786 - val_tof_gate_loss: 0.0422\n",
      "Epoch 12/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 561ms/step - loss: 2.2090 - main_output_accuracy: 0.6077 - main_output_loss: 1.7325 - tof_gate_loss: 0.2236 - val_loss: 1.7030 - val_main_output_accuracy: 0.6786 - val_main_output_loss: 1.2792 - val_tof_gate_loss: 0.0472\n",
      "Epoch 13/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 2.0514 - main_output_accuracy: 0.6325 - main_output_loss: 1.6073 - tof_gate_loss: 0.1652 - val_loss: 1.6642 - val_main_output_accuracy: 0.6903 - val_main_output_loss: 1.2593 - val_tof_gate_loss: 0.0556\n",
      "Epoch 14/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 2.0741 - main_output_accuracy: 0.6410 - main_output_loss: 1.6417 - tof_gate_loss: 0.2038 - val_loss: 1.6457 - val_main_output_accuracy: 0.6786 - val_main_output_loss: 1.2598 - val_tof_gate_loss: 0.0473\n",
      "Epoch 15/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 544ms/step - loss: 1.9937 - main_output_accuracy: 0.6480 - main_output_loss: 1.5872 - tof_gate_loss: 0.1639 - val_loss: 1.5643 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.1971 - val_tof_gate_loss: 0.0393\n",
      "Epoch 16/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 551ms/step - loss: 2.0238 - main_output_accuracy: 0.6388 - main_output_loss: 1.6254 - tof_gate_loss: 0.2039 - val_loss: 1.6066 - val_main_output_accuracy: 0.6877 - val_main_output_loss: 1.2543 - val_tof_gate_loss: 0.0403\n",
      "Epoch 17/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 560ms/step - loss: 2.0083 - main_output_accuracy: 0.6344 - main_output_loss: 1.6268 - tof_gate_loss: 0.1910 - val_loss: 1.5368 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.1958 - val_tof_gate_loss: 0.0478\n",
      "Epoch 18/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 555ms/step - loss: 1.9341 - main_output_accuracy: 0.6634 - main_output_loss: 1.5671 - tof_gate_loss: 0.1819 - val_loss: 1.5278 - val_main_output_accuracy: 0.7132 - val_main_output_loss: 1.2032 - val_tof_gate_loss: 0.0265\n",
      "Epoch 19/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.9047 - main_output_accuracy: 0.6856 - main_output_loss: 1.5498 - tof_gate_loss: 0.1800 - val_loss: 1.5048 - val_main_output_accuracy: 0.7285 - val_main_output_loss: 1.1877 - val_tof_gate_loss: 0.0468\n",
      "Epoch 20/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 561ms/step - loss: 2.0273 - main_output_accuracy: 0.6504 - main_output_loss: 1.6732 - tof_gate_loss: 0.2355 - val_loss: 1.4544 - val_main_output_accuracy: 0.7320 - val_main_output_loss: 1.1488 - val_tof_gate_loss: 0.0374\n",
      "Epoch 21/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.8780 - main_output_accuracy: 0.6757 - main_output_loss: 1.5405 - tof_gate_loss: 0.2020 - val_loss: 1.5222 - val_main_output_accuracy: 0.7122 - val_main_output_loss: 1.2244 - val_tof_gate_loss: 0.0474\n",
      "Epoch 22/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 551ms/step - loss: 1.8142 - main_output_accuracy: 0.6945 - main_output_loss: 1.4945 - tof_gate_loss: 0.1653 - val_loss: 1.4812 - val_main_output_accuracy: 0.7213 - val_main_output_loss: 1.1951 - val_tof_gate_loss: 0.0415\n",
      "Epoch 23/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 546ms/step - loss: 1.8905 - main_output_accuracy: 0.6825 - main_output_loss: 1.5725 - tof_gate_loss: 0.2017 - val_loss: 1.5543 - val_main_output_accuracy: 0.6867 - val_main_output_loss: 1.2762 - val_tof_gate_loss: 0.0453\n",
      "Epoch 24/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 553ms/step - loss: 1.8291 - main_output_accuracy: 0.7091 - main_output_loss: 1.5215 - tof_gate_loss: 0.1915 - val_loss: 1.4426 - val_main_output_accuracy: 0.7346 - val_main_output_loss: 1.1720 - val_tof_gate_loss: 0.0406\n",
      "Epoch 25/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 546ms/step - loss: 1.8305 - main_output_accuracy: 0.6927 - main_output_loss: 1.5287 - tof_gate_loss: 0.2008 - val_loss: 1.4257 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.1610 - val_tof_gate_loss: 0.0470\n",
      "Epoch 26/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.7943 - main_output_accuracy: 0.7111 - main_output_loss: 1.5004 - tof_gate_loss: 0.1986 - val_loss: 1.3909 - val_main_output_accuracy: 0.7371 - val_main_output_loss: 1.1369 - val_tof_gate_loss: 0.0372\n",
      "Epoch 27/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.8264 - main_output_accuracy: 0.6995 - main_output_loss: 1.5387 - tof_gate_loss: 0.2015 - val_loss: 1.4331 - val_main_output_accuracy: 0.7366 - val_main_output_loss: 1.1829 - val_tof_gate_loss: 0.0401\n",
      "Epoch 28/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.6966 - main_output_accuracy: 0.7358 - main_output_loss: 1.4211 - tof_gate_loss: 0.1719 - val_loss: 1.3812 - val_main_output_accuracy: 0.7550 - val_main_output_loss: 1.1344 - val_tof_gate_loss: 0.0556\n",
      "Epoch 29/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 565ms/step - loss: 1.6911 - main_output_accuracy: 0.7571 - main_output_loss: 1.4188 - tof_gate_loss: 0.1880 - val_loss: 1.3535 - val_main_output_accuracy: 0.7570 - val_main_output_loss: 1.1166 - val_tof_gate_loss: 0.0326\n",
      "Epoch 30/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 571ms/step - loss: 1.6440 - main_output_accuracy: 0.7528 - main_output_loss: 1.3814 - tof_gate_loss: 0.1654 - val_loss: 1.4121 - val_main_output_accuracy: 0.7285 - val_main_output_loss: 1.1841 - val_tof_gate_loss: 0.0311\n",
      "Epoch 31/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.7103 - main_output_accuracy: 0.7283 - main_output_loss: 1.4503 - tof_gate_loss: 0.1821 - val_loss: 1.4188 - val_main_output_accuracy: 0.7320 - val_main_output_loss: 1.1919 - val_tof_gate_loss: 0.0305\n",
      "Epoch 32/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 563ms/step - loss: 1.7605 - main_output_accuracy: 0.7099 - main_output_loss: 1.5018 - tof_gate_loss: 0.1987 - val_loss: 1.3128 - val_main_output_accuracy: 0.7652 - val_main_output_loss: 1.0913 - val_tof_gate_loss: 0.0351\n",
      "Epoch 33/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 579ms/step - loss: 1.7165 - main_output_accuracy: 0.7360 - main_output_loss: 1.4632 - tof_gate_loss: 0.1967 - val_loss: 1.3040 - val_main_output_accuracy: 0.7697 - val_main_output_loss: 1.0913 - val_tof_gate_loss: 0.0261\n",
      "Epoch 34/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 563ms/step - loss: 1.6580 - main_output_accuracy: 0.7546 - main_output_loss: 1.4095 - tof_gate_loss: 0.1962 - val_loss: 1.3696 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.1595 - val_tof_gate_loss: 0.0305\n",
      "Epoch 35/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.5855 - main_output_accuracy: 0.7609 - main_output_loss: 1.3469 - tof_gate_loss: 0.1675 - val_loss: 1.3040 - val_main_output_accuracy: 0.7759 - val_main_output_loss: 1.0981 - val_tof_gate_loss: 0.0290\n",
      "Epoch 36/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.6203 - main_output_accuracy: 0.7618 - main_output_loss: 1.3845 - tof_gate_loss: 0.1742 - val_loss: 1.2715 - val_main_output_accuracy: 0.7820 - val_main_output_loss: 1.0695 - val_tof_gate_loss: 0.0256\n",
      "Epoch 37/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 554ms/step - loss: 1.6091 - main_output_accuracy: 0.7665 - main_output_loss: 1.3762 - tof_gate_loss: 0.1831 - val_loss: 1.2893 - val_main_output_accuracy: 0.7718 - val_main_output_loss: 1.0897 - val_tof_gate_loss: 0.0362\n",
      "Epoch 38/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.4914 - main_output_accuracy: 0.7969 - main_output_loss: 1.2706 - tof_gate_loss: 0.1400 - val_loss: 1.2605 - val_main_output_accuracy: 0.7927 - val_main_output_loss: 1.0655 - val_tof_gate_loss: 0.0257\n",
      "Epoch 39/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 586ms/step - loss: 1.5325 - main_output_accuracy: 0.7927 - main_output_loss: 1.3128 - tof_gate_loss: 0.1522 - val_loss: 1.3370 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.1441 - val_tof_gate_loss: 0.0352\n",
      "Epoch 40/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 563ms/step - loss: 1.5107 - main_output_accuracy: 0.7817 - main_output_loss: 1.2942 - tof_gate_loss: 0.1509 - val_loss: 1.3096 - val_main_output_accuracy: 0.7718 - val_main_output_loss: 1.1214 - val_tof_gate_loss: 0.0245\n",
      "Epoch 41/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.7052 - main_output_accuracy: 0.7405 - main_output_loss: 1.4770 - tof_gate_loss: 0.2232 - val_loss: 1.2517 - val_main_output_accuracy: 0.8008 - val_main_output_loss: 1.0662 - val_tof_gate_loss: 0.0253\n",
      "Epoch 42/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 579ms/step - loss: 1.4998 - main_output_accuracy: 0.8009 - main_output_loss: 1.2873 - tof_gate_loss: 0.1608 - val_loss: 1.2454 - val_main_output_accuracy: 0.7830 - val_main_output_loss: 1.0630 - val_tof_gate_loss: 0.0321\n",
      "Epoch 43/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 555ms/step - loss: 1.6450 - main_output_accuracy: 0.7704 - main_output_loss: 1.4255 - tof_gate_loss: 0.2087 - val_loss: 1.2726 - val_main_output_accuracy: 0.7753 - val_main_output_loss: 1.0911 - val_tof_gate_loss: 0.0356\n",
      "Epoch 44/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 575ms/step - loss: 1.4601 - main_output_accuracy: 0.8081 - main_output_loss: 1.2542 - tof_gate_loss: 0.1542 - val_loss: 1.2118 - val_main_output_accuracy: 0.8039 - val_main_output_loss: 1.0339 - val_tof_gate_loss: 0.0276\n",
      "Epoch 45/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 1.5635 - main_output_accuracy: 0.7913 - main_output_loss: 1.3549 - tof_gate_loss: 0.1828 - val_loss: 1.2568 - val_main_output_accuracy: 0.7809 - val_main_output_loss: 1.0781 - val_tof_gate_loss: 0.0456\n",
      "Epoch 46/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 594ms/step - loss: 1.5628 - main_output_accuracy: 0.7841 - main_output_loss: 1.3539 - tof_gate_loss: 0.1950 - val_loss: 1.2608 - val_main_output_accuracy: 0.7866 - val_main_output_loss: 1.0894 - val_tof_gate_loss: 0.0271\n",
      "Epoch 47/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 554ms/step - loss: 1.5192 - main_output_accuracy: 0.8067 - main_output_loss: 1.3145 - tof_gate_loss: 0.1860 - val_loss: 1.2389 - val_main_output_accuracy: 0.7886 - val_main_output_loss: 1.0698 - val_tof_gate_loss: 0.0239\n",
      "Epoch 48/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 549ms/step - loss: 1.4290 - main_output_accuracy: 0.8186 - main_output_loss: 1.2327 - tof_gate_loss: 0.1565 - val_loss: 1.2295 - val_main_output_accuracy: 0.7972 - val_main_output_loss: 1.0613 - val_tof_gate_loss: 0.0255\n",
      "Epoch 49/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 554ms/step - loss: 1.4793 - main_output_accuracy: 0.8126 - main_output_loss: 1.2826 - tof_gate_loss: 0.1683 - val_loss: 1.2816 - val_main_output_accuracy: 0.7789 - val_main_output_loss: 1.1134 - val_tof_gate_loss: 0.0391\n",
      "Epoch 50/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.6081 - main_output_accuracy: 0.7964 - main_output_loss: 1.4054 - tof_gate_loss: 0.2075 - val_loss: 1.2347 - val_main_output_accuracy: 0.7901 - val_main_output_loss: 1.0705 - val_tof_gate_loss: 0.0255\n",
      "Epoch 51/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 619ms/step - loss: 1.3968 - main_output_accuracy: 0.8290 - main_output_loss: 1.2094 - tof_gate_loss: 0.1423 - val_loss: 1.1977 - val_main_output_accuracy: 0.8100 - val_main_output_loss: 1.0360 - val_tof_gate_loss: 0.0263\n",
      "Epoch 52/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.4470 - main_output_accuracy: 0.8372 - main_output_loss: 1.2570 - tof_gate_loss: 0.1628 - val_loss: 1.2089 - val_main_output_accuracy: 0.8059 - val_main_output_loss: 1.0502 - val_tof_gate_loss: 0.0224\n",
      "Epoch 53/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.4518 - main_output_accuracy: 0.8156 - main_output_loss: 1.2610 - tof_gate_loss: 0.1758 - val_loss: 1.2093 - val_main_output_accuracy: 0.8044 - val_main_output_loss: 1.0494 - val_tof_gate_loss: 0.0317\n",
      "Epoch 54/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 575ms/step - loss: 1.3905 - main_output_accuracy: 0.8411 - main_output_loss: 1.2086 - tof_gate_loss: 0.1394 - val_loss: 1.2707 - val_main_output_accuracy: 0.7896 - val_main_output_loss: 1.1155 - val_tof_gate_loss: 0.0207\n",
      "Epoch 55/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 567ms/step - loss: 1.5386 - main_output_accuracy: 0.8091 - main_output_loss: 1.3468 - tof_gate_loss: 0.1978 - val_loss: 1.2674 - val_main_output_accuracy: 0.7815 - val_main_output_loss: 1.1129 - val_tof_gate_loss: 0.0299\n",
      "Epoch 56/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.4691 - main_output_accuracy: 0.8355 - main_output_loss: 1.2810 - tof_gate_loss: 0.1865 - val_loss: 1.2225 - val_main_output_accuracy: 0.8008 - val_main_output_loss: 1.0665 - val_tof_gate_loss: 0.0409\n",
      "Epoch 57/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.5696 - main_output_accuracy: 0.8143 - main_output_loss: 1.3753 - tof_gate_loss: 0.2257 - val_loss: 1.2306 - val_main_output_accuracy: 0.7891 - val_main_output_loss: 1.0779 - val_tof_gate_loss: 0.0277\n",
      "Epoch 58/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 583ms/step - loss: 1.4992 - main_output_accuracy: 0.8079 - main_output_loss: 1.3122 - tof_gate_loss: 0.1968 - val_loss: 1.2138 - val_main_output_accuracy: 0.8018 - val_main_output_loss: 1.0628 - val_tof_gate_loss: 0.0257\n",
      "Epoch 59/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 574ms/step - loss: 1.4123 - main_output_accuracy: 0.8382 - main_output_loss: 1.2307 - tof_gate_loss: 0.1763 - val_loss: 1.2629 - val_main_output_accuracy: 0.7759 - val_main_output_loss: 1.1136 - val_tof_gate_loss: 0.0284\n",
      "Epoch 60/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.4392 - main_output_accuracy: 0.8311 - main_output_loss: 1.2576 - tof_gate_loss: 0.1803 - val_loss: 1.1757 - val_main_output_accuracy: 0.8181 - val_main_output_loss: 1.0265 - val_tof_gate_loss: 0.0320\n",
      "Epoch 61/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.3036 - main_output_accuracy: 0.8554 - main_output_loss: 1.1323 - tof_gate_loss: 0.1367 - val_loss: 1.2243 - val_main_output_accuracy: 0.8003 - val_main_output_loss: 1.0737 - val_tof_gate_loss: 0.0428\n",
      "Epoch 62/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 611ms/step - loss: 1.5145 - main_output_accuracy: 0.8017 - main_output_loss: 1.3316 - tof_gate_loss: 0.2023 - val_loss: 1.2053 - val_main_output_accuracy: 0.8023 - val_main_output_loss: 1.0585 - val_tof_gate_loss: 0.0328\n",
      "Epoch 63/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 583ms/step - loss: 1.4311 - main_output_accuracy: 0.8335 - main_output_loss: 1.2539 - tof_gate_loss: 0.1799 - val_loss: 1.1788 - val_main_output_accuracy: 0.8125 - val_main_output_loss: 1.0314 - val_tof_gate_loss: 0.0434\n",
      "Epoch 64/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 593ms/step - loss: 1.3421 - main_output_accuracy: 0.8624 - main_output_loss: 1.1728 - tof_gate_loss: 0.1452 - val_loss: 1.1930 - val_main_output_accuracy: 0.8110 - val_main_output_loss: 1.0519 - val_tof_gate_loss: 0.0199\n",
      "Epoch 65/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 592ms/step - loss: 1.3591 - main_output_accuracy: 0.8562 - main_output_loss: 1.1897 - tof_gate_loss: 0.1536 - val_loss: 1.1895 - val_main_output_accuracy: 0.8120 - val_main_output_loss: 1.0466 - val_tof_gate_loss: 0.0230\n",
      "Epoch 66/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 557ms/step - loss: 1.4595 - main_output_accuracy: 0.8304 - main_output_loss: 1.2829 - tof_gate_loss: 0.1934 - val_loss: 1.2200 - val_main_output_accuracy: 0.7972 - val_main_output_loss: 1.0801 - val_tof_gate_loss: 0.0225\n",
      "Epoch 67/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 1.3258 - main_output_accuracy: 0.8559 - main_output_loss: 1.1596 - tof_gate_loss: 0.1473 - val_loss: 1.1828 - val_main_output_accuracy: 0.8064 - val_main_output_loss: 1.0433 - val_tof_gate_loss: 0.0213\n",
      "Epoch 68/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - loss: 1.4796 - main_output_accuracy: 0.8260 - main_output_loss: 1.3049 - tof_gate_loss: 0.1967 - val_loss: 1.2114 - val_main_output_accuracy: 0.7972 - val_main_output_loss: 1.0723 - val_tof_gate_loss: 0.0249\n",
      "Epoch 69/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 583ms/step - loss: 1.3053 - main_output_accuracy: 0.8725 - main_output_loss: 1.1402 - tof_gate_loss: 0.1474 - val_loss: 1.1963 - val_main_output_accuracy: 0.8105 - val_main_output_loss: 1.0615 - val_tof_gate_loss: 0.0183\n",
      "Epoch 70/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.3240 - main_output_accuracy: 0.8656 - main_output_loss: 1.1611 - tof_gate_loss: 0.1451 - val_loss: 1.1932 - val_main_output_accuracy: 0.8074 - val_main_output_loss: 1.0533 - val_tof_gate_loss: 0.0340\n",
      "Epoch 71/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 540ms/step - loss: 1.3418 - main_output_accuracy: 0.8582 - main_output_loss: 1.1782 - tof_gate_loss: 0.1537 - val_loss: 1.1923 - val_main_output_accuracy: 0.8074 - val_main_output_loss: 1.0592 - val_tof_gate_loss: 0.0156\n",
      "Epoch 72/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 590ms/step - loss: 1.3198 - main_output_accuracy: 0.8589 - main_output_loss: 1.1594 - tof_gate_loss: 0.1427 - val_loss: 1.1707 - val_main_output_accuracy: 0.8192 - val_main_output_loss: 1.0351 - val_tof_gate_loss: 0.0262\n",
      "Epoch 73/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - loss: 1.2462 - main_output_accuracy: 0.8877 - main_output_loss: 1.0890 - tof_gate_loss: 0.1300 - val_loss: 1.1768 - val_main_output_accuracy: 0.8222 - val_main_output_loss: 1.0439 - val_tof_gate_loss: 0.0182\n",
      "Epoch 74/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.4396 - main_output_accuracy: 0.8478 - main_output_loss: 1.2653 - tof_gate_loss: 0.2190 - val_loss: 1.1787 - val_main_output_accuracy: 0.8202 - val_main_output_loss: 1.0460 - val_tof_gate_loss: 0.0254\n",
      "Epoch 75/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.2607 - main_output_accuracy: 0.8733 - main_output_loss: 1.1042 - tof_gate_loss: 0.1359 - val_loss: 1.1794 - val_main_output_accuracy: 0.8146 - val_main_output_loss: 1.0477 - val_tof_gate_loss: 0.0174\n",
      "Epoch 76/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - loss: 1.3219 - main_output_accuracy: 0.8680 - main_output_loss: 1.1602 - tof_gate_loss: 0.1644 - val_loss: 1.2929 - val_main_output_accuracy: 0.7718 - val_main_output_loss: 1.1621 - val_tof_gate_loss: 0.0235\n",
      "Epoch 77/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 580ms/step - loss: 1.2187 - main_output_accuracy: 0.8835 - main_output_loss: 1.0653 - tof_gate_loss: 0.1290 - val_loss: 1.1746 - val_main_output_accuracy: 0.8197 - val_main_output_loss: 1.0446 - val_tof_gate_loss: 0.0202\n",
      "Epoch 78/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.3661 - main_output_accuracy: 0.8554 - main_output_loss: 1.2023 - tof_gate_loss: 0.1843 - val_loss: 1.1996 - val_main_output_accuracy: 0.8120 - val_main_output_loss: 1.0713 - val_tof_gate_loss: 0.0205\n",
      "Epoch 79/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 592ms/step - loss: 1.3739 - main_output_accuracy: 0.8682 - main_output_loss: 1.2126 - tof_gate_loss: 0.1754 - val_loss: 1.1695 - val_main_output_accuracy: 0.8222 - val_main_output_loss: 1.0395 - val_tof_gate_loss: 0.0321\n",
      "Epoch 80/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 656ms/step - loss: 1.2757 - main_output_accuracy: 0.8873 - main_output_loss: 1.1189 - tof_gate_loss: 0.1547 - val_loss: 1.1903 - val_main_output_accuracy: 0.8074 - val_main_output_loss: 1.0622 - val_tof_gate_loss: 0.0232\n",
      "Epoch 81/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 576ms/step - loss: 1.3476 - main_output_accuracy: 0.8710 - main_output_loss: 1.1895 - tof_gate_loss: 0.1672 - val_loss: 1.1518 - val_main_output_accuracy: 0.8293 - val_main_output_loss: 1.0244 - val_tof_gate_loss: 0.0203\n",
      "Epoch 82/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 584ms/step - loss: 1.1245 - main_output_accuracy: 0.9113 - main_output_loss: 0.9792 - tof_gate_loss: 0.1060 - val_loss: 1.1658 - val_main_output_accuracy: 0.8197 - val_main_output_loss: 1.0391 - val_tof_gate_loss: 0.0195\n",
      "Epoch 83/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.3997 - main_output_accuracy: 0.8516 - main_output_loss: 1.2356 - tof_gate_loss: 0.2026 - val_loss: 1.1852 - val_main_output_accuracy: 0.8242 - val_main_output_loss: 1.0596 - val_tof_gate_loss: 0.0243\n",
      "Epoch 84/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - loss: 1.3313 - main_output_accuracy: 0.8557 - main_output_loss: 1.1748 - tof_gate_loss: 0.1663 - val_loss: 1.1676 - val_main_output_accuracy: 0.8217 - val_main_output_loss: 1.0407 - val_tof_gate_loss: 0.0291\n",
      "Epoch 85/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.1708 - main_output_accuracy: 0.9049 - main_output_loss: 1.0249 - tof_gate_loss: 0.1168 - val_loss: 1.1631 - val_main_output_accuracy: 0.8227 - val_main_output_loss: 1.0391 - val_tof_gate_loss: 0.0204\n",
      "Epoch 86/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.2623 - main_output_accuracy: 0.8906 - main_output_loss: 1.1105 - tof_gate_loss: 0.1504 - val_loss: 1.1599 - val_main_output_accuracy: 0.8248 - val_main_output_loss: 1.0353 - val_tof_gate_loss: 0.0247\n",
      "Epoch 87/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 580ms/step - loss: 1.4061 - main_output_accuracy: 0.8482 - main_output_loss: 1.2460 - tof_gate_loss: 0.1938 - val_loss: 1.1496 - val_main_output_accuracy: 0.8258 - val_main_output_loss: 1.0256 - val_tof_gate_loss: 0.0239\n",
      "Epoch 88/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - loss: 1.2685 - main_output_accuracy: 0.8908 - main_output_loss: 1.1190 - tof_gate_loss: 0.1442 - val_loss: 1.1717 - val_main_output_accuracy: 0.8156 - val_main_output_loss: 1.0483 - val_tof_gate_loss: 0.0210\n",
      "Epoch 89/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 567ms/step - loss: 1.3085 - main_output_accuracy: 0.8567 - main_output_loss: 1.1540 - tof_gate_loss: 0.1729 - val_loss: 1.2000 - val_main_output_accuracy: 0.8059 - val_main_output_loss: 1.0767 - val_tof_gate_loss: 0.0253\n",
      "Epoch 90/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 571ms/step - loss: 1.3118 - main_output_accuracy: 0.8763 - main_output_loss: 1.1582 - tof_gate_loss: 0.1707 - val_loss: 1.1551 - val_main_output_accuracy: 0.8293 - val_main_output_loss: 1.0333 - val_tof_gate_loss: 0.0248\n",
      "Epoch 91/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.2983 - main_output_accuracy: 0.8906 - main_output_loss: 1.1449 - tof_gate_loss: 0.1715 - val_loss: 1.1583 - val_main_output_accuracy: 0.8355 - val_main_output_loss: 1.0358 - val_tof_gate_loss: 0.0230\n",
      "Epoch 92/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.2997 - main_output_accuracy: 0.8886 - main_output_loss: 1.1481 - tof_gate_loss: 0.1648 - val_loss: 1.1555 - val_main_output_accuracy: 0.8304 - val_main_output_loss: 1.0350 - val_tof_gate_loss: 0.0224\n",
      "Epoch 93/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.3236 - main_output_accuracy: 0.8748 - main_output_loss: 1.1718 - tof_gate_loss: 0.1677 - val_loss: 1.1605 - val_main_output_accuracy: 0.8248 - val_main_output_loss: 1.0404 - val_tof_gate_loss: 0.0229\n",
      "Epoch 94/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 1.2226 - main_output_accuracy: 0.8950 - main_output_loss: 1.0758 - tof_gate_loss: 0.1462 - val_loss: 1.1781 - val_main_output_accuracy: 0.8202 - val_main_output_loss: 1.0593 - val_tof_gate_loss: 0.0200\n",
      "Epoch 95/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 598ms/step - loss: 1.2434 - main_output_accuracy: 0.8962 - main_output_loss: 1.0964 - tof_gate_loss: 0.1492 - val_loss: 1.1971 - val_main_output_accuracy: 0.8181 - val_main_output_loss: 1.0782 - val_tof_gate_loss: 0.0195\n",
      "Epoch 96/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.3270 - main_output_accuracy: 0.8726 - main_output_loss: 1.1734 - tof_gate_loss: 0.1844 - val_loss: 1.1571 - val_main_output_accuracy: 0.8253 - val_main_output_loss: 1.0371 - val_tof_gate_loss: 0.0262\n",
      "Epoch 97/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 581ms/step - loss: 1.2689 - main_output_accuracy: 0.9040 - main_output_loss: 1.1213 - tof_gate_loss: 0.1568 - val_loss: 1.1763 - val_main_output_accuracy: 0.8232 - val_main_output_loss: 1.0584 - val_tof_gate_loss: 0.0202\n",
      "Epoch 98/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 579ms/step - loss: 1.1170 - main_output_accuracy: 0.9280 - main_output_loss: 0.9779 - tof_gate_loss: 0.1161 - val_loss: 1.1946 - val_main_output_accuracy: 0.8222 - val_main_output_loss: 1.0765 - val_tof_gate_loss: 0.0214\n",
      "Epoch 99/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 594ms/step - loss: 1.2894 - main_output_accuracy: 0.8880 - main_output_loss: 1.1411 - tof_gate_loss: 0.1657 - val_loss: 1.1641 - val_main_output_accuracy: 0.8273 - val_main_output_loss: 1.0471 - val_tof_gate_loss: 0.0186\n",
      "Epoch 100/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 594ms/step - loss: 1.2417 - main_output_accuracy: 0.9068 - main_output_loss: 1.0954 - tof_gate_loss: 0.1546 - val_loss: 1.1720 - val_main_output_accuracy: 0.8278 - val_main_output_loss: 1.0549 - val_tof_gate_loss: 0.0198\n",
      "Epoch 101/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 595ms/step - loss: 1.2805 - main_output_accuracy: 0.8811 - main_output_loss: 1.1314 - tof_gate_loss: 0.1722 - val_loss: 1.1646 - val_main_output_accuracy: 0.8237 - val_main_output_loss: 1.0467 - val_tof_gate_loss: 0.0218\n",
      "Epoch 102/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 581ms/step - loss: 1.3679 - main_output_accuracy: 0.8626 - main_output_loss: 1.2168 - tof_gate_loss: 0.1842 - val_loss: 1.1498 - val_main_output_accuracy: 0.8299 - val_main_output_loss: 1.0336 - val_tof_gate_loss: 0.0193\n",
      "Epoch 103/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 587ms/step - loss: 1.2755 - main_output_accuracy: 0.8905 - main_output_loss: 1.1300 - tof_gate_loss: 0.1590 - val_loss: 1.1662 - val_main_output_accuracy: 0.8237 - val_main_output_loss: 1.0501 - val_tof_gate_loss: 0.0221\n",
      "Epoch 104/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 591ms/step - loss: 1.2316 - main_output_accuracy: 0.8921 - main_output_loss: 1.0883 - tof_gate_loss: 0.1496 - val_loss: 1.1576 - val_main_output_accuracy: 0.8273 - val_main_output_loss: 1.0430 - val_tof_gate_loss: 0.0156\n",
      "Epoch 105/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 571ms/step - loss: 1.2215 - main_output_accuracy: 0.9016 - main_output_loss: 1.0784 - tof_gate_loss: 0.1508 - val_loss: 1.1527 - val_main_output_accuracy: 0.8329 - val_main_output_loss: 1.0378 - val_tof_gate_loss: 0.0213\n",
      "Epoch 106/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 593ms/step - loss: 1.2145 - main_output_accuracy: 0.9000 - main_output_loss: 1.0728 - tof_gate_loss: 0.1447 - val_loss: 1.1768 - val_main_output_accuracy: 0.8248 - val_main_output_loss: 1.0627 - val_tof_gate_loss: 0.0155\n",
      "Epoch 107/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 591ms/step - loss: 1.1708 - main_output_accuracy: 0.9091 - main_output_loss: 1.0316 - tof_gate_loss: 0.1347 - val_loss: 1.1404 - val_main_output_accuracy: 0.8360 - val_main_output_loss: 1.0264 - val_tof_gate_loss: 0.0202\n",
      "Epoch 108/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 579ms/step - loss: 1.1289 - main_output_accuracy: 0.9249 - main_output_loss: 0.9937 - tof_gate_loss: 0.1161 - val_loss: 1.1486 - val_main_output_accuracy: 0.8304 - val_main_output_loss: 1.0352 - val_tof_gate_loss: 0.0187\n",
      "Epoch 109/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 575ms/step - loss: 1.1689 - main_output_accuracy: 0.9241 - main_output_loss: 1.0307 - tof_gate_loss: 0.1327 - val_loss: 1.1634 - val_main_output_accuracy: 0.8339 - val_main_output_loss: 1.0499 - val_tof_gate_loss: 0.0168\n",
      "Epoch 110/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 571ms/step - loss: 1.2257 - main_output_accuracy: 0.9031 - main_output_loss: 1.0837 - tof_gate_loss: 0.1536 - val_loss: 1.1606 - val_main_output_accuracy: 0.8299 - val_main_output_loss: 1.0477 - val_tof_gate_loss: 0.0195\n",
      "Epoch 111/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.3772 - main_output_accuracy: 0.8713 - main_output_loss: 1.2274 - tof_gate_loss: 0.1930 - val_loss: 1.1538 - val_main_output_accuracy: 0.8304 - val_main_output_loss: 1.0411 - val_tof_gate_loss: 0.0190\n",
      "Epoch 112/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 1.1575 - main_output_accuracy: 0.8995 - main_output_loss: 1.0205 - tof_gate_loss: 0.1307 - val_loss: 1.1585 - val_main_output_accuracy: 0.8258 - val_main_output_loss: 1.0468 - val_tof_gate_loss: 0.0183\n",
      "Epoch 113/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 584ms/step - loss: 1.1188 - main_output_accuracy: 0.9357 - main_output_loss: 0.9837 - tof_gate_loss: 0.1230 - val_loss: 1.1553 - val_main_output_accuracy: 0.8283 - val_main_output_loss: 1.0446 - val_tof_gate_loss: 0.0155\n",
      "Epoch 114/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.1882 - main_output_accuracy: 0.9024 - main_output_loss: 1.0493 - tof_gate_loss: 0.1433 - val_loss: 1.1803 - val_main_output_accuracy: 0.8186 - val_main_output_loss: 1.0696 - val_tof_gate_loss: 0.0164\n",
      "Epoch 115/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.1573 - main_output_accuracy: 0.9118 - main_output_loss: 1.0214 - tof_gate_loss: 0.1288 - val_loss: 1.1481 - val_main_output_accuracy: 0.8299 - val_main_output_loss: 1.0377 - val_tof_gate_loss: 0.0173\n",
      "Epoch 116/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 581ms/step - loss: 1.3041 - main_output_accuracy: 0.8812 - main_output_loss: 1.1574 - tof_gate_loss: 0.1852 - val_loss: 1.1527 - val_main_output_accuracy: 0.8304 - val_main_output_loss: 1.0413 - val_tof_gate_loss: 0.0215\n",
      "Epoch 117/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.1951 - main_output_accuracy: 0.9113 - main_output_loss: 1.0563 - tof_gate_loss: 0.1465 - val_loss: 1.1628 - val_main_output_accuracy: 0.8314 - val_main_output_loss: 1.0520 - val_tof_gate_loss: 0.0176\n",
      "Epoch 118/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 592ms/step - loss: 1.1901 - main_output_accuracy: 0.9076 - main_output_loss: 1.0528 - tof_gate_loss: 0.1400 - val_loss: 1.1525 - val_main_output_accuracy: 0.8339 - val_main_output_loss: 1.0424 - val_tof_gate_loss: 0.0184\n",
      "Epoch 119/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 587ms/step - loss: 1.1994 - main_output_accuracy: 0.9148 - main_output_loss: 1.0608 - tof_gate_loss: 0.1473 - val_loss: 1.1559 - val_main_output_accuracy: 0.8334 - val_main_output_loss: 1.0458 - val_tof_gate_loss: 0.0173\n",
      "Epoch 120/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 574ms/step - loss: 1.2171 - main_output_accuracy: 0.9047 - main_output_loss: 1.0782 - tof_gate_loss: 0.1489 - val_loss: 1.1568 - val_main_output_accuracy: 0.8283 - val_main_output_loss: 1.0472 - val_tof_gate_loss: 0.0173\n",
      "Epoch 121/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 586ms/step - loss: 1.1083 - main_output_accuracy: 0.9428 - main_output_loss: 0.9743 - tof_gate_loss: 0.1265 - val_loss: 1.1582 - val_main_output_accuracy: 0.8370 - val_main_output_loss: 1.0490 - val_tof_gate_loss: 0.0166\n",
      "Epoch 122/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 1.3073 - main_output_accuracy: 0.8836 - main_output_loss: 1.1631 - tof_gate_loss: 0.1780 - val_loss: 1.1715 - val_main_output_accuracy: 0.8232 - val_main_output_loss: 1.0624 - val_tof_gate_loss: 0.0167\n",
      "Epoch 123/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 567ms/step - loss: 1.2339 - main_output_accuracy: 0.8916 - main_output_loss: 1.0967 - tof_gate_loss: 0.1442 - val_loss: 1.1500 - val_main_output_accuracy: 0.8370 - val_main_output_loss: 1.0407 - val_tof_gate_loss: 0.0161\n",
      "Epoch 124/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 587ms/step - loss: 1.3173 - main_output_accuracy: 0.8963 - main_output_loss: 1.1735 - tof_gate_loss: 0.1776 - val_loss: 1.1312 - val_main_output_accuracy: 0.8360 - val_main_output_loss: 1.0223 - val_tof_gate_loss: 0.0140\n",
      "Epoch 125/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.2700 - main_output_accuracy: 0.9030 - main_output_loss: 1.1278 - tof_gate_loss: 0.1694 - val_loss: 1.1344 - val_main_output_accuracy: 0.8349 - val_main_output_loss: 1.0248 - val_tof_gate_loss: 0.0155\n",
      "Epoch 126/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.1793 - main_output_accuracy: 0.9144 - main_output_loss: 1.0431 - tof_gate_loss: 0.1399 - val_loss: 1.1351 - val_main_output_accuracy: 0.8365 - val_main_output_loss: 1.0256 - val_tof_gate_loss: 0.0165\n",
      "Epoch 127/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.3417 - main_output_accuracy: 0.8779 - main_output_loss: 1.1938 - tof_gate_loss: 0.1994 - val_loss: 1.1486 - val_main_output_accuracy: 0.8349 - val_main_output_loss: 1.0392 - val_tof_gate_loss: 0.0175\n",
      "Epoch 128/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 588ms/step - loss: 1.2115 - main_output_accuracy: 0.9145 - main_output_loss: 1.0747 - tof_gate_loss: 0.1452 - val_loss: 1.1390 - val_main_output_accuracy: 0.8385 - val_main_output_loss: 1.0299 - val_tof_gate_loss: 0.0165\n",
      "Epoch 129/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 602ms/step - loss: 1.2244 - main_output_accuracy: 0.8884 - main_output_loss: 1.0859 - tof_gate_loss: 0.1527 - val_loss: 1.1492 - val_main_output_accuracy: 0.8360 - val_main_output_loss: 1.0405 - val_tof_gate_loss: 0.0160\n",
      "Epoch 130/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.0917 - main_output_accuracy: 0.9292 - main_output_loss: 0.9613 - tof_gate_loss: 0.1129 - val_loss: 1.1461 - val_main_output_accuracy: 0.8339 - val_main_output_loss: 1.0376 - val_tof_gate_loss: 0.0147\n",
      "Epoch 131/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 1.2082 - main_output_accuracy: 0.9098 - main_output_loss: 1.0702 - tof_gate_loss: 0.1518 - val_loss: 1.1476 - val_main_output_accuracy: 0.8344 - val_main_output_loss: 1.0391 - val_tof_gate_loss: 0.0145\n",
      "Epoch 132/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 588ms/step - loss: 1.3089 - main_output_accuracy: 0.8807 - main_output_loss: 1.1657 - tof_gate_loss: 0.1779 - val_loss: 1.1401 - val_main_output_accuracy: 0.8406 - val_main_output_loss: 1.0317 - val_tof_gate_loss: 0.0162\n",
      "Epoch 133/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.2344 - main_output_accuracy: 0.9049 - main_output_loss: 1.0945 - tof_gate_loss: 0.1616 - val_loss: 1.1453 - val_main_output_accuracy: 0.8385 - val_main_output_loss: 1.0370 - val_tof_gate_loss: 0.0165\n",
      "Epoch 134/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 576ms/step - loss: 1.1632 - main_output_accuracy: 0.9173 - main_output_loss: 1.0282 - tof_gate_loss: 0.1371 - val_loss: 1.1456 - val_main_output_accuracy: 0.8395 - val_main_output_loss: 1.0376 - val_tof_gate_loss: 0.0152\n",
      "Epoch 135/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - loss: 1.1577 - main_output_accuracy: 0.9286 - main_output_loss: 1.0215 - tof_gate_loss: 0.1442 - val_loss: 1.1449 - val_main_output_accuracy: 0.8355 - val_main_output_loss: 1.0369 - val_tof_gate_loss: 0.0152\n",
      "Epoch 136/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.1986 - main_output_accuracy: 0.9030 - main_output_loss: 1.0618 - tof_gate_loss: 0.1467 - val_loss: 1.1430 - val_main_output_accuracy: 0.8406 - val_main_output_loss: 1.0347 - val_tof_gate_loss: 0.0157\n",
      "Epoch 137/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.1091 - main_output_accuracy: 0.9341 - main_output_loss: 0.9779 - tof_gate_loss: 0.1200 - val_loss: 1.1413 - val_main_output_accuracy: 0.8385 - val_main_output_loss: 1.0330 - val_tof_gate_loss: 0.0163\n",
      "Epoch 138/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 585ms/step - loss: 1.2816 - main_output_accuracy: 0.8866 - main_output_loss: 1.1413 - tof_gate_loss: 0.1656 - val_loss: 1.1445 - val_main_output_accuracy: 0.8339 - val_main_output_loss: 1.0363 - val_tof_gate_loss: 0.0160\n",
      "Epoch 139/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 591ms/step - loss: 1.3113 - main_output_accuracy: 0.8968 - main_output_loss: 1.1684 - tof_gate_loss: 0.1782 - val_loss: 1.1423 - val_main_output_accuracy: 0.8355 - val_main_output_loss: 1.0341 - val_tof_gate_loss: 0.0160\n",
      "Epoch 140/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - loss: 1.1264 - main_output_accuracy: 0.9268 - main_output_loss: 0.9952 - tof_gate_loss: 0.1200 - val_loss: 1.1443 - val_main_output_accuracy: 0.8344 - val_main_output_loss: 1.0361 - val_tof_gate_loss: 0.0158\n",
      "Epoch 141/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.1995 - main_output_accuracy: 0.9201 - main_output_loss: 1.0611 - tof_gate_loss: 0.1560 - val_loss: 1.1437 - val_main_output_accuracy: 0.8380 - val_main_output_loss: 1.0355 - val_tof_gate_loss: 0.0160\n",
      "Epoch 142/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.2880 - main_output_accuracy: 0.9027 - main_output_loss: 1.1477 - tof_gate_loss: 0.1663 - val_loss: 1.1438 - val_main_output_accuracy: 0.8349 - val_main_output_loss: 1.0358 - val_tof_gate_loss: 0.0151\n",
      "Epoch 143/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 583ms/step - loss: 1.2094 - main_output_accuracy: 0.9207 - main_output_loss: 1.0725 - tof_gate_loss: 0.1491 - val_loss: 1.1425 - val_main_output_accuracy: 0.8370 - val_main_output_loss: 1.0344 - val_tof_gate_loss: 0.0154\n",
      "Epoch 144/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 571ms/step - loss: 1.1691 - main_output_accuracy: 0.9121 - main_output_loss: 1.0333 - tof_gate_loss: 0.1434 - val_loss: 1.1406 - val_main_output_accuracy: 0.8370 - val_main_output_loss: 1.0326 - val_tof_gate_loss: 0.0150\n",
      "Epoch 145/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.1730 - main_output_accuracy: 0.9180 - main_output_loss: 1.0372 - tof_gate_loss: 0.1433 - val_loss: 1.1401 - val_main_output_accuracy: 0.8370 - val_main_output_loss: 1.0321 - val_tof_gate_loss: 0.0150\n",
      "Epoch 146/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 596ms/step - loss: 1.2528 - main_output_accuracy: 0.9126 - main_output_loss: 1.1123 - tof_gate_loss: 0.1666 - val_loss: 1.1413 - val_main_output_accuracy: 0.8355 - val_main_output_loss: 1.0333 - val_tof_gate_loss: 0.0149\n",
      "Epoch 147/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 583ms/step - loss: 1.0813 - main_output_accuracy: 0.9257 - main_output_loss: 0.9517 - tof_gate_loss: 0.1125 - val_loss: 1.1409 - val_main_output_accuracy: 0.8355 - val_main_output_loss: 1.0329 - val_tof_gate_loss: 0.0149\n",
      "Epoch 148/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 619ms/step - loss: 1.1308 - main_output_accuracy: 0.9302 - main_output_loss: 0.9977 - tof_gate_loss: 0.1299 - val_loss: 1.1405 - val_main_output_accuracy: 0.8365 - val_main_output_loss: 1.0325 - val_tof_gate_loss: 0.0152\n",
      "Epoch 149/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 622ms/step - loss: 1.1630 - main_output_accuracy: 0.9251 - main_output_loss: 1.0281 - tof_gate_loss: 0.1408 - val_loss: 1.1412 - val_main_output_accuracy: 0.8375 - val_main_output_loss: 1.0332 - val_tof_gate_loss: 0.0154\n",
      "Epoch 150/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 632ms/step - loss: 1.2298 - main_output_accuracy: 0.9019 - main_output_loss: 1.0915 - tof_gate_loss: 0.1557 - val_loss: 1.1411 - val_main_output_accuracy: 0.8365 - val_main_output_loss: 1.0330 - val_tof_gate_loss: 0.0152\n",
      "--- Training complete. Applying EMA weights for evaluation. ---\n",
      "EMA Callback: EMA weights have been applied to the model.\n",
      "--- Fold 1 Best Epoch: 132 ---\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step\n",
      "Fold 1 Accuracy: 0.8360\n",
      "\n",
      "=== Fold 2/4 for hybrid_head_model ===\n",
      "Size of X_train: (68, 106)\n",
      "LR Scheduler: 92 steps per epoch, 13800 total decay steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA Callback: EMA weights initialized.\n",
      "Epoch 1/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 652ms/step - loss: 4.0142 - main_output_accuracy: 0.1143 - main_output_loss: 3.0030 - tof_gate_loss: 0.4997 - val_loss: 3.4697 - val_main_output_accuracy: 0.2099 - val_main_output_loss: 2.5314 - val_tof_gate_loss: 0.3412\n",
      "Epoch 2/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 598ms/step - loss: 3.3366 - main_output_accuracy: 0.2672 - main_output_loss: 2.4129 - tof_gate_loss: 0.3419 - val_loss: 3.1589 - val_main_output_accuracy: 0.2919 - val_main_output_loss: 2.3254 - val_tof_gate_loss: 0.1429\n",
      "Epoch 3/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 589ms/step - loss: 3.0804 - main_output_accuracy: 0.3345 - main_output_loss: 2.2345 - tof_gate_loss: 0.2834 - val_loss: 2.5665 - val_main_output_accuracy: 0.4513 - val_main_output_loss: 1.8084 - val_tof_gate_loss: 0.0918\n",
      "Epoch 4/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 583ms/step - loss: 2.8342 - main_output_accuracy: 0.3953 - main_output_loss: 2.0701 - tof_gate_loss: 0.1927 - val_loss: 2.3106 - val_main_output_accuracy: 0.5543 - val_main_output_loss: 1.6121 - val_tof_gate_loss: 0.0922\n",
      "Epoch 5/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 2.7580 - main_output_accuracy: 0.4335 - main_output_loss: 2.0443 - tof_gate_loss: 0.2262 - val_loss: 2.1745 - val_main_output_accuracy: 0.5685 - val_main_output_loss: 1.5340 - val_tof_gate_loss: 0.0614\n",
      "Epoch 6/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - loss: 2.6064 - main_output_accuracy: 0.4749 - main_output_loss: 1.9445 - tof_gate_loss: 0.2193 - val_loss: 2.0311 - val_main_output_accuracy: 0.6246 - val_main_output_loss: 1.4373 - val_tof_gate_loss: 0.0534\n",
      "Epoch 7/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 2.5095 - main_output_accuracy: 0.4983 - main_output_loss: 1.8891 - tof_gate_loss: 0.2277 - val_loss: 2.1703 - val_main_output_accuracy: 0.5578 - val_main_output_loss: 1.6167 - val_tof_gate_loss: 0.0493\n",
      "Epoch 8/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 567ms/step - loss: 2.3443 - main_output_accuracy: 0.5375 - main_output_loss: 1.7725 - tof_gate_loss: 0.1765 - val_loss: 1.9111 - val_main_output_accuracy: 0.6424 - val_main_output_loss: 1.3921 - val_tof_gate_loss: 0.0459\n",
      "Epoch 9/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 567ms/step - loss: 2.2752 - main_output_accuracy: 0.5662 - main_output_loss: 1.7361 - tof_gate_loss: 0.1780 - val_loss: 1.8678 - val_main_output_accuracy: 0.6383 - val_main_output_loss: 1.3811 - val_tof_gate_loss: 0.0323\n",
      "Epoch 10/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 2.3183 - main_output_accuracy: 0.5582 - main_output_loss: 1.7986 - tof_gate_loss: 0.2236 - val_loss: 1.7909 - val_main_output_accuracy: 0.6572 - val_main_output_loss: 1.3288 - val_tof_gate_loss: 0.0412\n",
      "Epoch 11/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 579ms/step - loss: 2.2134 - main_output_accuracy: 0.5946 - main_output_loss: 1.7279 - tof_gate_loss: 0.1790 - val_loss: 1.7773 - val_main_output_accuracy: 0.6602 - val_main_output_loss: 1.3349 - val_tof_gate_loss: 0.0520\n",
      "Epoch 12/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 559ms/step - loss: 2.1550 - main_output_accuracy: 0.5932 - main_output_loss: 1.6896 - tof_gate_loss: 0.1900 - val_loss: 1.7335 - val_main_output_accuracy: 0.6679 - val_main_output_loss: 1.3157 - val_tof_gate_loss: 0.0328\n",
      "Epoch 13/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 555ms/step - loss: 2.0610 - main_output_accuracy: 0.6175 - main_output_loss: 1.6208 - tof_gate_loss: 0.1617 - val_loss: 1.7275 - val_main_output_accuracy: 0.6689 - val_main_output_loss: 1.3273 - val_tof_gate_loss: 0.0384\n",
      "Epoch 14/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 584ms/step - loss: 2.1082 - main_output_accuracy: 0.6106 - main_output_loss: 1.6810 - tof_gate_loss: 0.1850 - val_loss: 1.6756 - val_main_output_accuracy: 0.6877 - val_main_output_loss: 1.2894 - val_tof_gate_loss: 0.0466\n",
      "Epoch 15/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 567ms/step - loss: 2.0595 - main_output_accuracy: 0.6235 - main_output_loss: 1.6459 - tof_gate_loss: 0.2005 - val_loss: 1.6515 - val_main_output_accuracy: 0.6770 - val_main_output_loss: 1.2847 - val_tof_gate_loss: 0.0359\n",
      "Epoch 16/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 2.0033 - main_output_accuracy: 0.6452 - main_output_loss: 1.6067 - tof_gate_loss: 0.1902 - val_loss: 1.5755 - val_main_output_accuracy: 0.7056 - val_main_output_loss: 1.2229 - val_tof_gate_loss: 0.0304\n",
      "Epoch 17/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 555ms/step - loss: 1.9813 - main_output_accuracy: 0.6469 - main_output_loss: 1.5990 - tof_gate_loss: 0.1866 - val_loss: 1.5744 - val_main_output_accuracy: 0.7045 - val_main_output_loss: 1.2314 - val_tof_gate_loss: 0.0390\n",
      "Epoch 18/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 561ms/step - loss: 1.8905 - main_output_accuracy: 0.6754 - main_output_loss: 1.5231 - tof_gate_loss: 0.1774 - val_loss: 1.5414 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.2088 - val_tof_gate_loss: 0.0487\n",
      "Epoch 19/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.8834 - main_output_accuracy: 0.6811 - main_output_loss: 1.5283 - tof_gate_loss: 0.1736 - val_loss: 1.5247 - val_main_output_accuracy: 0.7173 - val_main_output_loss: 1.2083 - val_tof_gate_loss: 0.0233\n",
      "Epoch 20/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.8957 - main_output_accuracy: 0.6836 - main_output_loss: 1.5470 - tof_gate_loss: 0.1950 - val_loss: 1.5417 - val_main_output_accuracy: 0.7050 - val_main_output_loss: 1.2333 - val_tof_gate_loss: 0.0391\n",
      "Epoch 21/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.8534 - main_output_accuracy: 0.6829 - main_output_loss: 1.5201 - tof_gate_loss: 0.1700 - val_loss: 1.4756 - val_main_output_accuracy: 0.7371 - val_main_output_loss: 1.1781 - val_tof_gate_loss: 0.0277\n",
      "Epoch 22/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.8351 - main_output_accuracy: 0.6852 - main_output_loss: 1.5108 - tof_gate_loss: 0.1688 - val_loss: 1.4694 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.1785 - val_tof_gate_loss: 0.0363\n",
      "Epoch 23/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.7119 - main_output_accuracy: 0.7076 - main_output_loss: 1.4012 - tof_gate_loss: 0.1439 - val_loss: 1.4947 - val_main_output_accuracy: 0.7178 - val_main_output_loss: 1.2109 - val_tof_gate_loss: 0.0424\n",
      "Epoch 24/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.7479 - main_output_accuracy: 0.7163 - main_output_loss: 1.4397 - tof_gate_loss: 0.1707 - val_loss: 1.4545 - val_main_output_accuracy: 0.7336 - val_main_output_loss: 1.1788 - val_tof_gate_loss: 0.0241\n",
      "Epoch 25/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 571ms/step - loss: 1.7767 - main_output_accuracy: 0.7235 - main_output_loss: 1.4713 - tof_gate_loss: 0.1827 - val_loss: 1.3912 - val_main_output_accuracy: 0.7539 - val_main_output_loss: 1.1242 - val_tof_gate_loss: 0.0273\n",
      "Epoch 26/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 559ms/step - loss: 1.6961 - main_output_accuracy: 0.7271 - main_output_loss: 1.4037 - tof_gate_loss: 0.1608 - val_loss: 1.4497 - val_main_output_accuracy: 0.7438 - val_main_output_loss: 1.1902 - val_tof_gate_loss: 0.0272\n",
      "Epoch 27/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.7631 - main_output_accuracy: 0.7217 - main_output_loss: 1.4707 - tof_gate_loss: 0.1982 - val_loss: 1.4394 - val_main_output_accuracy: 0.7295 - val_main_output_loss: 1.1822 - val_tof_gate_loss: 0.0354\n",
      "Epoch 28/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 557ms/step - loss: 1.7365 - main_output_accuracy: 0.7419 - main_output_loss: 1.4521 - tof_gate_loss: 0.1862 - val_loss: 1.4204 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.1734 - val_tof_gate_loss: 0.0240\n",
      "Epoch 29/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.7238 - main_output_accuracy: 0.7439 - main_output_loss: 1.4473 - tof_gate_loss: 0.1796 - val_loss: 1.3706 - val_main_output_accuracy: 0.7636 - val_main_output_loss: 1.1289 - val_tof_gate_loss: 0.0272\n",
      "Epoch 30/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 551ms/step - loss: 1.8147 - main_output_accuracy: 0.7332 - main_output_loss: 1.5335 - tof_gate_loss: 0.2347 - val_loss: 1.4008 - val_main_output_accuracy: 0.7662 - val_main_output_loss: 1.1657 - val_tof_gate_loss: 0.0333\n",
      "Epoch 31/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.7739 - main_output_accuracy: 0.7146 - main_output_loss: 1.5007 - tof_gate_loss: 0.2242 - val_loss: 1.4024 - val_main_output_accuracy: 0.7478 - val_main_output_loss: 1.1698 - val_tof_gate_loss: 0.0423\n",
      "Epoch 32/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 592ms/step - loss: 1.6461 - main_output_accuracy: 0.7701 - main_output_loss: 1.3879 - tof_gate_loss: 0.1780 - val_loss: 1.3592 - val_main_output_accuracy: 0.7601 - val_main_output_loss: 1.1354 - val_tof_gate_loss: 0.0239\n",
      "Epoch 33/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - loss: 1.6188 - main_output_accuracy: 0.7526 - main_output_loss: 1.3682 - tof_gate_loss: 0.1619 - val_loss: 1.4025 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.1814 - val_tof_gate_loss: 0.0290\n",
      "Epoch 34/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.6831 - main_output_accuracy: 0.7435 - main_output_loss: 1.4319 - tof_gate_loss: 0.1842 - val_loss: 1.3316 - val_main_output_accuracy: 0.7677 - val_main_output_loss: 1.1157 - val_tof_gate_loss: 0.0301\n",
      "Epoch 35/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.6768 - main_output_accuracy: 0.7490 - main_output_loss: 1.4292 - tof_gate_loss: 0.1933 - val_loss: 1.3638 - val_main_output_accuracy: 0.7519 - val_main_output_loss: 1.1502 - val_tof_gate_loss: 0.0422\n",
      "Epoch 36/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 565ms/step - loss: 1.5730 - main_output_accuracy: 0.7633 - main_output_loss: 1.3340 - tof_gate_loss: 0.1700 - val_loss: 1.3519 - val_main_output_accuracy: 0.7448 - val_main_output_loss: 1.1462 - val_tof_gate_loss: 0.0238\n",
      "Epoch 37/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 581ms/step - loss: 1.5866 - main_output_accuracy: 0.7791 - main_output_loss: 1.3511 - tof_gate_loss: 0.1724 - val_loss: 1.3768 - val_main_output_accuracy: 0.7504 - val_main_output_loss: 1.1734 - val_tof_gate_loss: 0.0244\n",
      "Epoch 38/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 563ms/step - loss: 1.6572 - main_output_accuracy: 0.7548 - main_output_loss: 1.4196 - tof_gate_loss: 0.2027 - val_loss: 1.3805 - val_main_output_accuracy: 0.7438 - val_main_output_loss: 1.1797 - val_tof_gate_loss: 0.0317\n",
      "Epoch 39/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 568ms/step - loss: 1.5210 - main_output_accuracy: 0.7944 - main_output_loss: 1.2969 - tof_gate_loss: 0.1556 - val_loss: 1.3251 - val_main_output_accuracy: 0.7646 - val_main_output_loss: 1.1290 - val_tof_gate_loss: 0.0285\n",
      "Epoch 40/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.6680 - main_output_accuracy: 0.7576 - main_output_loss: 1.4360 - tof_gate_loss: 0.2108 - val_loss: 1.3218 - val_main_output_accuracy: 0.7641 - val_main_output_loss: 1.1298 - val_tof_gate_loss: 0.0290\n",
      "Epoch 41/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.5259 - main_output_accuracy: 0.7945 - main_output_loss: 1.3074 - tof_gate_loss: 0.1566 - val_loss: 1.3104 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1207 - val_tof_gate_loss: 0.0272\n",
      "Epoch 42/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 563ms/step - loss: 1.6349 - main_output_accuracy: 0.7637 - main_output_loss: 1.4105 - tof_gate_loss: 0.2043 - val_loss: 1.3021 - val_main_output_accuracy: 0.7764 - val_main_output_loss: 1.1142 - val_tof_gate_loss: 0.0253\n",
      "Epoch 43/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 588ms/step - loss: 1.4854 - main_output_accuracy: 0.8119 - main_output_loss: 1.2746 - tof_gate_loss: 0.1479 - val_loss: 1.2794 - val_main_output_accuracy: 0.7820 - val_main_output_loss: 1.0959 - val_tof_gate_loss: 0.0299\n",
      "Epoch 44/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.5568 - main_output_accuracy: 0.7884 - main_output_loss: 1.3425 - tof_gate_loss: 0.1844 - val_loss: 1.3098 - val_main_output_accuracy: 0.7682 - val_main_output_loss: 1.1296 - val_tof_gate_loss: 0.0221\n",
      "Epoch 45/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 574ms/step - loss: 1.5080 - main_output_accuracy: 0.8048 - main_output_loss: 1.2983 - tof_gate_loss: 0.1744 - val_loss: 1.2681 - val_main_output_accuracy: 0.7840 - val_main_output_loss: 1.0913 - val_tof_gate_loss: 0.0205\n",
      "Epoch 46/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.5275 - main_output_accuracy: 0.8139 - main_output_loss: 1.3182 - tof_gate_loss: 0.1873 - val_loss: 1.2379 - val_main_output_accuracy: 0.7978 - val_main_output_loss: 1.0626 - val_tof_gate_loss: 0.0217\n",
      "Epoch 47/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.5270 - main_output_accuracy: 0.7907 - main_output_loss: 1.3211 - tof_gate_loss: 0.1820 - val_loss: 1.2868 - val_main_output_accuracy: 0.7738 - val_main_output_loss: 1.1142 - val_tof_gate_loss: 0.0168\n",
      "Epoch 48/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - loss: 1.5058 - main_output_accuracy: 0.7966 - main_output_loss: 1.3019 - tof_gate_loss: 0.1790 - val_loss: 1.2762 - val_main_output_accuracy: 0.7906 - val_main_output_loss: 1.1022 - val_tof_gate_loss: 0.0376\n",
      "Epoch 49/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 554ms/step - loss: 1.5541 - main_output_accuracy: 0.7821 - main_output_loss: 1.3498 - tof_gate_loss: 0.1941 - val_loss: 1.2531 - val_main_output_accuracy: 0.7850 - val_main_output_loss: 1.0842 - val_tof_gate_loss: 0.0251\n",
      "Epoch 50/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 601ms/step - loss: 1.4012 - main_output_accuracy: 0.8340 - main_output_loss: 1.2105 - tof_gate_loss: 0.1385 - val_loss: 1.2681 - val_main_output_accuracy: 0.7840 - val_main_output_loss: 1.0997 - val_tof_gate_loss: 0.0296\n",
      "Epoch 51/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - loss: 1.5951 - main_output_accuracy: 0.7852 - main_output_loss: 1.3915 - tof_gate_loss: 0.2106 - val_loss: 1.2493 - val_main_output_accuracy: 0.7962 - val_main_output_loss: 1.0838 - val_tof_gate_loss: 0.0265\n",
      "Epoch 52/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 581ms/step - loss: 1.3975 - main_output_accuracy: 0.8341 - main_output_loss: 1.2069 - tof_gate_loss: 0.1577 - val_loss: 1.3058 - val_main_output_accuracy: 0.7631 - val_main_output_loss: 1.1429 - val_tof_gate_loss: 0.0243\n",
      "Epoch 53/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 559ms/step - loss: 1.4993 - main_output_accuracy: 0.8115 - main_output_loss: 1.3064 - tof_gate_loss: 0.1797 - val_loss: 1.2609 - val_main_output_accuracy: 0.7784 - val_main_output_loss: 1.0987 - val_tof_gate_loss: 0.0271\n",
      "Epoch 54/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.3706 - main_output_accuracy: 0.8476 - main_output_loss: 1.1852 - tof_gate_loss: 0.1493 - val_loss: 1.2607 - val_main_output_accuracy: 0.7952 - val_main_output_loss: 1.1014 - val_tof_gate_loss: 0.0254\n",
      "Epoch 55/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 573ms/step - loss: 1.4403 - main_output_accuracy: 0.8264 - main_output_loss: 1.2543 - tof_gate_loss: 0.1601 - val_loss: 1.2681 - val_main_output_accuracy: 0.7779 - val_main_output_loss: 1.1105 - val_tof_gate_loss: 0.0166\n",
      "Epoch 56/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 574ms/step - loss: 1.3245 - main_output_accuracy: 0.8497 - main_output_loss: 1.1453 - tof_gate_loss: 0.1345 - val_loss: 1.2663 - val_main_output_accuracy: 0.7779 - val_main_output_loss: 1.1094 - val_tof_gate_loss: 0.0284\n",
      "Epoch 57/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.3428 - main_output_accuracy: 0.8415 - main_output_loss: 1.1656 - tof_gate_loss: 0.1333 - val_loss: 1.2605 - val_main_output_accuracy: 0.7794 - val_main_output_loss: 1.1058 - val_tof_gate_loss: 0.0191\n",
      "Epoch 58/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 572ms/step - loss: 1.4918 - main_output_accuracy: 0.8271 - main_output_loss: 1.3029 - tof_gate_loss: 0.1985 - val_loss: 1.2565 - val_main_output_accuracy: 0.7845 - val_main_output_loss: 1.1036 - val_tof_gate_loss: 0.0232\n",
      "Epoch 59/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.5103 - main_output_accuracy: 0.8028 - main_output_loss: 1.3251 - tof_gate_loss: 0.1840 - val_loss: 1.2689 - val_main_output_accuracy: 0.7825 - val_main_output_loss: 1.1154 - val_tof_gate_loss: 0.0229\n",
      "Epoch 60/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - loss: 1.3937 - main_output_accuracy: 0.8363 - main_output_loss: 1.2136 - tof_gate_loss: 0.1643 - val_loss: 1.2269 - val_main_output_accuracy: 0.7942 - val_main_output_loss: 1.0767 - val_tof_gate_loss: 0.0185\n",
      "Epoch 61/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 586ms/step - loss: 1.3313 - main_output_accuracy: 0.8562 - main_output_loss: 1.1557 - tof_gate_loss: 0.1494 - val_loss: 1.2546 - val_main_output_accuracy: 0.7993 - val_main_output_loss: 1.1042 - val_tof_gate_loss: 0.0222\n",
      "Epoch 62/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 1.4819 - main_output_accuracy: 0.8393 - main_output_loss: 1.2996 - tof_gate_loss: 0.1915 - val_loss: 1.2272 - val_main_output_accuracy: 0.8023 - val_main_output_loss: 1.0779 - val_tof_gate_loss: 0.0276\n",
      "Epoch 63/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 584ms/step - loss: 1.3611 - main_output_accuracy: 0.8544 - main_output_loss: 1.1880 - tof_gate_loss: 0.1519 - val_loss: 1.2109 - val_main_output_accuracy: 0.7978 - val_main_output_loss: 1.0637 - val_tof_gate_loss: 0.0234\n",
      "Epoch 64/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 577ms/step - loss: 1.4798 - main_output_accuracy: 0.8285 - main_output_loss: 1.2981 - tof_gate_loss: 0.2017 - val_loss: 1.2823 - val_main_output_accuracy: 0.7799 - val_main_output_loss: 1.1350 - val_tof_gate_loss: 0.0282\n",
      "Epoch 65/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 554ms/step - loss: 1.4334 - main_output_accuracy: 0.8336 - main_output_loss: 1.2567 - tof_gate_loss: 0.1812 - val_loss: 1.2025 - val_main_output_accuracy: 0.8105 - val_main_output_loss: 1.0589 - val_tof_gate_loss: 0.0177\n",
      "Epoch 66/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 565ms/step - loss: 1.3792 - main_output_accuracy: 0.8424 - main_output_loss: 1.2071 - tof_gate_loss: 0.1656 - val_loss: 1.2365 - val_main_output_accuracy: 0.7891 - val_main_output_loss: 1.0938 - val_tof_gate_loss: 0.0192\n",
      "Epoch 67/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 1.4574 - main_output_accuracy: 0.8376 - main_output_loss: 1.2806 - tof_gate_loss: 0.1948 - val_loss: 1.2462 - val_main_output_accuracy: 0.7881 - val_main_output_loss: 1.1025 - val_tof_gate_loss: 0.0208\n",
      "Epoch 68/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 1.3987 - main_output_accuracy: 0.8523 - main_output_loss: 1.2266 - tof_gate_loss: 0.1748 - val_loss: 1.2414 - val_main_output_accuracy: 0.7850 - val_main_output_loss: 1.1014 - val_tof_gate_loss: 0.0219\n",
      "Epoch 69/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 570ms/step - loss: 1.2550 - main_output_accuracy: 0.8645 - main_output_loss: 1.0932 - tof_gate_loss: 0.1281 - val_loss: 1.2157 - val_main_output_accuracy: 0.7983 - val_main_output_loss: 1.0758 - val_tof_gate_loss: 0.0189\n",
      "Epoch 70/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.3093 - main_output_accuracy: 0.8569 - main_output_loss: 1.1439 - tof_gate_loss: 0.1497 - val_loss: 1.2572 - val_main_output_accuracy: 0.7901 - val_main_output_loss: 1.1187 - val_tof_gate_loss: 0.0139\n",
      "Epoch 71/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 564ms/step - loss: 1.3251 - main_output_accuracy: 0.8675 - main_output_loss: 1.1600 - tof_gate_loss: 0.1532 - val_loss: 1.2735 - val_main_output_accuracy: 0.7871 - val_main_output_loss: 1.1343 - val_tof_gate_loss: 0.0166\n",
      "Epoch 72/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 563ms/step - loss: 1.3887 - main_output_accuracy: 0.8540 - main_output_loss: 1.2193 - tof_gate_loss: 0.1753 - val_loss: 1.2617 - val_main_output_accuracy: 0.7906 - val_main_output_loss: 1.1247 - val_tof_gate_loss: 0.0186\n",
      "Epoch 73/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 562ms/step - loss: 1.3286 - main_output_accuracy: 0.8698 - main_output_loss: 1.1632 - tof_gate_loss: 0.1625 - val_loss: 1.2189 - val_main_output_accuracy: 0.8044 - val_main_output_loss: 1.0812 - val_tof_gate_loss: 0.0211\n",
      "Epoch 74/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 586ms/step - loss: 1.4833 - main_output_accuracy: 0.8331 - main_output_loss: 1.3075 - tof_gate_loss: 0.2165 - val_loss: 1.2451 - val_main_output_accuracy: 0.7952 - val_main_output_loss: 1.1087 - val_tof_gate_loss: 0.0203\n",
      "Epoch 75/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 560ms/step - loss: 1.2840 - main_output_accuracy: 0.8752 - main_output_loss: 1.1243 - tof_gate_loss: 0.1414 - val_loss: 1.2507 - val_main_output_accuracy: 0.7942 - val_main_output_loss: 1.1145 - val_tof_gate_loss: 0.0185\n",
      "Epoch 76/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.3500 - main_output_accuracy: 0.8541 - main_output_loss: 1.1862 - tof_gate_loss: 0.1665 - val_loss: 1.2379 - val_main_output_accuracy: 0.8013 - val_main_output_loss: 1.1029 - val_tof_gate_loss: 0.0242\n",
      "Epoch 77/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 552ms/step - loss: 1.2349 - main_output_accuracy: 0.8912 - main_output_loss: 1.0796 - tof_gate_loss: 0.1272 - val_loss: 1.2133 - val_main_output_accuracy: 0.8110 - val_main_output_loss: 1.0781 - val_tof_gate_loss: 0.0229\n",
      "Epoch 78/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 551ms/step - loss: 1.2722 - main_output_accuracy: 0.8662 - main_output_loss: 1.1143 - tof_gate_loss: 0.1454 - val_loss: 1.2356 - val_main_output_accuracy: 0.8003 - val_main_output_loss: 1.1050 - val_tof_gate_loss: 0.0144\n",
      "Epoch 79/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 579ms/step - loss: 1.3419 - main_output_accuracy: 0.8546 - main_output_loss: 1.1823 - tof_gate_loss: 0.1585 - val_loss: 1.1894 - val_main_output_accuracy: 0.8222 - val_main_output_loss: 1.0584 - val_tof_gate_loss: 0.0147\n",
      "Epoch 80/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 1.3571 - main_output_accuracy: 0.8520 - main_output_loss: 1.1929 - tof_gate_loss: 0.1841 - val_loss: 1.1883 - val_main_output_accuracy: 0.8181 - val_main_output_loss: 1.0564 - val_tof_gate_loss: 0.0244\n",
      "Epoch 81/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 574ms/step - loss: 1.3164 - main_output_accuracy: 0.8647 - main_output_loss: 1.1593 - tof_gate_loss: 0.1519 - val_loss: 1.1949 - val_main_output_accuracy: 0.8115 - val_main_output_loss: 1.0634 - val_tof_gate_loss: 0.0222\n",
      "Epoch 82/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 566ms/step - loss: 1.3680 - main_output_accuracy: 0.8395 - main_output_loss: 1.2049 - tof_gate_loss: 0.1846 - val_loss: 1.2298 - val_main_output_accuracy: 0.8049 - val_main_output_loss: 1.0983 - val_tof_gate_loss: 0.0268\n",
      "Epoch 83/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 569ms/step - loss: 1.2261 - main_output_accuracy: 0.9004 - main_output_loss: 1.0727 - tof_gate_loss: 0.1392 - val_loss: 1.1980 - val_main_output_accuracy: 0.8146 - val_main_output_loss: 1.0681 - val_tof_gate_loss: 0.0230\n",
      "Epoch 84/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 574ms/step - loss: 1.2242 - main_output_accuracy: 0.8923 - main_output_loss: 1.0732 - tof_gate_loss: 0.1298 - val_loss: 1.2403 - val_main_output_accuracy: 0.8064 - val_main_output_loss: 1.1097 - val_tof_gate_loss: 0.0198\n",
      "Epoch 85/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 558ms/step - loss: 1.3201 - main_output_accuracy: 0.8487 - main_output_loss: 1.1635 - tof_gate_loss: 0.1598 - val_loss: 1.1996 - val_main_output_accuracy: 0.8161 - val_main_output_loss: 1.0728 - val_tof_gate_loss: 0.0147\n",
      "Epoch 86/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 597ms/step - loss: 1.3192 - main_output_accuracy: 0.8858 - main_output_loss: 1.1609 - tof_gate_loss: 0.1716 - val_loss: 1.2012 - val_main_output_accuracy: 0.8222 - val_main_output_loss: 1.0736 - val_tof_gate_loss: 0.0191\n",
      "Epoch 87/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 650ms/step - loss: 1.3749 - main_output_accuracy: 0.8830 - main_output_loss: 1.2115 - tof_gate_loss: 0.1999 - val_loss: 1.2185 - val_main_output_accuracy: 0.8023 - val_main_output_loss: 1.0915 - val_tof_gate_loss: 0.0182\n",
      "Epoch 88/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 617ms/step - loss: 1.2671 - main_output_accuracy: 0.8748 - main_output_loss: 1.1150 - tof_gate_loss: 0.1445 - val_loss: 1.2020 - val_main_output_accuracy: 0.8156 - val_main_output_loss: 1.0750 - val_tof_gate_loss: 0.0167\n",
      "Epoch 89/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 628ms/step - loss: 1.2619 - main_output_accuracy: 0.8832 - main_output_loss: 1.1092 - tof_gate_loss: 0.1501 - val_loss: 1.2386 - val_main_output_accuracy: 0.7988 - val_main_output_loss: 1.1114 - val_tof_gate_loss: 0.0177\n",
      "Epoch 90/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 606ms/step - loss: 1.2945 - main_output_accuracy: 0.9023 - main_output_loss: 1.1378 - tof_gate_loss: 0.1741 - val_loss: 1.2035 - val_main_output_accuracy: 0.8115 - val_main_output_loss: 1.0781 - val_tof_gate_loss: 0.0172\n",
      "Epoch 91/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 631ms/step - loss: 1.1785 - main_output_accuracy: 0.9022 - main_output_loss: 1.0318 - tof_gate_loss: 0.1290 - val_loss: 1.2108 - val_main_output_accuracy: 0.8156 - val_main_output_loss: 1.0873 - val_tof_gate_loss: 0.0173\n",
      "Epoch 92/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 615ms/step - loss: 1.2263 - main_output_accuracy: 0.8984 - main_output_loss: 1.0753 - tof_gate_loss: 0.1529 - val_loss: 1.1990 - val_main_output_accuracy: 0.8192 - val_main_output_loss: 1.0756 - val_tof_gate_loss: 0.0176\n",
      "Epoch 93/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 624ms/step - loss: 1.1987 - main_output_accuracy: 0.9003 - main_output_loss: 1.0512 - tof_gate_loss: 0.1369 - val_loss: 1.2016 - val_main_output_accuracy: 0.8186 - val_main_output_loss: 1.0778 - val_tof_gate_loss: 0.0167\n",
      "Epoch 94/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 640ms/step - loss: 1.4096 - main_output_accuracy: 0.8626 - main_output_loss: 1.2478 - tof_gate_loss: 0.2115 - val_loss: 1.2049 - val_main_output_accuracy: 0.8136 - val_main_output_loss: 1.0819 - val_tof_gate_loss: 0.0165\n",
      "Epoch 95/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 635ms/step - loss: 1.2176 - main_output_accuracy: 0.8852 - main_output_loss: 1.0698 - tof_gate_loss: 0.1450 - val_loss: 1.2286 - val_main_output_accuracy: 0.8079 - val_main_output_loss: 1.1071 - val_tof_gate_loss: 0.0152\n",
      "Epoch 96/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 632ms/step - loss: 1.2252 - main_output_accuracy: 0.9016 - main_output_loss: 1.0769 - tof_gate_loss: 0.1500 - val_loss: 1.2438 - val_main_output_accuracy: 0.8018 - val_main_output_loss: 1.1211 - val_tof_gate_loss: 0.0159\n",
      "Epoch 97/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 652ms/step - loss: 1.2121 - main_output_accuracy: 0.9061 - main_output_loss: 1.0659 - tof_gate_loss: 0.1407 - val_loss: 1.2205 - val_main_output_accuracy: 0.8090 - val_main_output_loss: 1.0984 - val_tof_gate_loss: 0.0156\n",
      "Epoch 98/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 648ms/step - loss: 1.2379 - main_output_accuracy: 0.9038 - main_output_loss: 1.0890 - tof_gate_loss: 0.1575 - val_loss: 1.2182 - val_main_output_accuracy: 0.8125 - val_main_output_loss: 1.0959 - val_tof_gate_loss: 0.0204\n",
      "Epoch 99/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 641ms/step - loss: 1.2052 - main_output_accuracy: 0.9019 - main_output_loss: 1.0600 - tof_gate_loss: 0.1409 - val_loss: 1.1920 - val_main_output_accuracy: 0.8181 - val_main_output_loss: 1.0716 - val_tof_gate_loss: 0.0168\n",
      "--- Training complete. Applying EMA weights for evaluation. ---\n",
      "EMA Callback: EMA weights have been applied to the model.\n",
      "--- Fold 2 Best Epoch: 79 ---\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step\n",
      "Fold 2 Accuracy: 0.8293\n",
      "\n",
      "=== Fold 3/4 for hybrid_head_model ===\n",
      "Size of X_train: (57, 106)\n",
      "LR Scheduler: 92 steps per epoch, 13800 total decay steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA Callback: EMA weights initialized.\n",
      "Epoch 1/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 635ms/step - loss: 4.0036 - main_output_accuracy: 0.1155 - main_output_loss: 2.9951 - tof_gate_loss: 0.4785 - val_loss: 3.4079 - val_main_output_accuracy: 0.2620 - val_main_output_loss: 2.4583 - val_tof_gate_loss: 0.3660\n",
      "Epoch 2/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 592ms/step - loss: 3.3718 - main_output_accuracy: 0.2483 - main_output_loss: 2.4479 - tof_gate_loss: 0.3145 - val_loss: 2.8090 - val_main_output_accuracy: 0.4179 - val_main_output_loss: 1.9547 - val_tof_gate_loss: 0.1954\n",
      "Epoch 3/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 622ms/step - loss: 3.1182 - main_output_accuracy: 0.3083 - main_output_loss: 2.2703 - tof_gate_loss: 0.2460 - val_loss: 2.5919 - val_main_output_accuracy: 0.4567 - val_main_output_loss: 1.8143 - val_tof_gate_loss: 0.1225\n",
      "Epoch 4/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 630ms/step - loss: 2.8796 - main_output_accuracy: 0.3919 - main_output_loss: 2.0962 - tof_gate_loss: 0.2264 - val_loss: 2.4902 - val_main_output_accuracy: 0.4908 - val_main_output_loss: 1.7749 - val_tof_gate_loss: 0.0902\n",
      "Epoch 5/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 614ms/step - loss: 2.7585 - main_output_accuracy: 0.4470 - main_output_loss: 2.0303 - tof_gate_loss: 0.2284 - val_loss: 2.1792 - val_main_output_accuracy: 0.5810 - val_main_output_loss: 1.5230 - val_tof_gate_loss: 0.0538\n",
      "Epoch 6/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 636ms/step - loss: 2.5863 - main_output_accuracy: 0.4774 - main_output_loss: 1.9124 - tof_gate_loss: 0.2067 - val_loss: 2.1387 - val_main_output_accuracy: 0.5912 - val_main_output_loss: 1.5271 - val_tof_gate_loss: 0.0541\n",
      "Epoch 7/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 641ms/step - loss: 2.4672 - main_output_accuracy: 0.5104 - main_output_loss: 1.8411 - tof_gate_loss: 0.1866 - val_loss: 1.9933 - val_main_output_accuracy: 0.6193 - val_main_output_loss: 1.4225 - val_tof_gate_loss: 0.0551\n",
      "Epoch 8/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 644ms/step - loss: 2.4439 - main_output_accuracy: 0.5215 - main_output_loss: 1.8529 - tof_gate_loss: 0.2046 - val_loss: 1.8759 - val_main_output_accuracy: 0.6621 - val_main_output_loss: 1.3426 - val_tof_gate_loss: 0.0426\n",
      "Epoch 9/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 710ms/step - loss: 2.3759 - main_output_accuracy: 0.5452 - main_output_loss: 1.8171 - tof_gate_loss: 0.2120 - val_loss: 1.8331 - val_main_output_accuracy: 0.6580 - val_main_output_loss: 1.3306 - val_tof_gate_loss: 0.0392\n",
      "Epoch 10/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 695ms/step - loss: 2.2725 - main_output_accuracy: 0.5607 - main_output_loss: 1.7484 - tof_gate_loss: 0.1864 - val_loss: 1.8362 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.3610 - val_tof_gate_loss: 0.0337\n",
      "Epoch 11/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 660ms/step - loss: 2.2584 - main_output_accuracy: 0.5574 - main_output_loss: 1.7546 - tof_gate_loss: 0.2175 - val_loss: 1.7938 - val_main_output_accuracy: 0.6427 - val_main_output_loss: 1.3388 - val_tof_gate_loss: 0.0572\n",
      "Epoch 12/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 639ms/step - loss: 2.2358 - main_output_accuracy: 0.5923 - main_output_loss: 1.7533 - tof_gate_loss: 0.2294 - val_loss: 1.8242 - val_main_output_accuracy: 0.6427 - val_main_output_loss: 1.3904 - val_tof_gate_loss: 0.0617\n",
      "Epoch 13/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 620ms/step - loss: 2.2282 - main_output_accuracy: 0.5854 - main_output_loss: 1.7685 - tof_gate_loss: 0.2217 - val_loss: 1.6813 - val_main_output_accuracy: 0.6784 - val_main_output_loss: 1.2649 - val_tof_gate_loss: 0.0716\n",
      "Epoch 14/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 648ms/step - loss: 2.1822 - main_output_accuracy: 0.5969 - main_output_loss: 1.7410 - tof_gate_loss: 0.2223 - val_loss: 1.6120 - val_main_output_accuracy: 0.7090 - val_main_output_loss: 1.2195 - val_tof_gate_loss: 0.0391\n",
      "Epoch 15/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 621ms/step - loss: 2.0544 - main_output_accuracy: 0.6186 - main_output_loss: 1.6382 - tof_gate_loss: 0.1834 - val_loss: 1.6252 - val_main_output_accuracy: 0.7013 - val_main_output_loss: 1.2448 - val_tof_gate_loss: 0.0545\n",
      "Epoch 16/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 644ms/step - loss: 2.1562 - main_output_accuracy: 0.6002 - main_output_loss: 1.7422 - tof_gate_loss: 0.2501 - val_loss: 1.6032 - val_main_output_accuracy: 0.6957 - val_main_output_loss: 1.2407 - val_tof_gate_loss: 0.0411\n",
      "Epoch 17/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 633ms/step - loss: 2.0589 - main_output_accuracy: 0.6381 - main_output_loss: 1.6641 - tof_gate_loss: 0.2247 - val_loss: 1.5541 - val_main_output_accuracy: 0.7018 - val_main_output_loss: 1.2081 - val_tof_gate_loss: 0.0222\n",
      "Epoch 18/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 630ms/step - loss: 1.9505 - main_output_accuracy: 0.6448 - main_output_loss: 1.5763 - tof_gate_loss: 0.1813 - val_loss: 1.5526 - val_main_output_accuracy: 0.7120 - val_main_output_loss: 1.2131 - val_tof_gate_loss: 0.0445\n",
      "Epoch 19/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 630ms/step - loss: 1.9705 - main_output_accuracy: 0.6452 - main_output_loss: 1.6055 - tof_gate_loss: 0.1960 - val_loss: 1.4943 - val_main_output_accuracy: 0.7339 - val_main_output_loss: 1.1684 - val_tof_gate_loss: 0.0421\n",
      "Epoch 20/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 643ms/step - loss: 1.9272 - main_output_accuracy: 0.6675 - main_output_loss: 1.5739 - tof_gate_loss: 0.1952 - val_loss: 1.5506 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2351 - val_tof_gate_loss: 0.0368\n",
      "Epoch 21/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 624ms/step - loss: 1.8418 - main_output_accuracy: 0.6710 - main_output_loss: 1.5030 - tof_gate_loss: 0.1709 - val_loss: 1.4733 - val_main_output_accuracy: 0.7294 - val_main_output_loss: 1.1673 - val_tof_gate_loss: 0.0399\n",
      "Epoch 22/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 639ms/step - loss: 1.9199 - main_output_accuracy: 0.6705 - main_output_loss: 1.5835 - tof_gate_loss: 0.2082 - val_loss: 1.4852 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.1901 - val_tof_gate_loss: 0.0267\n",
      "Epoch 23/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 642ms/step - loss: 1.7845 - main_output_accuracy: 0.6945 - main_output_loss: 1.4661 - tof_gate_loss: 0.1624 - val_loss: 1.4371 - val_main_output_accuracy: 0.7411 - val_main_output_loss: 1.1493 - val_tof_gate_loss: 0.0316\n",
      "Epoch 24/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 632ms/step - loss: 1.8152 - main_output_accuracy: 0.6931 - main_output_loss: 1.5013 - tof_gate_loss: 0.1807 - val_loss: 1.4501 - val_main_output_accuracy: 0.7339 - val_main_output_loss: 1.1684 - val_tof_gate_loss: 0.0448\n",
      "Epoch 25/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 631ms/step - loss: 1.7921 - main_output_accuracy: 0.7198 - main_output_loss: 1.4862 - tof_gate_loss: 0.1818 - val_loss: 1.3909 - val_main_output_accuracy: 0.7513 - val_main_output_loss: 1.1198 - val_tof_gate_loss: 0.0370\n",
      "Epoch 26/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 641ms/step - loss: 1.7919 - main_output_accuracy: 0.7025 - main_output_loss: 1.4924 - tof_gate_loss: 0.1890 - val_loss: 1.4058 - val_main_output_accuracy: 0.7457 - val_main_output_loss: 1.1422 - val_tof_gate_loss: 0.0311\n",
      "Epoch 27/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 640ms/step - loss: 1.8195 - main_output_accuracy: 0.7197 - main_output_loss: 1.5241 - tof_gate_loss: 0.2034 - val_loss: 1.3800 - val_main_output_accuracy: 0.7615 - val_main_output_loss: 1.1221 - val_tof_gate_loss: 0.0350\n",
      "Epoch 28/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 650ms/step - loss: 1.7005 - main_output_accuracy: 0.7381 - main_output_loss: 1.4176 - tof_gate_loss: 0.1719 - val_loss: 1.4138 - val_main_output_accuracy: 0.7431 - val_main_output_loss: 1.1611 - val_tof_gate_loss: 0.0356\n",
      "Epoch 29/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 642ms/step - loss: 1.7171 - main_output_accuracy: 0.7328 - main_output_loss: 1.4386 - tof_gate_loss: 0.1815 - val_loss: 1.3915 - val_main_output_accuracy: 0.7533 - val_main_output_loss: 1.1419 - val_tof_gate_loss: 0.0474\n",
      "Epoch 30/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 644ms/step - loss: 1.6628 - main_output_accuracy: 0.7409 - main_output_loss: 1.3943 - tof_gate_loss: 0.1611 - val_loss: 1.4397 - val_main_output_accuracy: 0.7355 - val_main_output_loss: 1.1944 - val_tof_gate_loss: 0.0540\n",
      "Epoch 31/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 647ms/step - loss: 1.6642 - main_output_accuracy: 0.7464 - main_output_loss: 1.3969 - tof_gate_loss: 0.1807 - val_loss: 1.4054 - val_main_output_accuracy: 0.7401 - val_main_output_loss: 1.1715 - val_tof_gate_loss: 0.0260\n",
      "Epoch 32/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 650ms/step - loss: 1.7089 - main_output_accuracy: 0.7386 - main_output_loss: 1.4468 - tof_gate_loss: 0.1797 - val_loss: 1.3519 - val_main_output_accuracy: 0.7645 - val_main_output_loss: 1.1218 - val_tof_gate_loss: 0.0268\n",
      "Epoch 33/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 637ms/step - loss: 1.6514 - main_output_accuracy: 0.7577 - main_output_loss: 1.3954 - tof_gate_loss: 0.1736 - val_loss: 1.3884 - val_main_output_accuracy: 0.7564 - val_main_output_loss: 1.1573 - val_tof_gate_loss: 0.0610\n",
      "Epoch 34/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 634ms/step - loss: 1.6720 - main_output_accuracy: 0.7447 - main_output_loss: 1.4178 - tof_gate_loss: 0.1890 - val_loss: 1.3319 - val_main_output_accuracy: 0.7727 - val_main_output_loss: 1.1069 - val_tof_gate_loss: 0.0536\n",
      "Epoch 35/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 617ms/step - loss: 1.5487 - main_output_accuracy: 0.7700 - main_output_loss: 1.3073 - tof_gate_loss: 0.1472 - val_loss: 1.3190 - val_main_output_accuracy: 0.7783 - val_main_output_loss: 1.0998 - val_tof_gate_loss: 0.0412\n",
      "Epoch 36/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 636ms/step - loss: 1.5983 - main_output_accuracy: 0.7605 - main_output_loss: 1.3563 - tof_gate_loss: 0.1711 - val_loss: 1.2903 - val_main_output_accuracy: 0.7778 - val_main_output_loss: 1.0762 - val_tof_gate_loss: 0.0414\n",
      "Epoch 37/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 632ms/step - loss: 1.6618 - main_output_accuracy: 0.7691 - main_output_loss: 1.4180 - tof_gate_loss: 0.1999 - val_loss: 1.3166 - val_main_output_accuracy: 0.7681 - val_main_output_loss: 1.1058 - val_tof_gate_loss: 0.0380\n",
      "Epoch 38/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 619ms/step - loss: 1.5784 - main_output_accuracy: 0.7808 - main_output_loss: 1.3429 - tof_gate_loss: 0.1781 - val_loss: 1.2805 - val_main_output_accuracy: 0.7798 - val_main_output_loss: 1.0757 - val_tof_gate_loss: 0.0261\n",
      "Epoch 39/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 641ms/step - loss: 1.5503 - main_output_accuracy: 0.7730 - main_output_loss: 1.3213 - tof_gate_loss: 0.1612 - val_loss: 1.2875 - val_main_output_accuracy: 0.7686 - val_main_output_loss: 1.0864 - val_tof_gate_loss: 0.0321\n",
      "Epoch 40/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 646ms/step - loss: 1.5218 - main_output_accuracy: 0.7835 - main_output_loss: 1.2966 - tof_gate_loss: 0.1601 - val_loss: 1.3016 - val_main_output_accuracy: 0.7706 - val_main_output_loss: 1.1019 - val_tof_gate_loss: 0.0383\n",
      "Epoch 41/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 636ms/step - loss: 1.5720 - main_output_accuracy: 0.7901 - main_output_loss: 1.3455 - tof_gate_loss: 0.1835 - val_loss: 1.2520 - val_main_output_accuracy: 0.7931 - val_main_output_loss: 1.0541 - val_tof_gate_loss: 0.0373\n",
      "Epoch 42/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 640ms/step - loss: 1.6471 - main_output_accuracy: 0.7803 - main_output_loss: 1.4193 - tof_gate_loss: 0.2038 - val_loss: 1.2556 - val_main_output_accuracy: 0.7778 - val_main_output_loss: 1.0628 - val_tof_gate_loss: 0.0317\n",
      "Epoch 43/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 635ms/step - loss: 1.4956 - main_output_accuracy: 0.8184 - main_output_loss: 1.2806 - tof_gate_loss: 0.1554 - val_loss: 1.2659 - val_main_output_accuracy: 0.7870 - val_main_output_loss: 1.0760 - val_tof_gate_loss: 0.0261\n",
      "Epoch 44/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 628ms/step - loss: 1.5389 - main_output_accuracy: 0.7899 - main_output_loss: 1.3249 - tof_gate_loss: 0.1637 - val_loss: 1.2689 - val_main_output_accuracy: 0.7819 - val_main_output_loss: 1.0835 - val_tof_gate_loss: 0.0253\n",
      "Epoch 45/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 637ms/step - loss: 1.4071 - main_output_accuracy: 0.8275 - main_output_loss: 1.2016 - tof_gate_loss: 0.1336 - val_loss: 1.3043 - val_main_output_accuracy: 0.7681 - val_main_output_loss: 1.1167 - val_tof_gate_loss: 0.0391\n",
      "Epoch 46/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 625ms/step - loss: 1.5602 - main_output_accuracy: 0.8059 - main_output_loss: 1.3467 - tof_gate_loss: 0.1853 - val_loss: 1.2496 - val_main_output_accuracy: 0.7824 - val_main_output_loss: 1.0692 - val_tof_gate_loss: 0.0193\n",
      "Epoch 47/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 656ms/step - loss: 1.5960 - main_output_accuracy: 0.7823 - main_output_loss: 1.3823 - tof_gate_loss: 0.2000 - val_loss: 1.2831 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.0977 - val_tof_gate_loss: 0.0531\n",
      "Epoch 48/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 636ms/step - loss: 1.6003 - main_output_accuracy: 0.7625 - main_output_loss: 1.3864 - tof_gate_loss: 0.2110 - val_loss: 1.2642 - val_main_output_accuracy: 0.7829 - val_main_output_loss: 1.0861 - val_tof_gate_loss: 0.0310\n",
      "Epoch 49/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 632ms/step - loss: 1.5685 - main_output_accuracy: 0.7975 - main_output_loss: 1.3603 - tof_gate_loss: 0.1924 - val_loss: 1.2445 - val_main_output_accuracy: 0.7885 - val_main_output_loss: 1.0702 - val_tof_gate_loss: 0.0257\n",
      "Epoch 50/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 634ms/step - loss: 1.5412 - main_output_accuracy: 0.8023 - main_output_loss: 1.3367 - tof_gate_loss: 0.1873 - val_loss: 1.2599 - val_main_output_accuracy: 0.7773 - val_main_output_loss: 1.0854 - val_tof_gate_loss: 0.0364\n",
      "Epoch 51/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 630ms/step - loss: 1.4536 - main_output_accuracy: 0.8311 - main_output_loss: 1.2562 - tof_gate_loss: 0.1619 - val_loss: 1.2393 - val_main_output_accuracy: 0.7905 - val_main_output_loss: 1.0656 - val_tof_gate_loss: 0.0400\n",
      "Epoch 52/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 640ms/step - loss: 1.4123 - main_output_accuracy: 0.8148 - main_output_loss: 1.2187 - tof_gate_loss: 0.1511 - val_loss: 1.2406 - val_main_output_accuracy: 0.7977 - val_main_output_loss: 1.0711 - val_tof_gate_loss: 0.0242\n",
      "Epoch 53/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 651ms/step - loss: 1.4187 - main_output_accuracy: 0.8326 - main_output_loss: 1.2276 - tof_gate_loss: 0.1491 - val_loss: 1.2399 - val_main_output_accuracy: 0.7966 - val_main_output_loss: 1.0738 - val_tof_gate_loss: 0.0239\n",
      "Epoch 54/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 665ms/step - loss: 1.5231 - main_output_accuracy: 0.7992 - main_output_loss: 1.3247 - tof_gate_loss: 0.1973 - val_loss: 1.2187 - val_main_output_accuracy: 0.7931 - val_main_output_loss: 1.0527 - val_tof_gate_loss: 0.0303\n",
      "Epoch 55/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 642ms/step - loss: 1.4733 - main_output_accuracy: 0.8081 - main_output_loss: 1.2784 - tof_gate_loss: 0.1871 - val_loss: 1.2665 - val_main_output_accuracy: 0.7798 - val_main_output_loss: 1.1017 - val_tof_gate_loss: 0.0290\n",
      "Epoch 56/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 646ms/step - loss: 1.3686 - main_output_accuracy: 0.8441 - main_output_loss: 1.1833 - tof_gate_loss: 0.1473 - val_loss: 1.2744 - val_main_output_accuracy: 0.7793 - val_main_output_loss: 1.1121 - val_tof_gate_loss: 0.0297\n",
      "Epoch 57/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 647ms/step - loss: 1.3833 - main_output_accuracy: 0.8465 - main_output_loss: 1.2004 - tof_gate_loss: 0.1429 - val_loss: 1.2156 - val_main_output_accuracy: 0.8073 - val_main_output_loss: 1.0550 - val_tof_gate_loss: 0.0244\n",
      "Epoch 58/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 647ms/step - loss: 1.5364 - main_output_accuracy: 0.8303 - main_output_loss: 1.3442 - tof_gate_loss: 0.1967 - val_loss: 1.2218 - val_main_output_accuracy: 0.8124 - val_main_output_loss: 1.0599 - val_tof_gate_loss: 0.0366\n",
      "Epoch 59/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 654ms/step - loss: 1.5170 - main_output_accuracy: 0.8266 - main_output_loss: 1.3233 - tof_gate_loss: 0.2111 - val_loss: 1.2490 - val_main_output_accuracy: 0.7895 - val_main_output_loss: 1.0902 - val_tof_gate_loss: 0.0291\n",
      "Epoch 60/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 670ms/step - loss: 1.3884 - main_output_accuracy: 0.8345 - main_output_loss: 1.2049 - tof_gate_loss: 0.1675 - val_loss: 1.2153 - val_main_output_accuracy: 0.7941 - val_main_output_loss: 1.0571 - val_tof_gate_loss: 0.0368\n",
      "Epoch 61/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 663ms/step - loss: 1.5383 - main_output_accuracy: 0.8126 - main_output_loss: 1.3475 - tof_gate_loss: 0.2109 - val_loss: 1.2113 - val_main_output_accuracy: 0.7982 - val_main_output_loss: 1.0551 - val_tof_gate_loss: 0.0295\n",
      "Epoch 62/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 655ms/step - loss: 1.4877 - main_output_accuracy: 0.8335 - main_output_loss: 1.3031 - tof_gate_loss: 0.1863 - val_loss: 1.1802 - val_main_output_accuracy: 0.8140 - val_main_output_loss: 1.0280 - val_tof_gate_loss: 0.0205\n",
      "Epoch 63/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 638ms/step - loss: 1.2968 - main_output_accuracy: 0.8637 - main_output_loss: 1.1238 - tof_gate_loss: 0.1365 - val_loss: 1.2491 - val_main_output_accuracy: 0.7915 - val_main_output_loss: 1.0911 - val_tof_gate_loss: 0.0490\n",
      "Epoch 64/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 648ms/step - loss: 1.3985 - main_output_accuracy: 0.8447 - main_output_loss: 1.2200 - tof_gate_loss: 0.1640 - val_loss: 1.1924 - val_main_output_accuracy: 0.8078 - val_main_output_loss: 1.0417 - val_tof_gate_loss: 0.0203\n",
      "Epoch 65/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 637ms/step - loss: 1.3614 - main_output_accuracy: 0.8536 - main_output_loss: 1.1852 - tof_gate_loss: 0.1620 - val_loss: 1.2093 - val_main_output_accuracy: 0.8053 - val_main_output_loss: 1.0591 - val_tof_gate_loss: 0.0268\n",
      "Epoch 66/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 642ms/step - loss: 1.3753 - main_output_accuracy: 0.8318 - main_output_loss: 1.1985 - tof_gate_loss: 0.1727 - val_loss: 1.2211 - val_main_output_accuracy: 0.8022 - val_main_output_loss: 1.0678 - val_tof_gate_loss: 0.0482\n",
      "Epoch 67/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 644ms/step - loss: 1.3106 - main_output_accuracy: 0.8708 - main_output_loss: 1.1398 - tof_gate_loss: 0.1479 - val_loss: 1.2081 - val_main_output_accuracy: 0.8043 - val_main_output_loss: 1.0622 - val_tof_gate_loss: 0.0197\n",
      "Epoch 68/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 638ms/step - loss: 1.2771 - main_output_accuracy: 0.8699 - main_output_loss: 1.1106 - tof_gate_loss: 0.1328 - val_loss: 1.1898 - val_main_output_accuracy: 0.8135 - val_main_output_loss: 1.0408 - val_tof_gate_loss: 0.0379\n",
      "Epoch 69/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 635ms/step - loss: 1.3706 - main_output_accuracy: 0.8586 - main_output_loss: 1.1967 - tof_gate_loss: 0.1736 - val_loss: 1.2239 - val_main_output_accuracy: 0.7931 - val_main_output_loss: 1.0778 - val_tof_gate_loss: 0.0302\n",
      "Epoch 70/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 641ms/step - loss: 1.3235 - main_output_accuracy: 0.8575 - main_output_loss: 1.1557 - tof_gate_loss: 0.1479 - val_loss: 1.1832 - val_main_output_accuracy: 0.8135 - val_main_output_loss: 1.0396 - val_tof_gate_loss: 0.0252\n",
      "Epoch 71/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 651ms/step - loss: 1.2597 - main_output_accuracy: 0.8799 - main_output_loss: 1.0947 - tof_gate_loss: 0.1396 - val_loss: 1.1936 - val_main_output_accuracy: 0.8114 - val_main_output_loss: 1.0496 - val_tof_gate_loss: 0.0263\n",
      "Epoch 72/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 609ms/step - loss: 1.3906 - main_output_accuracy: 0.8626 - main_output_loss: 1.2188 - tof_gate_loss: 0.1770 - val_loss: 1.2004 - val_main_output_accuracy: 0.8119 - val_main_output_loss: 1.0587 - val_tof_gate_loss: 0.0207\n",
      "Epoch 73/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 597ms/step - loss: 1.3762 - main_output_accuracy: 0.8691 - main_output_loss: 1.2073 - tof_gate_loss: 0.1659 - val_loss: 1.1726 - val_main_output_accuracy: 0.8155 - val_main_output_loss: 1.0316 - val_tof_gate_loss: 0.0216\n",
      "Epoch 74/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 606ms/step - loss: 1.4070 - main_output_accuracy: 0.8316 - main_output_loss: 1.2344 - tof_gate_loss: 0.1908 - val_loss: 1.1876 - val_main_output_accuracy: 0.8191 - val_main_output_loss: 1.0476 - val_tof_gate_loss: 0.0225\n",
      "Epoch 75/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 589ms/step - loss: 1.3073 - main_output_accuracy: 0.8713 - main_output_loss: 1.1431 - tof_gate_loss: 0.1527 - val_loss: 1.1978 - val_main_output_accuracy: 0.8109 - val_main_output_loss: 1.0594 - val_tof_gate_loss: 0.0195\n",
      "Epoch 76/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 589ms/step - loss: 1.4271 - main_output_accuracy: 0.8313 - main_output_loss: 1.2563 - tof_gate_loss: 0.1897 - val_loss: 1.1711 - val_main_output_accuracy: 0.8170 - val_main_output_loss: 1.0330 - val_tof_gate_loss: 0.0236\n",
      "Epoch 77/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 600ms/step - loss: 1.3811 - main_output_accuracy: 0.8597 - main_output_loss: 1.2123 - tof_gate_loss: 0.1856 - val_loss: 1.1850 - val_main_output_accuracy: 0.8170 - val_main_output_loss: 1.0472 - val_tof_gate_loss: 0.0222\n",
      "Epoch 78/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 601ms/step - loss: 1.2189 - main_output_accuracy: 0.8898 - main_output_loss: 1.0622 - tof_gate_loss: 0.1290 - val_loss: 1.1734 - val_main_output_accuracy: 0.8262 - val_main_output_loss: 1.0354 - val_tof_gate_loss: 0.0257\n",
      "Epoch 79/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 644ms/step - loss: 1.2413 - main_output_accuracy: 0.8921 - main_output_loss: 1.0839 - tof_gate_loss: 0.1356 - val_loss: 1.1778 - val_main_output_accuracy: 0.8155 - val_main_output_loss: 1.0422 - val_tof_gate_loss: 0.0209\n",
      "Epoch 80/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 657ms/step - loss: 1.3041 - main_output_accuracy: 0.8772 - main_output_loss: 1.1449 - tof_gate_loss: 0.1500 - val_loss: 1.2459 - val_main_output_accuracy: 0.7951 - val_main_output_loss: 1.1109 - val_tof_gate_loss: 0.0295\n",
      "Epoch 81/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 613ms/step - loss: 1.3046 - main_output_accuracy: 0.8740 - main_output_loss: 1.1433 - tof_gate_loss: 0.1642 - val_loss: 1.1961 - val_main_output_accuracy: 0.8129 - val_main_output_loss: 1.0604 - val_tof_gate_loss: 0.0269\n",
      "Epoch 82/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 624ms/step - loss: 1.2775 - main_output_accuracy: 0.8944 - main_output_loss: 1.1197 - tof_gate_loss: 0.1506 - val_loss: 1.1798 - val_main_output_accuracy: 0.8150 - val_main_output_loss: 1.0463 - val_tof_gate_loss: 0.0204\n",
      "Epoch 83/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 628ms/step - loss: 1.2912 - main_output_accuracy: 0.8858 - main_output_loss: 1.1328 - tof_gate_loss: 0.1569 - val_loss: 1.1964 - val_main_output_accuracy: 0.8170 - val_main_output_loss: 1.0633 - val_tof_gate_loss: 0.0263\n",
      "Epoch 84/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 622ms/step - loss: 1.3983 - main_output_accuracy: 0.8270 - main_output_loss: 1.2340 - tof_gate_loss: 0.1895 - val_loss: 1.1853 - val_main_output_accuracy: 0.8135 - val_main_output_loss: 1.0529 - val_tof_gate_loss: 0.0167\n",
      "Epoch 85/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 632ms/step - loss: 1.2131 - main_output_accuracy: 0.8912 - main_output_loss: 1.0620 - tof_gate_loss: 0.1268 - val_loss: 1.1849 - val_main_output_accuracy: 0.8135 - val_main_output_loss: 1.0532 - val_tof_gate_loss: 0.0214\n",
      "Epoch 86/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 612ms/step - loss: 1.3245 - main_output_accuracy: 0.8756 - main_output_loss: 1.1661 - tof_gate_loss: 0.1672 - val_loss: 1.1867 - val_main_output_accuracy: 0.8094 - val_main_output_loss: 1.0568 - val_tof_gate_loss: 0.0172\n",
      "Epoch 87/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 646ms/step - loss: 1.3297 - main_output_accuracy: 0.8630 - main_output_loss: 1.1707 - tof_gate_loss: 0.1736 - val_loss: 1.1824 - val_main_output_accuracy: 0.8175 - val_main_output_loss: 1.0514 - val_tof_gate_loss: 0.0234\n",
      "Epoch 88/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 625ms/step - loss: 1.2464 - main_output_accuracy: 0.8917 - main_output_loss: 1.0941 - tof_gate_loss: 0.1410 - val_loss: 1.1653 - val_main_output_accuracy: 0.8242 - val_main_output_loss: 1.0355 - val_tof_gate_loss: 0.0204\n",
      "Epoch 89/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 634ms/step - loss: 1.2900 - main_output_accuracy: 0.8634 - main_output_loss: 1.1354 - tof_gate_loss: 0.1567 - val_loss: 1.2135 - val_main_output_accuracy: 0.8180 - val_main_output_loss: 1.0845 - val_tof_gate_loss: 0.0191\n",
      "Epoch 90/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 697ms/step - loss: 1.2869 - main_output_accuracy: 0.8752 - main_output_loss: 1.1342 - tof_gate_loss: 0.1491 - val_loss: 1.1827 - val_main_output_accuracy: 0.8257 - val_main_output_loss: 1.0546 - val_tof_gate_loss: 0.0199\n",
      "Epoch 91/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 601ms/step - loss: 1.2803 - main_output_accuracy: 0.8829 - main_output_loss: 1.1254 - tof_gate_loss: 0.1622 - val_loss: 1.2018 - val_main_output_accuracy: 0.8129 - val_main_output_loss: 1.0728 - val_tof_gate_loss: 0.0228\n",
      "Epoch 92/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 620ms/step - loss: 1.3325 - main_output_accuracy: 0.8726 - main_output_loss: 1.1767 - tof_gate_loss: 0.1698 - val_loss: 1.1739 - val_main_output_accuracy: 0.8206 - val_main_output_loss: 1.0441 - val_tof_gate_loss: 0.0309\n",
      "Epoch 93/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 604ms/step - loss: 1.2700 - main_output_accuracy: 0.8817 - main_output_loss: 1.1191 - tof_gate_loss: 0.1488 - val_loss: 1.1823 - val_main_output_accuracy: 0.8145 - val_main_output_loss: 1.0557 - val_tof_gate_loss: 0.0200\n",
      "Epoch 94/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 604ms/step - loss: 1.3304 - main_output_accuracy: 0.8881 - main_output_loss: 1.1753 - tof_gate_loss: 0.1722 - val_loss: 1.1744 - val_main_output_accuracy: 0.8282 - val_main_output_loss: 1.0478 - val_tof_gate_loss: 0.0239\n",
      "Epoch 95/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 769ms/step - loss: 1.3725 - main_output_accuracy: 0.8703 - main_output_loss: 1.2134 - tof_gate_loss: 0.1955 - val_loss: 1.1763 - val_main_output_accuracy: 0.8226 - val_main_output_loss: 1.0482 - val_tof_gate_loss: 0.0297\n",
      "Epoch 96/150\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 670ms/step - loss: 1.3610 - main_output_accuracy: 0.8611 - main_output_loss: 1.2037 - tof_gate_loss: 0.1897 - val_loss: 1.1708 - val_main_output_accuracy: 0.8216 - val_main_output_loss: 1.0441 - val_tof_gate_loss: 0.0249\n",
      "Epoch 97/150\n",
      "\u001b[1m22/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 598ms/step - loss: 1.3356 - main_output_accuracy: 0.8605 - main_output_loss: 1.1794 - tof_gate_loss: 0.1861"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "gesture_encoded = le.fit_transform(base_df.get_column('gesture'))\n",
    "base_df = base_df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "final_df = merge_feature_sets(base_df, feature_paths)\n",
    "print(f\"  Final merged DataFrame created with shape: {final_df.shape}\")\n",
    "\n",
    "imu_cols = [\n",
    "    'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', \n",
    "    'acc_mag', 'acc_mag_jerk', 'linear_acc_x_right', 'linear_acc_y_right', 'linear_acc_z_right',\n",
    "    'angular_vel_x_right', 'angular_vel_y_right', 'angular_vel_z_right',\n",
    "    'angular_accel_x', 'angular_accel_y', 'angular_accel_z',\n",
    "    'grav_orient_x', 'grav_orient_y', 'grav_orient_z',\n",
    "    'linear_acc_mag_right', 'angular_vel_mag', 'angular_accel_mag',\n",
    "    'linear_acc_mag_jerk_right', 'angular_vel_mag_jerk', 'angular_accel_mag_jerk',\n",
    "    'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x',\n",
    "    'angular_vel_y', 'angular_vel_z', 'angular_distance',\n",
    "]\n",
    "\n",
    "tof_cols = [\n",
    " 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', \n",
    " 'tof_1_mean', 'tof_1_std', 'tof_1_min', 'tof_1_max', 'tof_2_mean', 'tof_2_std', 'tof_2_min', 'tof_2_max',\n",
    " 'tof_3_mean', 'tof_3_std', 'tof_3_min', 'tof_3_max', 'tof_4_mean', 'tof_4_std', 'tof_4_min', 'tof_4_max',\n",
    " 'tof_5_mean', 'tof_5_std', 'tof_5_min', 'tof_5_max', 'tof_1_mean_right', 'tof_1_std_right', 'tof_1_min_right',\n",
    " 'tof_1_max_right', 'tof_1_diff_mean', 'tof_1_mean_decay', 'tof_1_active_pixels', 'tof_1_centroid_x', 'tof_1_centroid_y', 'tof_2_mean_right',\n",
    " 'tof_2_std_right', 'tof_2_min_right', 'tof_2_max_right', 'tof_2_diff_mean', 'tof_2_mean_decay', \n",
    " 'tof_2_active_pixels', 'tof_2_centroid_x', 'tof_2_centroid_y', 'tof_3_mean_right', 'tof_3_std_right', 'tof_3_min_right',\n",
    " 'tof_3_max_right', 'tof_3_diff_mean', 'tof_3_mean_decay', 'tof_3_active_pixels', 'tof_3_centroid_x', 'tof_3_centroid_y', 'tof_4_mean_right', 'tof_4_std_right', 'tof_4_min_right',\n",
    " 'tof_4_max_right', 'tof_4_diff_mean', 'tof_4_mean_decay', 'tof_4_active_pixels', 'tof_4_centroid_x', 'tof_4_centroid_y', 'tof_5_mean_right', 'tof_5_std_right', 'tof_5_min_right',\n",
    " 'tof_5_max_right', 'tof_5_diff_mean', 'tof_5_mean_decay', 'tof_5_active_pixels', 'tof_5_centroid_x', 'tof_5_centroid_y',]\n",
    "\n",
    "# 2. Create the final, ordered list of all features.\n",
    "all_feature_cols = imu_cols + tof_cols\n",
    "imu_dim = len(imu_cols)\n",
    "print(f\"  Training with {len(all_feature_cols)} total features ({imu_dim} IMU, {len(tof_cols)} ToF/Thm).\")    \n",
    "\n",
    "# 3. Reorder the DataFrame to match the required structure for the model.\n",
    "metadata_to_keep = ['sequence_id', 'sequence_counter', 'gesture', 'gesture_int', 'subject']\n",
    "final_df = final_df.select(metadata_to_keep + all_feature_cols)\n",
    "print(\"  DataFrame columns have been reordered for the model.\")\n",
    "\n",
    "# --- Step 3: Prepare for Cross-Validation ---\n",
    "cv_info = final_df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "y_for_split = cv_info.get_column(\"gesture_int\").to_numpy()\n",
    "\n",
    "input_shape = (MAX_PAD_LEN, len(all_feature_cols)) \n",
    "\n",
    "model_results = {}\n",
    "# model_builders = [\n",
    "# #     # (\"Best_unet_2\", lambda: best_unet_2(input_shape, imu_dim)),\n",
    "# #     (\"Advanced_Dual_UNet\", lambda: create_advanced_model_A_dual_unet(input_shape, imu_dim)),\n",
    "#     (\"Best_unet_1\", lambda: best_unet_1(input_shape, imu_dim)),\n",
    "# #     # (\"gated_cnn_transformer_2_blocks\", lambda: create_gated_cnn_transformer(input_shape, imu_dim)),\n",
    "# ]\n",
    "\n",
    "model_builders = [\n",
    "        # (\"Best_unet_1\", lambda: best_unet_1(input_shape, imu_dim)),\n",
    "        # (\"conformer_model\", lambda: create_conformer_model(input_shape, imu_dim)),\n",
    "        # (\"dual_refiner_model\", lambda: create_dual_refiner_model(input_shape, imu_dim)),\n",
    "        # (\"pann_rnn_head\", lambda:pann_rnn_head_feat_processing(input_shape, imu_dim))\n",
    "    ]\n",
    "\n",
    "for model_name, model_builder in model_builders:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\" Training and Evaluating Model: {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    best_epochs = []\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids, y_for_split)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} for {model_name} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        train_df = final_df.filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = final_df.filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        # Use the explicitly ordered 'all_feature_cols' list\n",
    "        train_features_scaled = scaler.fit_transform(train_df.select(all_feature_cols))\n",
    "        val_features_scaled = scaler.transform(val_df.select(all_feature_cols))\n",
    "        \n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=all_feature_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=all_feature_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'sequence_counter', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        # Use the explicitly ordered 'all_feature_cols' list\n",
    "        X_train, y_train, train_gate_target = create_sequence_dataset(train_df_final, all_feature_cols, generate_gate_targets(train_df, tof_cols))\n",
    "        X_val, y_val, val_gate_target = create_sequence_dataset(val_df_final, all_feature_cols, generate_gate_targets(val_df, tof_cols))\n",
    "\n",
    "        X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='pre', dtype='float32')\n",
    "        X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='pre', dtype='float32')\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "        \n",
    "        train_dataset = GatedMixupGenerator(\n",
    "            X=X_train_padded, y=y_train_cat, gate_targets=train_gate_target,\n",
    "            batch_size=BATCH_SIZE, imu_dim=imu_dim, alpha=0.2, masking_prob=0.25\n",
    "        )\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            X_val_padded, {'main_output': y_val_cat, 'tof_gate': val_gate_target[:, np.newaxis]}\n",
    "        )).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        print(f'Size of X_train: {X_train[0].shape}')\n",
    "        del X_train, y_train, X_val, y_val, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        model = model_builder()\n",
    "        # =============================================================================\n",
    "        # MODIFICATION 1: Instantiate the EMACallback\n",
    "        # =============================================================================\n",
    "        ema_callback = EMACallback(decay=0.999)\n",
    "\n",
    "        # Pass the callback to your training function\n",
    "        history = train_model(\n",
    "            model, \n",
    "            train_dataset, \n",
    "            val_dataset, \n",
    "            epochs=150, \n",
    "            initial_learning_rate=LR_INIT, \n",
    "            weight_decay=WD,\n",
    "            extra_callbacks=[ema_callback] # Pass the callback here\n",
    "        )\n",
    "        \n",
    "        # =============================================================================\n",
    "        # MODIFICATION 2: Apply the EMA weights before evaluation\n",
    "        # =============================================================================\n",
    "        print(\"--- Training complete. Applying EMA weights for evaluation. ---\")\n",
    "        ema_callback.apply_ema_weights()\n",
    "\n",
    "        monitor_metric = 'val_main_output_accuracy' if isinstance(model.output, dict) else 'val_accuracy'\n",
    "        best_epoch = np.argmax(history.history[monitor_metric]) + 1\n",
    "        best_epochs.append(best_epoch)\n",
    "        print(f\"--- Fold {fold_idx + 1} Best Epoch: {best_epoch} ---\")\n",
    "\n",
    "        # --- EVALUATION (now uses the EMA weights) ---\n",
    "        val_preds = model.predict(val_dataset)\n",
    "        main_output_preds = val_preds['main_output']\n",
    "        \n",
    "        y_pred_fold = np.argmax(main_output_preds, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT for this model architecture ---\n",
    "    print(f\"\\n=== OOF Summary for {model_name} ===\")\n",
    "    print(f\"Per-fold Accuracies: {[round(a, 4) for a in fold_accuracies]}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}  {np.std(fold_accuracies):.4f}\")\n",
    "    \n",
    "    # --- NEW: Report on the best epochs found ---\n",
    "    avg_best_epoch = int(np.mean(best_epochs))\n",
    "    print(f\"Best epochs per fold: {best_epochs}\")\n",
    "    print(f\"Average best epoch: {avg_best_epoch}\")\n",
    "    \n",
    "    # Store the results for this model\n",
    "    model_results[model_name] = {\n",
    "        'mean_accuracy': np.mean(fold_accuracies),\n",
    "        'avg_best_epoch': avg_best_epoch\n",
    "    }\n",
    "\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# --- FINAL SUMMARY ACROSS ALL MODELS ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" FINAL MODEL EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for model_name, results in model_results.items():\n",
    "    print(f\"  - {model_name}: Mean Accuracy = {results['mean_accuracy']:.4f}, Avg Best Epoch = {results['avg_best_epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5febb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import traceback\n",
    "# # =====================================================================================\n",
    "# # ARCHITECTURE SANITY CHECK\n",
    "# # =====================================================================================\n",
    "\n",
    "# # --- Step 1: Get a sample batch and define shapes ---\n",
    "# # (This part of your code is correct)\n",
    "# # Make sure your train_dataset is created before this block\n",
    "# try:\n",
    "#     sample_batch = next(iter(train_dataset))\n",
    "#     sample_input = sample_batch[0]\n",
    "#     input_shape = sample_input.shape[1:]\n",
    "#     imu_dim = len(imu_cols) # Assuming imu_cols is defined\n",
    "#     print(f\"Sample input shape for testing: {sample_input.shape}\\n\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not get a sample from the dataset. Error: {e}\")\n",
    "#     # Exit if we can't get a sample to test with\n",
    "#     exit()\n",
    "\n",
    "# # --- Step 2: Create a list of all model-building functions ---\n",
    "# # (This part of your code is correct)\n",
    "# # model_builders = [\n",
    "# #     (\"CNN_Baseline\", lambda: create_model_1_cnn_baseline(input_shape)),\n",
    "# #     (\"GRU_Baseline\", lambda: create_model_2_gru_baseline(input_shape)),\n",
    "# #     (\"CNN_RNN_Hybrid\", lambda: create_model_3_cnn_rnn_hybrid(input_shape)),\n",
    "# #     (\"WaveNet_Style\", lambda: create_model_4_wavenet_style(input_shape)),\n",
    "# #     (\"UNet_Style\", lambda: create_model_5_unet_style(input_shape)),\n",
    "# #     (\"Transformer\", lambda: create_model_6_transformer(input_shape)),\n",
    "# #     (\"CNN_Transformer\", lambda: create_model_7_cnn_transformer(input_shape)),\n",
    "# #     # For your two-branch model, you'll need the full IMU+ToF dataset\n",
    "# #     # (\"Two_Branch\", lambda: create_model_8_two_branch(input_shape, imu_dim)),\n",
    "# # ]\n",
    "\n",
    "# model_builders = [\n",
    "#     (\"wave_net\", lambda: create_wave_net(input_shape, imu_dim)),\n",
    "#     (\"unet_wave\", lambda: create_advanced_model_3_unet_wave(input_shape, imu_dim)),\n",
    "#     (\"Advanced_Dual_UNet\", lambda: create_advanced_model_A_dual_unet(input_shape, imu_dim)),\n",
    "#     (\"Hyper UNet\", lambda: create_advanced_model_B_hyper_unet(input_shape, imu_dim)),\n",
    "# ]\n",
    "\n",
    "# # --- Step 3: Loop through the models, build them, and test with the sample ---\n",
    "# print(\"--- Testing all model architectures with a sample batch ---\")\n",
    "# for model_name, model_builder in model_builders:\n",
    "#     print(\"\\n\" + \"=\"*60)\n",
    "#     print(f\" Testing Model: {model_name}\")\n",
    "#     print(\"=\"*60)\n",
    "    \n",
    "#     try:\n",
    "#         # 1. Build the model using the builder function\n",
    "#         model = model_builder()\n",
    "        \n",
    "#         # Optional: Print the model summary to check its structure\n",
    "#         print(f\"Model Summary for {model_name}:\")\n",
    "#         model.summary()\n",
    "        \n",
    "#         # 2. Pass the sample input through the model\n",
    "#         print(f\"\\nPerforming forward pass for {model_name}...\")\n",
    "#         output = model(sample_input)\n",
    "        \n",
    "#         # 3. Print the output shape to verify it's correct\n",
    "#         print(f\" SUCCESS: Model '{model_name}' ran successfully.\")\n",
    "#         # For multi-output models, output might be a list/dict. For single, it's a tensor.\n",
    "#         if isinstance(output, dict):\n",
    "#             for key, value in output.items():\n",
    "#                 print(f\"   Output '{key}' shape: {value.shape}\")\n",
    "#         elif isinstance(output, list):\n",
    "#             for i, value in enumerate(output):\n",
    "#                 print(f\"   Output {i} shape: {value.shape}\")\n",
    "#         else:\n",
    "#             print(f\"   Output shape: {output.shape}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\" ERROR: Model '{model_name}' failed to build or run.\")\n",
    "#         traceback.print_exc() # This will print the full error traceback\n",
    "        \n",
    "#     # Clean up the created model to save memory\n",
    "#     del model\n",
    "#     gc.collect()\n",
    "\n",
    "# print(\"\\n--- Model architecture testing complete. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
