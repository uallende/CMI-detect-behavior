{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea175bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:47:07.950643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754923627.993571  715332 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754923628.006450  715332 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754923628.080687  715332 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754923628.080743  715332 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754923628.080747  715332 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754923628.080749  715332 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-11 15:47:08.099358: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Parquet file for sequence IDs...\n",
      "Found 8151 unique sequences.\n",
      "\n",
      "=== Fold 1/4 ===\n",
      "Loading data for fold 1...\n",
      "Fold data loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754923671.930617  715332 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1754923716.055665  715532 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-11 15:48:42.306846: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.330561: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.382564: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.452577: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.545116: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.624184: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.916983: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:42.955755: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/96\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17:22\u001b[0m 49s/step - loss: 5.0174 - main_output_accuracy: 0.0312 - main_output_loss: 3.8136 - tof_gate_loss: 0.7990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:48:43.258486: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-11 15:48:43.282557: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 358ms/step - loss: 4.4067 - main_output_accuracy: 0.0959 - main_output_loss: 3.2897 - tof_gate_loss: 0.4979 - val_loss: 3.5251 - val_main_output_accuracy: 0.1869 - val_main_output_loss: 2.5278 - val_tof_gate_loss: 0.4883\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 288ms/step - loss: 3.6636 - main_output_accuracy: 0.2044 - main_output_loss: 2.7481 - tof_gate_loss: 0.2965 - val_loss: 2.8834 - val_main_output_accuracy: 0.3405 - val_main_output_loss: 2.1223 - val_tof_gate_loss: 0.1431\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 285ms/step - loss: 3.3019 - main_output_accuracy: 0.2589 - main_output_loss: 2.5535 - tof_gate_loss: 0.2501 - val_loss: 2.5908 - val_main_output_accuracy: 0.4063 - val_main_output_loss: 1.9581 - val_tof_gate_loss: 0.1280\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 296ms/step - loss: 3.0276 - main_output_accuracy: 0.3037 - main_output_loss: 2.3955 - tof_gate_loss: 0.2349 - val_loss: 2.3290 - val_main_output_accuracy: 0.4828 - val_main_output_loss: 1.8000 - val_tof_gate_loss: 0.0677\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 305ms/step - loss: 2.8768 - main_output_accuracy: 0.3049 - main_output_loss: 2.3389 - tof_gate_loss: 0.2110 - val_loss: 2.2607 - val_main_output_accuracy: 0.4755 - val_main_output_loss: 1.7948 - val_tof_gate_loss: 0.0992\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 301ms/step - loss: 2.7911 - main_output_accuracy: 0.3423 - main_output_loss: 2.3072 - tof_gate_loss: 0.2491 - val_loss: 2.2695 - val_main_output_accuracy: 0.4460 - val_main_output_loss: 1.8571 - val_tof_gate_loss: 0.0809\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 300ms/step - loss: 2.6012 - main_output_accuracy: 0.3872 - main_output_loss: 2.1709 - tof_gate_loss: 0.2260 - val_loss: 2.0062 - val_main_output_accuracy: 0.5466 - val_main_output_loss: 1.6354 - val_tof_gate_loss: 0.0757\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 304ms/step - loss: 2.4893 - main_output_accuracy: 0.4282 - main_output_loss: 2.0963 - tof_gate_loss: 0.2284 - val_loss: 1.9226 - val_main_output_accuracy: 0.5687 - val_main_output_loss: 1.5844 - val_tof_gate_loss: 0.0638\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 312ms/step - loss: 2.4663 - main_output_accuracy: 0.4417 - main_output_loss: 2.0955 - tof_gate_loss: 0.2601 - val_loss: 1.8706 - val_main_output_accuracy: 0.5765 - val_main_output_loss: 1.5583 - val_tof_gate_loss: 0.0638\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 325ms/step - loss: 2.2516 - main_output_accuracy: 0.4866 - main_output_loss: 1.9233 - tof_gate_loss: 0.1943 - val_loss: 1.8213 - val_main_output_accuracy: 0.5800 - val_main_output_loss: 1.5290 - val_tof_gate_loss: 0.0549\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 2.3155 - main_output_accuracy: 0.4819 - main_output_loss: 1.9928 - tof_gate_loss: 0.2319 - val_loss: 1.8610 - val_main_output_accuracy: 0.5785 - val_main_output_loss: 1.5765 - val_tof_gate_loss: 0.1034\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 321ms/step - loss: 2.2566 - main_output_accuracy: 0.4942 - main_output_loss: 1.9504 - tof_gate_loss: 0.2286 - val_loss: 1.6860 - val_main_output_accuracy: 0.6335 - val_main_output_loss: 1.4251 - val_tof_gate_loss: 0.0517\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 305ms/step - loss: 2.2379 - main_output_accuracy: 0.5013 - main_output_loss: 1.9408 - tof_gate_loss: 0.2486 - val_loss: 1.7712 - val_main_output_accuracy: 0.5662 - val_main_output_loss: 1.5189 - val_tof_gate_loss: 0.0695\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 2.1498 - main_output_accuracy: 0.5358 - main_output_loss: 1.8702 - tof_gate_loss: 0.2146 - val_loss: 1.6384 - val_main_output_accuracy: 0.6413 - val_main_output_loss: 1.4008 - val_tof_gate_loss: 0.0492\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 312ms/step - loss: 2.0775 - main_output_accuracy: 0.5456 - main_output_loss: 1.8122 - tof_gate_loss: 0.1979 - val_loss: 1.6925 - val_main_output_accuracy: 0.6045 - val_main_output_loss: 1.4652 - val_tof_gate_loss: 0.0371\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 304ms/step - loss: 2.0050 - main_output_accuracy: 0.5713 - main_output_loss: 1.7512 - tof_gate_loss: 0.1791 - val_loss: 1.6658 - val_main_output_accuracy: 0.5976 - val_main_output_loss: 1.4411 - val_tof_gate_loss: 0.0622\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - loss: 2.0087 - main_output_accuracy: 0.5726 - main_output_loss: 1.7516 - tof_gate_loss: 0.2142 - val_loss: 1.5950 - val_main_output_accuracy: 0.6541 - val_main_output_loss: 1.3737 - val_tof_gate_loss: 0.0774\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 320ms/step - loss: 1.9632 - main_output_accuracy: 0.5855 - main_output_loss: 1.7227 - tof_gate_loss: 0.1812 - val_loss: 1.5938 - val_main_output_accuracy: 0.6315 - val_main_output_loss: 1.3848 - val_tof_gate_loss: 0.0508\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.9774 - main_output_accuracy: 0.5889 - main_output_loss: 1.7416 - tof_gate_loss: 0.1940 - val_loss: 1.5922 - val_main_output_accuracy: 0.6335 - val_main_output_loss: 1.3875 - val_tof_gate_loss: 0.0546\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - loss: 1.9902 - main_output_accuracy: 0.5958 - main_output_loss: 1.7544 - tof_gate_loss: 0.2121 - val_loss: 1.5442 - val_main_output_accuracy: 0.6575 - val_main_output_loss: 1.3430 - val_tof_gate_loss: 0.0579\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.8932 - main_output_accuracy: 0.6134 - main_output_loss: 1.6665 - tof_gate_loss: 0.1899 - val_loss: 1.5417 - val_main_output_accuracy: 0.6668 - val_main_output_loss: 1.3481 - val_tof_gate_loss: 0.0411\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 309ms/step - loss: 1.9089 - main_output_accuracy: 0.6032 - main_output_loss: 1.6851 - tof_gate_loss: 0.1949 - val_loss: 1.5382 - val_main_output_accuracy: 0.6541 - val_main_output_loss: 1.3477 - val_tof_gate_loss: 0.0426\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.9093 - main_output_accuracy: 0.6200 - main_output_loss: 1.6871 - tof_gate_loss: 0.2040 - val_loss: 1.5068 - val_main_output_accuracy: 0.6654 - val_main_output_loss: 1.3184 - val_tof_gate_loss: 0.0506\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 318ms/step - loss: 1.9219 - main_output_accuracy: 0.6186 - main_output_loss: 1.6989 - tof_gate_loss: 0.2209 - val_loss: 1.4877 - val_main_output_accuracy: 0.6698 - val_main_output_loss: 1.3052 - val_tof_gate_loss: 0.0343\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 300ms/step - loss: 1.8892 - main_output_accuracy: 0.6414 - main_output_loss: 1.6725 - tof_gate_loss: 0.2079 - val_loss: 1.5057 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.3214 - val_tof_gate_loss: 0.0571\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 308ms/step - loss: 1.8766 - main_output_accuracy: 0.6265 - main_output_loss: 1.6626 - tof_gate_loss: 0.2039 - val_loss: 1.5728 - val_main_output_accuracy: 0.6349 - val_main_output_loss: 1.3939 - val_tof_gate_loss: 0.0411\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.8038 - main_output_accuracy: 0.6488 - main_output_loss: 1.6010 - tof_gate_loss: 0.1756 - val_loss: 1.5053 - val_main_output_accuracy: 0.6629 - val_main_output_loss: 1.3282 - val_tof_gate_loss: 0.0452\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - loss: 1.8539 - main_output_accuracy: 0.6528 - main_output_loss: 1.6423 - tof_gate_loss: 0.2226 - val_loss: 1.4735 - val_main_output_accuracy: 0.6835 - val_main_output_loss: 1.2999 - val_tof_gate_loss: 0.0374\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - loss: 1.7825 - main_output_accuracy: 0.6670 - main_output_loss: 1.5814 - tof_gate_loss: 0.1902 - val_loss: 1.4537 - val_main_output_accuracy: 0.6757 - val_main_output_loss: 1.2822 - val_tof_gate_loss: 0.0388\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 309ms/step - loss: 1.8380 - main_output_accuracy: 0.6643 - main_output_loss: 1.6310 - tof_gate_loss: 0.2172 - val_loss: 1.4445 - val_main_output_accuracy: 0.6845 - val_main_output_loss: 1.2740 - val_tof_gate_loss: 0.0441\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - loss: 1.7629 - main_output_accuracy: 0.6776 - main_output_loss: 1.5608 - tof_gate_loss: 0.1969 - val_loss: 1.4778 - val_main_output_accuracy: 0.6747 - val_main_output_loss: 1.3104 - val_tof_gate_loss: 0.0346\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 325ms/step - loss: 1.8410 - main_output_accuracy: 0.6617 - main_output_loss: 1.6283 - tof_gate_loss: 0.2263 - val_loss: 1.4534 - val_main_output_accuracy: 0.6835 - val_main_output_loss: 1.2880 - val_tof_gate_loss: 0.0314\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - loss: 1.8118 - main_output_accuracy: 0.6638 - main_output_loss: 1.6107 - tof_gate_loss: 0.2113 - val_loss: 1.4757 - val_main_output_accuracy: 0.6673 - val_main_output_loss: 1.3124 - val_tof_gate_loss: 0.0319\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - loss: 1.7496 - main_output_accuracy: 0.6873 - main_output_loss: 1.5535 - tof_gate_loss: 0.1959 - val_loss: 1.5102 - val_main_output_accuracy: 0.6521 - val_main_output_loss: 1.3469 - val_tof_gate_loss: 0.0413\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 1.7089 - main_output_accuracy: 0.7073 - main_output_loss: 1.5169 - tof_gate_loss: 0.1833 - val_loss: 1.4587 - val_main_output_accuracy: 0.6923 - val_main_output_loss: 1.2983 - val_tof_gate_loss: 0.0337\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - loss: 1.7138 - main_output_accuracy: 0.7062 - main_output_loss: 1.5237 - tof_gate_loss: 0.1822 - val_loss: 1.4843 - val_main_output_accuracy: 0.6712 - val_main_output_loss: 1.3256 - val_tof_gate_loss: 0.0325\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 328ms/step - loss: 1.7498 - main_output_accuracy: 0.6967 - main_output_loss: 1.5631 - tof_gate_loss: 0.2057 - val_loss: 1.3822 - val_main_output_accuracy: 0.7149 - val_main_output_loss: 1.2231 - val_tof_gate_loss: 0.0340\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - loss: 1.6090 - main_output_accuracy: 0.7239 - main_output_loss: 1.4243 - tof_gate_loss: 0.1639 - val_loss: 1.4159 - val_main_output_accuracy: 0.6953 - val_main_output_loss: 1.2563 - val_tof_gate_loss: 0.0484\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 303ms/step - loss: 1.6906 - main_output_accuracy: 0.7152 - main_output_loss: 1.5135 - tof_gate_loss: 0.1952 - val_loss: 1.3543 - val_main_output_accuracy: 0.7174 - val_main_output_loss: 1.1978 - val_tof_gate_loss: 0.0371\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.6748 - main_output_accuracy: 0.7283 - main_output_loss: 1.4895 - tof_gate_loss: 0.1889 - val_loss: 1.3572 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2011 - val_tof_gate_loss: 0.0419\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 308ms/step - loss: 1.6534 - main_output_accuracy: 0.7312 - main_output_loss: 1.4638 - tof_gate_loss: 0.1974 - val_loss: 1.4034 - val_main_output_accuracy: 0.7076 - val_main_output_loss: 1.2489 - val_tof_gate_loss: 0.0334\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.5986 - main_output_accuracy: 0.7508 - main_output_loss: 1.4175 - tof_gate_loss: 0.1697 - val_loss: 1.3957 - val_main_output_accuracy: 0.7056 - val_main_output_loss: 1.2418 - val_tof_gate_loss: 0.0394\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 312ms/step - loss: 1.5683 - main_output_accuracy: 0.7500 - main_output_loss: 1.3872 - tof_gate_loss: 0.1738 - val_loss: 1.3798 - val_main_output_accuracy: 0.7174 - val_main_output_loss: 1.2282 - val_tof_gate_loss: 0.0320\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 304ms/step - loss: 1.5539 - main_output_accuracy: 0.7496 - main_output_loss: 1.3771 - tof_gate_loss: 0.1484 - val_loss: 1.4102 - val_main_output_accuracy: 0.7139 - val_main_output_loss: 1.2602 - val_tof_gate_loss: 0.0282\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 1.6762 - main_output_accuracy: 0.7407 - main_output_loss: 1.4965 - tof_gate_loss: 0.2009 - val_loss: 1.3625 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.2108 - val_tof_gate_loss: 0.0410\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 304ms/step - loss: 1.6734 - main_output_accuracy: 0.7537 - main_output_loss: 1.4876 - tof_gate_loss: 0.2159 - val_loss: 1.3441 - val_main_output_accuracy: 0.7355 - val_main_output_loss: 1.1966 - val_tof_gate_loss: 0.0260\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - loss: 1.6123 - main_output_accuracy: 0.7369 - main_output_loss: 1.4322 - tof_gate_loss: 0.1799 - val_loss: 1.3573 - val_main_output_accuracy: 0.7208 - val_main_output_loss: 1.2095 - val_tof_gate_loss: 0.0312\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - loss: 1.6170 - main_output_accuracy: 0.7550 - main_output_loss: 1.4379 - tof_gate_loss: 0.1929 - val_loss: 1.3631 - val_main_output_accuracy: 0.7252 - val_main_output_loss: 1.2151 - val_tof_gate_loss: 0.0351\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 304ms/step - loss: 1.5788 - main_output_accuracy: 0.7615 - main_output_loss: 1.4007 - tof_gate_loss: 0.1819 - val_loss: 1.3530 - val_main_output_accuracy: 0.7257 - val_main_output_loss: 1.2058 - val_tof_gate_loss: 0.0336\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 308ms/step - loss: 1.6346 - main_output_accuracy: 0.7586 - main_output_loss: 1.4539 - tof_gate_loss: 0.1999 - val_loss: 1.3974 - val_main_output_accuracy: 0.7130 - val_main_output_loss: 1.2516 - val_tof_gate_loss: 0.0322\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - loss: 1.5573 - main_output_accuracy: 0.7704 - main_output_loss: 1.3808 - tof_gate_loss: 0.1828 - val_loss: 1.3495 - val_main_output_accuracy: 0.7291 - val_main_output_loss: 1.2045 - val_tof_gate_loss: 0.0258\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 300ms/step - loss: 1.5378 - main_output_accuracy: 0.7759 - main_output_loss: 1.3610 - tof_gate_loss: 0.1820 - val_loss: 1.3724 - val_main_output_accuracy: 0.7242 - val_main_output_loss: 1.2259 - val_tof_gate_loss: 0.0365\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 312ms/step - loss: 1.5675 - main_output_accuracy: 0.7742 - main_output_loss: 1.3887 - tof_gate_loss: 0.1780 - val_loss: 1.3283 - val_main_output_accuracy: 0.7345 - val_main_output_loss: 1.1844 - val_tof_gate_loss: 0.0272\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 326ms/step - loss: 1.4344 - main_output_accuracy: 0.7994 - main_output_loss: 1.2696 - tof_gate_loss: 0.1475 - val_loss: 1.3335 - val_main_output_accuracy: 0.7370 - val_main_output_loss: 1.1907 - val_tof_gate_loss: 0.0279\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 345ms/step - loss: 1.5523 - main_output_accuracy: 0.7755 - main_output_loss: 1.3751 - tof_gate_loss: 0.1898 - val_loss: 1.3469 - val_main_output_accuracy: 0.7331 - val_main_output_loss: 1.2005 - val_tof_gate_loss: 0.0330\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 336ms/step - loss: 1.5920 - main_output_accuracy: 0.7675 - main_output_loss: 1.4110 - tof_gate_loss: 0.1902 - val_loss: 1.3280 - val_main_output_accuracy: 0.7385 - val_main_output_loss: 1.1839 - val_tof_gate_loss: 0.0355\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.5833 - main_output_accuracy: 0.7863 - main_output_loss: 1.4010 - tof_gate_loss: 0.1914 - val_loss: 1.3277 - val_main_output_accuracy: 0.7370 - val_main_output_loss: 1.1848 - val_tof_gate_loss: 0.0315\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 331ms/step - loss: 1.5571 - main_output_accuracy: 0.7683 - main_output_loss: 1.3824 - tof_gate_loss: 0.1880 - val_loss: 1.3585 - val_main_output_accuracy: 0.7355 - val_main_output_loss: 1.2175 - val_tof_gate_loss: 0.0282\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 336ms/step - loss: 1.5401 - main_output_accuracy: 0.7952 - main_output_loss: 1.3650 - tof_gate_loss: 0.1986 - val_loss: 1.4007 - val_main_output_accuracy: 0.7159 - val_main_output_loss: 1.2593 - val_tof_gate_loss: 0.0340\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.5177 - main_output_accuracy: 0.7898 - main_output_loss: 1.3459 - tof_gate_loss: 0.1792 - val_loss: 1.3614 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.2214 - val_tof_gate_loss: 0.0305\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.5179 - main_output_accuracy: 0.7858 - main_output_loss: 1.3436 - tof_gate_loss: 0.1852 - val_loss: 1.2938 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1549 - val_tof_gate_loss: 0.0262\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 336ms/step - loss: 1.4084 - main_output_accuracy: 0.8226 - main_output_loss: 1.2549 - tof_gate_loss: 0.1485 - val_loss: 1.3541 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2148 - val_tof_gate_loss: 0.0266\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 331ms/step - loss: 1.4729 - main_output_accuracy: 0.7951 - main_output_loss: 1.3049 - tof_gate_loss: 0.1726 - val_loss: 1.4511 - val_main_output_accuracy: 0.7031 - val_main_output_loss: 1.3138 - val_tof_gate_loss: 0.0261\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 336ms/step - loss: 1.4394 - main_output_accuracy: 0.8011 - main_output_loss: 1.2757 - tof_gate_loss: 0.1540 - val_loss: 1.3416 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.2031 - val_tof_gate_loss: 0.0288\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 332ms/step - loss: 1.4907 - main_output_accuracy: 0.8070 - main_output_loss: 1.3182 - tof_gate_loss: 0.1851 - val_loss: 1.3252 - val_main_output_accuracy: 0.7478 - val_main_output_loss: 1.1881 - val_tof_gate_loss: 0.0261\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 332ms/step - loss: 1.4851 - main_output_accuracy: 0.8076 - main_output_loss: 1.3159 - tof_gate_loss: 0.1824 - val_loss: 1.3163 - val_main_output_accuracy: 0.7493 - val_main_output_loss: 1.1797 - val_tof_gate_loss: 0.0275\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 326ms/step - loss: 1.5106 - main_output_accuracy: 0.7963 - main_output_loss: 1.3346 - tof_gate_loss: 0.1996 - val_loss: 1.3298 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1913 - val_tof_gate_loss: 0.0406\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.4468 - main_output_accuracy: 0.8252 - main_output_loss: 1.2891 - tof_gate_loss: 0.1694 - val_loss: 1.3088 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.1736 - val_tof_gate_loss: 0.0223\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 332ms/step - loss: 1.4149 - main_output_accuracy: 0.8200 - main_output_loss: 1.2558 - tof_gate_loss: 0.1583 - val_loss: 1.3289 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.1946 - val_tof_gate_loss: 0.0227\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 335ms/step - loss: 1.5988 - main_output_accuracy: 0.7795 - main_output_loss: 1.4360 - tof_gate_loss: 0.2135 - val_loss: 1.2745 - val_main_output_accuracy: 0.7625 - val_main_output_loss: 1.1395 - val_tof_gate_loss: 0.0287\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 330ms/step - loss: 1.4642 - main_output_accuracy: 0.8188 - main_output_loss: 1.2982 - tof_gate_loss: 0.1848 - val_loss: 1.3353 - val_main_output_accuracy: 0.7444 - val_main_output_loss: 1.2013 - val_tof_gate_loss: 0.0248\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 329ms/step - loss: 1.5061 - main_output_accuracy: 0.8199 - main_output_loss: 1.3420 - tof_gate_loss: 0.2039 - val_loss: 1.3189 - val_main_output_accuracy: 0.7566 - val_main_output_loss: 1.1840 - val_tof_gate_loss: 0.0308\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 332ms/step - loss: 1.4238 - main_output_accuracy: 0.8388 - main_output_loss: 1.2673 - tof_gate_loss: 0.1854 - val_loss: 1.3501 - val_main_output_accuracy: 0.7306 - val_main_output_loss: 1.2168 - val_tof_gate_loss: 0.0285\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.4220 - main_output_accuracy: 0.8359 - main_output_loss: 1.2554 - tof_gate_loss: 0.1889 - val_loss: 1.3067 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1732 - val_tof_gate_loss: 0.0296\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 344ms/step - loss: 1.3679 - main_output_accuracy: 0.8456 - main_output_loss: 1.2085 - tof_gate_loss: 0.1552 - val_loss: 1.3449 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.2124 - val_tof_gate_loss: 0.0225\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 343ms/step - loss: 1.3597 - main_output_accuracy: 0.8430 - main_output_loss: 1.2049 - tof_gate_loss: 0.1580 - val_loss: 1.3206 - val_main_output_accuracy: 0.7547 - val_main_output_loss: 1.1889 - val_tof_gate_loss: 0.0266\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 340ms/step - loss: 1.5084 - main_output_accuracy: 0.8094 - main_output_loss: 1.3413 - tof_gate_loss: 0.2135 - val_loss: 1.2985 - val_main_output_accuracy: 0.7625 - val_main_output_loss: 1.1682 - val_tof_gate_loss: 0.0227\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 331ms/step - loss: 1.3763 - main_output_accuracy: 0.8435 - main_output_loss: 1.2142 - tof_gate_loss: 0.1807 - val_loss: 1.2885 - val_main_output_accuracy: 0.7655 - val_main_output_loss: 1.1578 - val_tof_gate_loss: 0.0255\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 318ms/step - loss: 1.4041 - main_output_accuracy: 0.8513 - main_output_loss: 1.2413 - tof_gate_loss: 0.1821 - val_loss: 1.3196 - val_main_output_accuracy: 0.7655 - val_main_output_loss: 1.1904 - val_tof_gate_loss: 0.0208\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 322ms/step - loss: 1.3883 - main_output_accuracy: 0.8517 - main_output_loss: 1.2284 - tof_gate_loss: 0.1687 - val_loss: 1.3220 - val_main_output_accuracy: 0.7532 - val_main_output_loss: 1.1924 - val_tof_gate_loss: 0.0263\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 328ms/step - loss: 1.4453 - main_output_accuracy: 0.8477 - main_output_loss: 1.2821 - tof_gate_loss: 0.1794 - val_loss: 1.2943 - val_main_output_accuracy: 0.7605 - val_main_output_loss: 1.1652 - val_tof_gate_loss: 0.0251\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.4113 - main_output_accuracy: 0.8433 - main_output_loss: 1.2442 - tof_gate_loss: 0.1867 - val_loss: 1.3301 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.2013 - val_tof_gate_loss: 0.0232\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - loss: 1.4508 - main_output_accuracy: 0.8276 - main_output_loss: 1.2868 - tof_gate_loss: 0.1992 - val_loss: 1.3044 - val_main_output_accuracy: 0.7645 - val_main_output_loss: 1.1763 - val_tof_gate_loss: 0.0243\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - loss: 1.4188 - main_output_accuracy: 0.8444 - main_output_loss: 1.2588 - tof_gate_loss: 0.1791 - val_loss: 1.3086 - val_main_output_accuracy: 0.7650 - val_main_output_loss: 1.1811 - val_tof_gate_loss: 0.0242\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 328ms/step - loss: 1.4094 - main_output_accuracy: 0.8277 - main_output_loss: 1.2492 - tof_gate_loss: 0.1881 - val_loss: 1.3191 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1925 - val_tof_gate_loss: 0.0196\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 319ms/step - loss: 1.3691 - main_output_accuracy: 0.8496 - main_output_loss: 1.2109 - tof_gate_loss: 0.1664 - val_loss: 1.2912 - val_main_output_accuracy: 0.7694 - val_main_output_loss: 1.1654 - val_tof_gate_loss: 0.0197\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - loss: 1.4286 - main_output_accuracy: 0.8529 - main_output_loss: 1.2759 - tof_gate_loss: 0.1897 - val_loss: 1.3037 - val_main_output_accuracy: 0.7640 - val_main_output_loss: 1.1759 - val_tof_gate_loss: 0.0290\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - loss: 1.4578 - main_output_accuracy: 0.8431 - main_output_loss: 1.2937 - tof_gate_loss: 0.2050 - val_loss: 1.2955 - val_main_output_accuracy: 0.7664 - val_main_output_loss: 1.1697 - val_tof_gate_loss: 0.0217\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - loss: 1.3202 - main_output_accuracy: 0.8743 - main_output_loss: 1.1653 - tof_gate_loss: 0.1637 - val_loss: 1.3030 - val_main_output_accuracy: 0.7620 - val_main_output_loss: 1.1773 - val_tof_gate_loss: 0.0238\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 319ms/step - loss: 1.4925 - main_output_accuracy: 0.8468 - main_output_loss: 1.3271 - tof_gate_loss: 0.2172 - val_loss: 1.2850 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1615 - val_tof_gate_loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Saving artifacts for Fold 1 ---\n",
      "Scaler, feature_cols, maxlen, and classes saved.\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step\n",
      "Fold 1 Accuracy: 0.7625\n",
      "\n",
      "=== Fold 2/4 ===\n",
      "Loading data for fold 2...\n",
      "Fold data loaded.\n",
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 326ms/step - loss: 4.5195 - main_output_accuracy: 0.0918 - main_output_loss: 3.3592 - tof_gate_loss: 0.6818 - val_loss: 3.5690 - val_main_output_accuracy: 0.1963 - val_main_output_loss: 2.5842 - val_tof_gate_loss: 0.3697\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 282ms/step - loss: 3.6681 - main_output_accuracy: 0.1904 - main_output_loss: 2.7349 - tof_gate_loss: 0.3195 - val_loss: 3.0763 - val_main_output_accuracy: 0.3238 - val_main_output_loss: 2.2794 - val_tof_gate_loss: 0.2177\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 283ms/step - loss: 3.3258 - main_output_accuracy: 0.2414 - main_output_loss: 2.5509 - tof_gate_loss: 0.2747 - val_loss: 2.5981 - val_main_output_accuracy: 0.4156 - val_main_output_loss: 1.9432 - val_tof_gate_loss: 0.1184\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 303ms/step - loss: 3.0576 - main_output_accuracy: 0.2823 - main_output_loss: 2.4025 - tof_gate_loss: 0.2454 - val_loss: 2.3499 - val_main_output_accuracy: 0.4711 - val_main_output_loss: 1.7977 - val_tof_gate_loss: 0.0727\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 304ms/step - loss: 2.9111 - main_output_accuracy: 0.3086 - main_output_loss: 2.3404 - tof_gate_loss: 0.2537 - val_loss: 2.2128 - val_main_output_accuracy: 0.4882 - val_main_output_loss: 1.7274 - val_tof_gate_loss: 0.0844\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 2.6919 - main_output_accuracy: 0.3660 - main_output_loss: 2.1903 - tof_gate_loss: 0.2335 - val_loss: 2.1773 - val_main_output_accuracy: 0.4941 - val_main_output_loss: 1.7521 - val_tof_gate_loss: 0.0534\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 2.5875 - main_output_accuracy: 0.3913 - main_output_loss: 2.1376 - tof_gate_loss: 0.2292 - val_loss: 1.9770 - val_main_output_accuracy: 0.5500 - val_main_output_loss: 1.5932 - val_tof_gate_loss: 0.0418\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 312ms/step - loss: 2.4928 - main_output_accuracy: 0.4259 - main_output_loss: 2.0794 - tof_gate_loss: 0.2350 - val_loss: 1.9220 - val_main_output_accuracy: 0.5761 - val_main_output_loss: 1.5709 - val_tof_gate_loss: 0.0382\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 2.3896 - main_output_accuracy: 0.4550 - main_output_loss: 2.0057 - tof_gate_loss: 0.2405 - val_loss: 1.8554 - val_main_output_accuracy: 0.5721 - val_main_output_loss: 1.5278 - val_tof_gate_loss: 0.0499\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - loss: 2.3169 - main_output_accuracy: 0.4755 - main_output_loss: 1.9629 - tof_gate_loss: 0.2108 - val_loss: 1.7969 - val_main_output_accuracy: 0.5873 - val_main_output_loss: 1.4923 - val_tof_gate_loss: 0.0433\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 303ms/step - loss: 2.3025 - main_output_accuracy: 0.4844 - main_output_loss: 1.9686 - tof_gate_loss: 0.2299 - val_loss: 1.8656 - val_main_output_accuracy: 0.5348 - val_main_output_loss: 1.5801 - val_tof_gate_loss: 0.0399\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - loss: 2.2737 - main_output_accuracy: 0.5005 - main_output_loss: 1.9523 - tof_gate_loss: 0.2385 - val_loss: 1.7372 - val_main_output_accuracy: 0.6045 - val_main_output_loss: 1.4613 - val_tof_gate_loss: 0.0710\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 2.1881 - main_output_accuracy: 0.5277 - main_output_loss: 1.8889 - tof_gate_loss: 0.2191 - val_loss: 1.8205 - val_main_output_accuracy: 0.5761 - val_main_output_loss: 1.5608 - val_tof_gate_loss: 0.0537\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - loss: 2.1855 - main_output_accuracy: 0.5234 - main_output_loss: 1.8901 - tof_gate_loss: 0.2462 - val_loss: 1.6460 - val_main_output_accuracy: 0.6413 - val_main_output_loss: 1.3958 - val_tof_gate_loss: 0.0580\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 307ms/step - loss: 2.1601 - main_output_accuracy: 0.5339 - main_output_loss: 1.8772 - tof_gate_loss: 0.2276 - val_loss: 1.7137 - val_main_output_accuracy: 0.6163 - val_main_output_loss: 1.4737 - val_tof_gate_loss: 0.0600\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 309ms/step - loss: 2.1811 - main_output_accuracy: 0.5187 - main_output_loss: 1.9016 - tof_gate_loss: 0.2647 - val_loss: 1.6788 - val_main_output_accuracy: 0.6001 - val_main_output_loss: 1.4509 - val_tof_gate_loss: 0.0426\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 307ms/step - loss: 1.9409 - main_output_accuracy: 0.5928 - main_output_loss: 1.6887 - tof_gate_loss: 0.1719 - val_loss: 1.6811 - val_main_output_accuracy: 0.6148 - val_main_output_loss: 1.4628 - val_tof_gate_loss: 0.0290\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 305ms/step - loss: 2.0109 - main_output_accuracy: 0.5690 - main_output_loss: 1.7605 - tof_gate_loss: 0.1965 - val_loss: 1.5479 - val_main_output_accuracy: 0.6737 - val_main_output_loss: 1.3325 - val_tof_gate_loss: 0.0465\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 300ms/step - loss: 2.0487 - main_output_accuracy: 0.5817 - main_output_loss: 1.7997 - tof_gate_loss: 0.2190 - val_loss: 1.5466 - val_main_output_accuracy: 0.6580 - val_main_output_loss: 1.3361 - val_tof_gate_loss: 0.0465\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 298ms/step - loss: 1.9625 - main_output_accuracy: 0.6083 - main_output_loss: 1.7239 - tof_gate_loss: 0.1972 - val_loss: 1.6180 - val_main_output_accuracy: 0.6335 - val_main_output_loss: 1.4137 - val_tof_gate_loss: 0.0453\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 301ms/step - loss: 1.8811 - main_output_accuracy: 0.6231 - main_output_loss: 1.6545 - tof_gate_loss: 0.1814 - val_loss: 1.5455 - val_main_output_accuracy: 0.6521 - val_main_output_loss: 1.3479 - val_tof_gate_loss: 0.0324\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 314ms/step - loss: 1.9050 - main_output_accuracy: 0.6120 - main_output_loss: 1.6743 - tof_gate_loss: 0.1917 - val_loss: 1.4794 - val_main_output_accuracy: 0.6879 - val_main_output_loss: 1.2843 - val_tof_gate_loss: 0.0369\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - loss: 1.9120 - main_output_accuracy: 0.6104 - main_output_loss: 1.6824 - tof_gate_loss: 0.2169 - val_loss: 1.4690 - val_main_output_accuracy: 0.6933 - val_main_output_loss: 1.2785 - val_tof_gate_loss: 0.0343\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - loss: 1.9201 - main_output_accuracy: 0.6262 - main_output_loss: 1.6951 - tof_gate_loss: 0.2202 - val_loss: 1.4947 - val_main_output_accuracy: 0.6904 - val_main_output_loss: 1.3074 - val_tof_gate_loss: 0.0385\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 296ms/step - loss: 1.9061 - main_output_accuracy: 0.6517 - main_output_loss: 1.6892 - tof_gate_loss: 0.2190 - val_loss: 1.4896 - val_main_output_accuracy: 0.6708 - val_main_output_loss: 1.3056 - val_tof_gate_loss: 0.0369\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 1.8034 - main_output_accuracy: 0.6537 - main_output_loss: 1.5966 - tof_gate_loss: 0.1796 - val_loss: 1.4449 - val_main_output_accuracy: 0.6919 - val_main_output_loss: 1.2631 - val_tof_gate_loss: 0.0348\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 309ms/step - loss: 1.8243 - main_output_accuracy: 0.6549 - main_output_loss: 1.6107 - tof_gate_loss: 0.1990 - val_loss: 1.4185 - val_main_output_accuracy: 0.7169 - val_main_output_loss: 1.2372 - val_tof_gate_loss: 0.0422\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 306ms/step - loss: 1.8003 - main_output_accuracy: 0.6719 - main_output_loss: 1.5902 - tof_gate_loss: 0.1911 - val_loss: 1.4458 - val_main_output_accuracy: 0.6919 - val_main_output_loss: 1.2706 - val_tof_gate_loss: 0.0289\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - loss: 1.7521 - main_output_accuracy: 0.6788 - main_output_loss: 1.5479 - tof_gate_loss: 0.1754 - val_loss: 1.4611 - val_main_output_accuracy: 0.6884 - val_main_output_loss: 1.2853 - val_tof_gate_loss: 0.0436\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 312ms/step - loss: 1.7754 - main_output_accuracy: 0.6802 - main_output_loss: 1.5685 - tof_gate_loss: 0.1985 - val_loss: 1.3727 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2016 - val_tof_gate_loss: 0.0357\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 1.7900 - main_output_accuracy: 0.6714 - main_output_loss: 1.5830 - tof_gate_loss: 0.2152 - val_loss: 1.3852 - val_main_output_accuracy: 0.7179 - val_main_output_loss: 1.2157 - val_tof_gate_loss: 0.0337\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 307ms/step - loss: 1.8775 - main_output_accuracy: 0.6596 - main_output_loss: 1.6779 - tof_gate_loss: 0.2455 - val_loss: 1.4499 - val_main_output_accuracy: 0.6811 - val_main_output_loss: 1.2802 - val_tof_gate_loss: 0.0455\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 306ms/step - loss: 1.7604 - main_output_accuracy: 0.6856 - main_output_loss: 1.5610 - tof_gate_loss: 0.1876 - val_loss: 1.3836 - val_main_output_accuracy: 0.7125 - val_main_output_loss: 1.2190 - val_tof_gate_loss: 0.0304\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 353ms/step - loss: 1.6507 - main_output_accuracy: 0.7156 - main_output_loss: 1.4594 - tof_gate_loss: 0.1673 - val_loss: 1.4503 - val_main_output_accuracy: 0.6904 - val_main_output_loss: 1.2877 - val_tof_gate_loss: 0.0307\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 325ms/step - loss: 1.8102 - main_output_accuracy: 0.6802 - main_output_loss: 1.6070 - tof_gate_loss: 0.2303 - val_loss: 1.4345 - val_main_output_accuracy: 0.6973 - val_main_output_loss: 1.2730 - val_tof_gate_loss: 0.0266\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 311ms/step - loss: 1.7492 - main_output_accuracy: 0.6941 - main_output_loss: 1.5538 - tof_gate_loss: 0.1972 - val_loss: 1.4110 - val_main_output_accuracy: 0.7154 - val_main_output_loss: 1.2493 - val_tof_gate_loss: 0.0378\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 322ms/step - loss: 1.6139 - main_output_accuracy: 0.7216 - main_output_loss: 1.4269 - tof_gate_loss: 0.1644 - val_loss: 1.3366 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1769 - val_tof_gate_loss: 0.0386\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 332ms/step - loss: 1.6433 - main_output_accuracy: 0.7216 - main_output_loss: 1.4558 - tof_gate_loss: 0.1731 - val_loss: 1.3751 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2135 - val_tof_gate_loss: 0.0412\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - loss: 1.7637 - main_output_accuracy: 0.6977 - main_output_loss: 1.5685 - tof_gate_loss: 0.2156 - val_loss: 1.3456 - val_main_output_accuracy: 0.7262 - val_main_output_loss: 1.1892 - val_tof_gate_loss: 0.0282\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 340ms/step - loss: 1.6469 - main_output_accuracy: 0.7277 - main_output_loss: 1.4579 - tof_gate_loss: 0.1884 - val_loss: 1.3693 - val_main_output_accuracy: 0.7242 - val_main_output_loss: 1.2145 - val_tof_gate_loss: 0.0297\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 346ms/step - loss: 1.6447 - main_output_accuracy: 0.7240 - main_output_loss: 1.4595 - tof_gate_loss: 0.1810 - val_loss: 1.3379 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1816 - val_tof_gate_loss: 0.0387\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 358ms/step - loss: 1.6083 - main_output_accuracy: 0.7557 - main_output_loss: 1.4251 - tof_gate_loss: 0.1787 - val_loss: 1.3952 - val_main_output_accuracy: 0.7026 - val_main_output_loss: 1.2416 - val_tof_gate_loss: 0.0341\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 350ms/step - loss: 1.7542 - main_output_accuracy: 0.7116 - main_output_loss: 1.5694 - tof_gate_loss: 0.2655 - val_loss: 1.3191 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1676 - val_tof_gate_loss: 0.0269\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 345ms/step - loss: 1.6377 - main_output_accuracy: 0.7533 - main_output_loss: 1.4538 - tof_gate_loss: 0.1899 - val_loss: 1.4396 - val_main_output_accuracy: 0.6948 - val_main_output_loss: 1.2900 - val_tof_gate_loss: 0.0327\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 320ms/step - loss: 1.7143 - main_output_accuracy: 0.7093 - main_output_loss: 1.5282 - tof_gate_loss: 0.2085 - val_loss: 1.3392 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.1908 - val_tof_gate_loss: 0.0290\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - loss: 1.6485 - main_output_accuracy: 0.7414 - main_output_loss: 1.4669 - tof_gate_loss: 0.2126 - val_loss: 1.3335 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1849 - val_tof_gate_loss: 0.0323\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 325ms/step - loss: 1.6096 - main_output_accuracy: 0.7611 - main_output_loss: 1.4258 - tof_gate_loss: 0.1885 - val_loss: 1.3118 - val_main_output_accuracy: 0.7532 - val_main_output_loss: 1.1633 - val_tof_gate_loss: 0.0324\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 351ms/step - loss: 1.7032 - main_output_accuracy: 0.7457 - main_output_loss: 1.5142 - tof_gate_loss: 0.2242 - val_loss: 1.3473 - val_main_output_accuracy: 0.7355 - val_main_output_loss: 1.2012 - val_tof_gate_loss: 0.0275\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 359ms/step - loss: 1.5502 - main_output_accuracy: 0.7749 - main_output_loss: 1.3745 - tof_gate_loss: 0.1742 - val_loss: 1.3644 - val_main_output_accuracy: 0.7262 - val_main_output_loss: 1.2182 - val_tof_gate_loss: 0.0323\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 326ms/step - loss: 1.5907 - main_output_accuracy: 0.7542 - main_output_loss: 1.4156 - tof_gate_loss: 0.1772 - val_loss: 1.3727 - val_main_output_accuracy: 0.7296 - val_main_output_loss: 1.2287 - val_tof_gate_loss: 0.0250\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 327ms/step - loss: 1.4809 - main_output_accuracy: 0.7772 - main_output_loss: 1.3129 - tof_gate_loss: 0.1497 - val_loss: 1.3313 - val_main_output_accuracy: 0.7517 - val_main_output_loss: 1.1892 - val_tof_gate_loss: 0.0199\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 337ms/step - loss: 1.4684 - main_output_accuracy: 0.7894 - main_output_loss: 1.2975 - tof_gate_loss: 0.1583 - val_loss: 1.3305 - val_main_output_accuracy: 0.7326 - val_main_output_loss: 1.1873 - val_tof_gate_loss: 0.0314\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 362ms/step - loss: 1.5336 - main_output_accuracy: 0.7842 - main_output_loss: 1.3596 - tof_gate_loss: 0.1815 - val_loss: 1.3788 - val_main_output_accuracy: 0.7203 - val_main_output_loss: 1.2368 - val_tof_gate_loss: 0.0250\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 353ms/step - loss: 1.5659 - main_output_accuracy: 0.7709 - main_output_loss: 1.3906 - tof_gate_loss: 0.1823 - val_loss: 1.3635 - val_main_output_accuracy: 0.7311 - val_main_output_loss: 1.2218 - val_tof_gate_loss: 0.0267\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 325ms/step - loss: 1.5424 - main_output_accuracy: 0.7861 - main_output_loss: 1.3680 - tof_gate_loss: 0.1907 - val_loss: 1.3136 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.1727 - val_tof_gate_loss: 0.0227\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 322ms/step - loss: 1.5551 - main_output_accuracy: 0.7956 - main_output_loss: 1.3836 - tof_gate_loss: 0.1912 - val_loss: 1.3037 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.1623 - val_tof_gate_loss: 0.0283\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 348ms/step - loss: 1.5527 - main_output_accuracy: 0.7850 - main_output_loss: 1.3775 - tof_gate_loss: 0.1965 - val_loss: 1.2842 - val_main_output_accuracy: 0.7581 - val_main_output_loss: 1.1439 - val_tof_gate_loss: 0.0262\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 371ms/step - loss: 1.5140 - main_output_accuracy: 0.7886 - main_output_loss: 1.3417 - tof_gate_loss: 0.1796 - val_loss: 1.3633 - val_main_output_accuracy: 0.7257 - val_main_output_loss: 1.2226 - val_tof_gate_loss: 0.0318\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 331ms/step - loss: 1.5225 - main_output_accuracy: 0.7764 - main_output_loss: 1.3501 - tof_gate_loss: 0.1862 - val_loss: 1.3424 - val_main_output_accuracy: 0.7331 - val_main_output_loss: 1.2021 - val_tof_gate_loss: 0.0261\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 337ms/step - loss: 1.5943 - main_output_accuracy: 0.7977 - main_output_loss: 1.4205 - tof_gate_loss: 0.2176 - val_loss: 1.3423 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 1.2035 - val_tof_gate_loss: 0.0243\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 347ms/step - loss: 1.5624 - main_output_accuracy: 0.7867 - main_output_loss: 1.3914 - tof_gate_loss: 0.2084 - val_loss: 1.2949 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1556 - val_tof_gate_loss: 0.0277\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 346ms/step - loss: 1.4948 - main_output_accuracy: 0.8051 - main_output_loss: 1.3233 - tof_gate_loss: 0.1897 - val_loss: 1.3003 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.1620 - val_tof_gate_loss: 0.0284\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 354ms/step - loss: 1.5656 - main_output_accuracy: 0.7915 - main_output_loss: 1.3941 - tof_gate_loss: 0.1990 - val_loss: 1.3297 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.1924 - val_tof_gate_loss: 0.0272\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 337ms/step - loss: 1.4639 - main_output_accuracy: 0.8234 - main_output_loss: 1.2973 - tof_gate_loss: 0.1772 - val_loss: 1.3119 - val_main_output_accuracy: 0.7547 - val_main_output_loss: 1.1766 - val_tof_gate_loss: 0.0217\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 336ms/step - loss: 1.4795 - main_output_accuracy: 0.8063 - main_output_loss: 1.3126 - tof_gate_loss: 0.1827 - val_loss: 1.2924 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.1557 - val_tof_gate_loss: 0.0264\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 343ms/step - loss: 1.4803 - main_output_accuracy: 0.8177 - main_output_loss: 1.3128 - tof_gate_loss: 0.1845 - val_loss: 1.3489 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.2139 - val_tof_gate_loss: 0.0265\n",
      "Epoch 67/150\n",
      "\u001b[1m41/96\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 309ms/step - loss: 1.6071 - main_output_accuracy: 0.7782 - main_output_loss: 1.4281 - tof_gate_loss: 0.2473"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 173\u001b[39m\n\u001b[32m    170\u001b[39m gc.collect()\n\u001b[32m    172\u001b[39m model = create_model(train_dataset, \u001b[38;5;28mlen\u001b[39m(imu_cols))\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR_INIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# --- SAVE ARTIFACTS ---\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Saving artifacts for Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/src/functions.py:183\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_dataset, val_dataset, epochs, initial_learning_rate, weight_decay)\u001b[39m\n\u001b[32m    169\u001b[39m model.compile(\n\u001b[32m    170\u001b[39m     optimizer=optimizer,\n\u001b[32m    171\u001b[39m     loss={\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m     metrics={\u001b[33m\"\u001b[39m\u001b[33mmain_output\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    180\u001b[39m     )\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# --- 5. Fit the Model ---\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    unet_se_cnn,\n",
    "    features_processing, \n",
    "    GatedMixupGenerator, \n",
    "    tof_block, \n",
    "    match_time_steps, \n",
    "    time_sum, \n",
    "    squeeze_last_axis,\n",
    "    expand_last_axis,\n",
    "    crop_or_pad_output_shape\n",
    ")\n",
    "\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    create_sequence_dataset,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "# =====================================================================================\n",
    "# MASTER CONTROL FLAG\n",
    "# =====================================================================================\n",
    "TRAIN = False\n",
    "TRAIN = True \n",
    "\n",
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "PARQUET_FILE = 'output/final_model_input_dataset.parquet'\n",
    "# PARQUET_FILE = \"data/extended_features_df.parquet\"\n",
    "# PARQUET_FILE = 'output/kaggle_0.8_feats.parquet'\n",
    "PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION (Your existing function)\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    wave_block, residual_se_cnn_block, tof_block_2, attention_layer\n",
    ")\n",
    "\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    xa = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3) # 64,128\n",
    "    xa = unet_se_cnn(xa, 3, base_filters=128, kernel_size=5)\n",
    "    # xb = tf.keras.layers.MaxPool1D(2)(xb) # 64,128\n",
    "    # x1 = tf.keras.layers.Concatenate()([xa, xb])\n",
    "    # x1 = tf.keras.layers.Conv1D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')(x1)\n",
    "\n",
    "    # input_shape=[(None, 64, 256), (None, 32, 128)\n",
    "    x2 = tof_block_2(tof, wd) \n",
    "\n",
    "    x = features_processing(xa, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "if TRAIN:\n",
    "    schema_df = pl.read_parquet(PARQUET_FILE, n_rows=0)\n",
    "    all_columns = schema_df.columns\n",
    "    meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                    'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "    feature_cols = [c for c in all_columns if c not in meta_cols]\n",
    "    imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "    tof_cols  = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "\n",
    "    print(\"Scanning Parquet file for sequence IDs...\")\n",
    "    all_sequence_ids = (\n",
    "        pl.scan_parquet(PARQUET_FILE)\n",
    "        .select('sequence_id')\n",
    "        .unique()\n",
    "        .collect()\n",
    "        .to_numpy()\n",
    "        .ravel()\n",
    "    )\n",
    "    print(f\"Found {len(all_sequence_ids)} unique sequences.\")\n",
    "\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    imu_dim = len(imu_cols)\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        print(f\"Loading data for fold {fold_idx + 1}...\")\n",
    "        train_df = pl.read_parquet(PARQUET_FILE).filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = pl.read_parquet(PARQUET_FILE).filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        print(\"Fold data loaded.\")\n",
    "\n",
    "        train_gate_df = generate_gate_targets(train_df, tof_cols)\n",
    "        val_gate_df = generate_gate_targets(val_df, tof_cols)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_df['gesture'])\n",
    "        train_df = train_df.with_columns(pl.Series(\"gesture_int\", le.transform(train_df['gesture'])))\n",
    "        val_df = val_df.with_columns(pl.Series(\"gesture_int\", le.transform(val_df['gesture'])))\n",
    "\n",
    "        # --- StandardScaler Logic ---\n",
    "        scaler = StandardScaler()\n",
    "        # Fit on training data and transform both\n",
    "        train_features_scaled = scaler.fit_transform(train_df[imu_cols + tof_cols])\n",
    "        val_features_scaled = scaler.transform(val_df[imu_cols + tof_cols])\n",
    "        # Create Polars DataFrames from the scaled numpy arrays\n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=imu_cols + tof_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=imu_cols + tof_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "        gc.collect()\n",
    "\n",
    "        X_train, y_train, train_gate_target = create_sequence_dataset(train_df_final, imu_cols + tof_cols, train_gate_df)\n",
    "        X_val, y_val, val_gate_target = create_sequence_dataset(val_df_final, imu_cols + tof_cols, val_gate_df)\n",
    "\n",
    "        del train_df_final, val_df_final\n",
    "        gc.collect()\n",
    "\n",
    "        X_train_padded = perform_padding(X_train, MAX_PAD_LEN)\n",
    "        X_val_padded = perform_padding(X_val, MAX_PAD_LEN)\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "        train_dataset = GatedMixupGenerator(\n",
    "            X=X_train_padded, y=y_train_cat, gate_targets=train_gate_target,\n",
    "            batch_size=BATCH_SIZE, imu_dim=imu_dim, alpha=0.2, masking_prob=0.25\n",
    "        )\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            X_val_padded, {'main_output': y_val_cat, 'tof_gate': val_gate_target[:, np.newaxis]}\n",
    "        )).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        del X_val, y_val, X_train, y_train, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        model = create_model(train_dataset, len(imu_cols))\n",
    "        train_model(model, train_dataset, val_dataset, 150, LR_INIT, WD)\n",
    "\n",
    "        # --- SAVE ARTIFACTS ---\n",
    "        print(f\"--- Saving artifacts for Fold {fold_idx + 1} ---\")\n",
    "        model.save(PRETRAINED_DIR / f\"gesture_model_fold_{fold_idx}.h5\")\n",
    "        \n",
    "        # Save scaler and other metadata only from the first fold\n",
    "        if fold_idx == 0:\n",
    "            joblib.dump(scaler, PRETRAINED_DIR / \"scaler.pkl\")\n",
    "            np.save(PRETRAINED_DIR / \"feature_cols.npy\", np.array(imu_cols + tof_cols))\n",
    "            np.save(PRETRAINED_DIR / \"sequence_maxlen.npy\", MAX_PAD_LEN)\n",
    "            np.save(PRETRAINED_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "            print(\"Scaler, feature_cols, maxlen, and classes saved.\")\n",
    "\n",
    "        # --- EVALUATION ---\n",
    "        val_preds = model.predict(val_dataset)\n",
    "        main_output_preds = val_preds['main_output']\n",
    "        y_pred_fold = np.argmax(main_output_preds, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT ---\n",
    "    print(\"\\n=== Cross-validation Summary ===\")\n",
    "    print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# =====================================================================================\n",
    "# INFERENCE LOGIC\n",
    "# =====================================================================================\n",
    "else:\n",
    "    import pandas as pd \n",
    "    from src.metric import CompetitionMetric \n",
    "    from tensorflow import argmax, minimum, shape\n",
    "\n",
    "    def crop_or_pad(inputs):\n",
    "        x, skip = inputs\n",
    "        x_len = shape(x)[1]\n",
    "        skip_len = shape(skip)[1]\n",
    "        min_len = minimum(x_len, skip_len)\n",
    "        return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "    \n",
    "    # --- 1. Load All Inference Artifacts ---\n",
    "    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "    pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "    scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "    print(\"Scaler expects:\", list(scaler.feature_names_in_))\n",
    "    print(\"We have:\", final_feature_cols)\n",
    "    print(\"Missing:\", set(scaler.feature_names_in_) - set(final_feature_cols))\n",
    "    print(\"Extra:\", set(final_feature_cols) - set(scaler.feature_names_in_))\n",
    "\n",
    "    models = []\n",
    "    print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "    for fold in range(N_SPLITS):\n",
    "        model_path = PRETRAINED_DIR / f\"gesture_model_fold_{fold}.h5\"\n",
    "        \n",
    "        model = load_model(model_path, compile=False, custom_objects={\n",
    "            'unet_se_cnn': unet_se_cnn,\n",
    "            'tof_block': tof_block,\n",
    "            'features_processing': features_processing,\n",
    "            'match_time_steps': match_time_steps,\n",
    "            'crop_or_pad': crop_or_pad,\n",
    "            'squeeze_last_axis': squeeze_last_axis,\n",
    "            'expand_last_axis': expand_last_axis,\n",
    "            'time_sum': time_sum,\n",
    "            'crop_or_pad_output_shape': crop_or_pad_output_shape\n",
    "        })\n",
    "        models.append(model)\n",
    "    print(\"  Models, scaler, and metadata loaded – ready for evaluation.\")\n",
    "\n",
    "    # --- 2. Define TTA Parameters and Predict Function ---\n",
    "    TTA_STEPS = 10\n",
    "    TTA_NOISE_STDDEV = 0.01\n",
    "\n",
    "    from src.tof_feats import remove_gravity_from_acc, calculate_angular_velocity_from_quat, calculate_angular_distance\n",
    "\n",
    "    def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "        # Convert to pandas for the processing pipeline\n",
    "        df_seq = sequence.to_pandas()\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 1: Sanitize Raw Inputs ---\n",
    "        # =================================================================================\n",
    "        # This is a robust guard against non-numeric data in the hidden test set.\n",
    "        sensor_cols = [c for c in df_seq.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "        for col in sensor_cols:\n",
    "            if df_seq[col].dtype == 'object':\n",
    "                df_seq[col] = pd.to_numeric(df_seq[col], errors='coerce')\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 2: Feature Engineering (Must match training pipeline exactly) ---\n",
    "        # =================================================================================\n",
    "        \n",
    "        new_features = {}\n",
    "\n",
    "        # --- IMU Features ---\n",
    "        linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "        new_features['linear_acc_x'] = linear_accel[:, 0]\n",
    "        new_features['linear_acc_y'] = linear_accel[:, 1]\n",
    "        new_features['linear_acc_z'] = linear_accel[:, 2]\n",
    "        \n",
    "        linear_acc_mag = np.sqrt(np.square(linear_accel).sum(axis=1))\n",
    "        new_features['linear_acc_mag'] = linear_acc_mag\n",
    "        new_features['linear_acc_mag_jerk'] = pd.Series(linear_acc_mag).diff().fillna(0).values\n",
    "        \n",
    "        angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "        new_features['angular_vel_x'] = angular_vel[:, 0]\n",
    "        new_features['angular_vel_y'] = angular_vel[:, 1]\n",
    "        new_features['angular_vel_z'] = angular_vel[:, 2]\n",
    "        \n",
    "        new_features['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "\n",
    "        # --- ToF Aggregated Features ---\n",
    "        for i in range(1, 6):\n",
    "            pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "\n",
    "            tof_data = df_seq[pixel_cols].replace(-1, np.nan) \n",
    "            new_features[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "            new_features[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "            new_features[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "            new_features[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "\n",
    "        # Add all new features to the DataFrame in one efficient operation\n",
    "        df_seq = df_seq.assign(**new_features)\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 3: Final Processing (Scaling and Padding) ---\n",
    "        # =================================================================================\n",
    "\n",
    "        mat_unscaled_df = df_seq[final_feature_cols]\n",
    "        mat_unscaled_filled = mat_unscaled_df.ffill().bfill().fillna(0)\n",
    "        mat_scaled = scaler.transform(mat_unscaled_filled)\n",
    "        pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 4: TTA and Ensemble Prediction ---\n",
    "        # =================================================================================\n",
    "        all_tta_predictions = []\n",
    "        for i in range(TTA_STEPS):\n",
    "            noisy_input = pad_input\n",
    "            if i > 0:\n",
    "                noise = tf.random.normal(shape=tf.shape(pad_input), mean=0.0, stddev=TTA_NOISE_STDDEV)\n",
    "                noisy_input = pad_input + noise\n",
    "\n",
    "            all_fold_predictions = []\n",
    "            for model in models:\n",
    "                # Correctly unpack the dictionary returned by the model\n",
    "                predictions_dict = model.predict(noisy_input, verbose=0)\n",
    "                main_preds = predictions_dict['main_output']\n",
    "                all_fold_predictions.append(main_preds)\n",
    "            \n",
    "            avg_fold_prediction = np.mean(all_fold_predictions, axis=0)\n",
    "            all_tta_predictions.append(avg_fold_prediction)\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 5: Final Averaging and Prediction ---\n",
    "        # =================================================================================\n",
    "        final_avg_prediction = np.mean(all_tta_predictions, axis=0)\n",
    "        idx = int(final_avg_prediction.argmax())\n",
    "        \n",
    "        return str(gesture_classes[idx])\n",
    "    \n",
    "    # --- 3. Run Kaggle Evaluation Server ---\n",
    "    import kaggle_evaluation.cmi_inference_server\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        # For local testing, you need to provide the paths to the test data\n",
    "        print(\"Running local gateway for testing...\")\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                'input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "                'input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "PARQUET_FILE = 'output/kaggle_0.8_feats.parquet'\n",
    "df = pl.read_parquet(PARQUET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30587df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m:\n\u001b[32m      2\u001b[39m     x = e[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m     y = e[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for e in train_dataset:\n",
    "    x = e[0]\n",
    "    y = e[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3ad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 128, 38)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 38)\n"
     ]
    }
   ],
   "source": [
    "input_shape = x[0].shape\n",
    "inp = tf.keras.layers.Input(shape=input_shape)\n",
    "imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a87a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 32, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = 0\n",
    "# TOF/Thermal lighter branch\n",
    "x2 = tf.keras.layers.Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(wd))(tof)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "x2 = tf.keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(wd))(x2)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33df75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU deep branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n",
    "\n",
    "    # TOF/Thermal lighter branch\n",
    "    x2 = tf.keras.layers.Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.layers.l2(wd))(tof)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.layers.l2(wd))(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "\n",
    "    merged = tf.keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "    xa = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, kernel_regularizer=tf.keras.layers.l2(wd)))(merged)\n",
    "    xb = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=tf.keras.layers.l2(wd)))(merged)\n",
    "    xc = tf.keras.layers.GaussianNoise(0.09)(merged)\n",
    "    xc = tf.keras.layers.Dense(16, activation='elu')(xc)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([xa, xb, xc])\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = tf.keras.layers.Dense(units, use_bias=False, kernel_regularizer=tf.keras.layers.l2(wd))(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x); x = tf.keras.layers.Activation('relu')(x)\n",
    "        x = tf.keras.layers.Dropout(drop)(x)\n",
    "\n",
    "    main_out = tf.keras.layers.tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # =====================================================================================\n",
    "# # --- INFERENCE & LOCAL DEBUGGING SCRIPT ---\n",
    "# # =====================================================================================\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# import traceback\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# import os\n",
    "# import gc\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import polars as pl\n",
    "# import tensorflow as tf\n",
    "# from pathlib import Path\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "# from tensorflow import argmax, minimum, shape\n",
    "\n",
    "# # --- Your existing function imports ---\n",
    "# from src.nn_blocks import (\n",
    "#     unet_se_cnn,\n",
    "#     features_processing, \n",
    "#     GatedMixupGenerator, \n",
    "#     tof_block, \n",
    "#     match_time_steps, \n",
    "#     time_sum, \n",
    "#     squeeze_last_axis,\n",
    "#     expand_last_axis,\n",
    "#     crop_or_pad_output_shape\n",
    "# )\n",
    "\n",
    "# from src.functions import (\n",
    "#     train_model, \n",
    "#     create_sequence_dataset,\n",
    "#     perform_padding,\n",
    "#     generate_gate_targets\n",
    "# )\n",
    "# from src.constants import DATA_PATH\n",
    "# from src.tof_feats import remove_gravity_from_acc, calculate_angular_velocity_from_quat, calculate_angular_distance\n",
    "\n",
    "# def crop_or_pad(inputs):\n",
    "#     x, skip = inputs\n",
    "#     x_len = shape(x)[1]\n",
    "#     skip_len = shape(skip)[1]\n",
    "#     min_len = minimum(x_len, skip_len)\n",
    "#     return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MASTER CONTROL FLAG\n",
    "# # =====================================================================================\n",
    "# TRAIN = True \n",
    "# TRAIN = False\n",
    "\n",
    "# # =====================================================================================\n",
    "# # CONFIGURATION\n",
    "# # =====================================================================================\n",
    "# PARQUET_FILE = 'output/final_processed_train_data.parquet'\n",
    "# PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "# PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "# LR_INIT = 5e-4\n",
    "# WD = 3e-3\n",
    "# NUM_CLASSES = 18\n",
    "# BATCH_SIZE = 64\n",
    "# N_SPLITS = 4 \n",
    "# MAX_PAD_LEN = 128\n",
    "\n",
    "# # --- 2. Define TTA Parameters and Predict Function ---\n",
    "# TTA_STEPS = 10\n",
    "# TTA_NOISE_STDDEV = 0.01\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MODEL DEFINITION (Your existing function)\n",
    "# # =====================================================================================\n",
    "# def create_model(dataset, imu_dim, wd=1e-4):\n",
    "#     sample_batch = next(iter(dataset))\n",
    "#     input_shape = sample_batch[0].shape[1:]\n",
    "#     inp = tf.keras.layers.Input(shape=input_shape)\n",
    "#     imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "#     tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "#     x1 = unet_se_cnn(imu, 3, base_filters=64, kernel_size=3)\n",
    "#     x2 = tof_block(tof, wd)\n",
    "\n",
    "#     x = features_processing(x1, x2)\n",
    "#     x = tf.keras.layers.Dropout(0.3)(x) \n",
    "#     main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "#     gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "#     return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# # --- 1. Load All Inference Artifacts ---\n",
    "# print(\"▶ LOCAL DEBUG MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "# try:\n",
    "#     final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "#     pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "#     scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "#     gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "#     models = []\n",
    "#     print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "#     for fold in range(N_SPLITS):\n",
    "#         model_path = PRETRAINED_DIR / f\"gesture_model_fold_{fold}.h5\"\n",
    "#         model = load_model(model_path, compile=False, custom_objects={\n",
    "#             'unet_se_cnn': unet_se_cnn,\n",
    "#             'tof_block': tof_block,\n",
    "#             'features_processing': features_processing,\n",
    "#             'match_time_steps': match_time_steps,\n",
    "#             'crop_or_pad': crop_or_pad,\n",
    "#             'squeeze_last_axis': squeeze_last_axis,\n",
    "#             'expand_last_axis': expand_last_axis,\n",
    "#             'time_sum': time_sum,\n",
    "#             'crop_or_pad_output_shape': crop_or_pad_output_shape\n",
    "#         })\n",
    "#         models.append(model)\n",
    "#     print(\"  Models, scaler, and metadata loaded.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"ERROR loading artifacts: {e}\")\n",
    "#     # Stop execution if artifacts can't be loaded\n",
    "#     exit()\n",
    "\n",
    "# # --- 2. Define the Predict Function (Using the most robust version) ---\n",
    "# def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#     # ... (All your feature engineering code is correct and can remain the same) ...\n",
    "#     df_seq = sequence.to_pandas()\n",
    "#     # ... (Sanitization, feature creation, scaling, padding) ...\n",
    "#     sensor_cols = [c for c in df_seq.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "#     for col in sensor_cols:\n",
    "#         if df_seq[col].dtype == 'object':\n",
    "#             df_seq[col] = pd.to_numeric(df_seq[col], errors='coerce')\n",
    "#     new_features = {}\n",
    "#     linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "#     new_features['linear_acc_x'] = linear_accel[:, 0]\n",
    "#     new_features['linear_acc_y'] = linear_accel[:, 1]\n",
    "#     new_features['linear_acc_z'] = linear_accel[:, 2]\n",
    "#     linear_acc_mag = np.sqrt(np.square(linear_accel).sum(axis=1))\n",
    "#     new_features['linear_acc_mag'] = linear_acc_mag\n",
    "#     new_features['linear_acc_mag_jerk'] = pd.Series(linear_acc_mag).diff().fillna(0).values\n",
    "#     angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "#     new_features['angular_vel_x'] = angular_vel[:, 0]\n",
    "#     new_features['angular_vel_y'] = angular_vel[:, 1]\n",
    "#     new_features['angular_vel_z'] = angular_vel[:, 2]\n",
    "#     new_features['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "#         tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "#         new_features[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "#         new_features[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "#         new_features[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "#         new_features[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "#     df_seq = df_seq.assign(**new_features)\n",
    "#     mat_unscaled_df = df_seq[final_feature_cols].ffill().bfill().fillna(0)\n",
    "#     mat_scaled = scaler.transform(mat_unscaled_df)\n",
    "#     pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "#     # --- TTA Loop ---\n",
    "#     all_tta_predictions = []\n",
    "#     for i in range(TTA_STEPS):\n",
    "#         noisy_input = pad_input\n",
    "#         if i > 0:\n",
    "#             noise = tf.random.normal(shape=tf.shape(pad_input), mean=0.0, stddev=TTA_NOISE_STDDEV)\n",
    "#             noisy_input = pad_input + noise\n",
    "\n",
    "#         # Ensemble predictions from all fold models\n",
    "#         all_fold_predictions = []\n",
    "#         for model in models:\n",
    "            \n",
    "#             # =========================================================================\n",
    "#             # --- THE FINAL FIX IS HERE ---\n",
    "#             # =========================================================================\n",
    "#             # model.predict returns a dictionary, access the 'main_output' key\n",
    "#             predictions_dict = model.predict(noisy_input, verbose=0)\n",
    "#             main_preds = predictions_dict['main_output']\n",
    "            \n",
    "#             all_fold_predictions.append(main_preds)\n",
    "        \n",
    "#         avg_fold_prediction = np.mean(all_fold_predictions, axis=0)\n",
    "#         all_tta_predictions.append(avg_fold_prediction)\n",
    "\n",
    "#     # --- Final Averaging and Prediction (Unchanged) ---\n",
    "#     final_avg_prediction = np.mean(all_tta_predictions, axis=0)\n",
    "#     idx = int(final_avg_prediction.argmax())\n",
    "    \n",
    "#     return str(gesture_classes[idx])\n",
    "\n",
    "# # =====================================================================================\n",
    "# # --- LOCAL TEST HARNESS ---\n",
    "# # =====================================================================================\n",
    "# print(\"\\n--- Starting Local Test ---\")\n",
    "\n",
    "# # Load the actual test data\n",
    "# TEST_CSV_PATH = 'input/cmi-detect-behavior-with-sensor-data/test.csv'\n",
    "# TEST_DEM_PATH = 'input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n",
    "\n",
    "# try:\n",
    "#     test_df = pl.read_csv(TEST_CSV_PATH)\n",
    "#     test_dem_df = pl.read_csv(TEST_DEM_PATH)\n",
    "    \n",
    "#     # Pick the first sequence from the test set\n",
    "#     target_sequence_id = test_df.get_column(\"sequence_id\").unique()[0]\n",
    "#     print(f\"Testing with sequence_id: {target_sequence_id}\")\n",
    "    \n",
    "#     # Isolate the data for that single sequence\n",
    "#     sample_sequence_pl = test_df.filter(pl.col(\"sequence_id\") == target_sequence_id)\n",
    "    \n",
    "#     # Find the corresponding subject and their demographics\n",
    "#     subject_id = sample_sequence_pl.get_column(\"subject\")[0]\n",
    "#     sample_demographics_pl = test_dem_df.filter(pl.col(\"subject\") == subject_id)\n",
    "    \n",
    "#     # --- Call the predict function directly and catch the REAL error ---\n",
    "#     print(\"\\nCalling predict function directly...\")\n",
    "#     predicted_gesture = predict(sample_sequence_pl, sample_demographics_pl)\n",
    "    \n",
    "#     print(\"\\n✅ SUCCESS! The function ran without errors on a sample.\")\n",
    "#     print(f\"Predicted Gesture: {predicted_gesture}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"\\n❌ ERROR! The function failed. Here is the full Python traceback:\")\n",
    "#     traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
