{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea175bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 16:18:09.639585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754839089.670622  397751 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754839089.680543  397751 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754839089.714474  397751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754839089.714508  397751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754839089.714511  397751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754839089.714513  397751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-10 16:18:09.724402: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Parquet file for sequence IDs...\n",
      "Found 8151 unique sequences.\n",
      "\n",
      "=== Fold 1/4 ===\n",
      "Loading data for fold 1...\n",
      "Fold data loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754839130.112321  397751 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1754839156.463394  397953 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 232ms/step - loss: 3.7659 - main_output_accuracy: 0.0934 - main_output_loss: 3.2885 - tof_gate_loss: 0.4926 - val_loss: 2.9906 - val_main_output_accuracy: 0.2846 - val_main_output_loss: 2.5512 - val_tof_gate_loss: 0.3101\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 3.1144 - main_output_accuracy: 0.2154 - main_output_loss: 2.6744 - tof_gate_loss: 0.3241 - val_loss: 2.5425 - val_main_output_accuracy: 0.3862 - val_main_output_loss: 2.1475 - val_tof_gate_loss: 0.1640\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 2.8917 - main_output_accuracy: 0.2645 - main_output_loss: 2.4854 - tof_gate_loss: 0.2449 - val_loss: 2.2446 - val_main_output_accuracy: 0.4588 - val_main_output_loss: 1.8784 - val_tof_gate_loss: 0.1029\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 2.6760 - main_output_accuracy: 0.3258 - main_output_loss: 2.2940 - tof_gate_loss: 0.2038 - val_loss: 2.2210 - val_main_output_accuracy: 0.4318 - val_main_output_loss: 1.8706 - val_tof_gate_loss: 0.1029\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 2.5748 - main_output_accuracy: 0.3471 - main_output_loss: 2.2080 - tof_gate_loss: 0.2093 - val_loss: 2.0341 - val_main_output_accuracy: 0.5226 - val_main_output_loss: 1.7041 - val_tof_gate_loss: 0.0797\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 2.5752 - main_output_accuracy: 0.3648 - main_output_loss: 2.2194 - tof_gate_loss: 0.2313 - val_loss: 1.9647 - val_main_output_accuracy: 0.5314 - val_main_output_loss: 1.6515 - val_tof_gate_loss: 0.0690\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.4804 - main_output_accuracy: 0.3986 - main_output_loss: 2.1339 - tof_gate_loss: 0.2561 - val_loss: 1.8586 - val_main_output_accuracy: 0.5795 - val_main_output_loss: 1.5635 - val_tof_gate_loss: 0.0476\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 2.4058 - main_output_accuracy: 0.4391 - main_output_loss: 2.0771 - tof_gate_loss: 0.2370 - val_loss: 1.8101 - val_main_output_accuracy: 0.5927 - val_main_output_loss: 1.5258 - val_tof_gate_loss: 0.0564\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.2383 - main_output_accuracy: 0.4899 - main_output_loss: 1.9355 - tof_gate_loss: 0.1956 - val_loss: 1.7618 - val_main_output_accuracy: 0.5981 - val_main_output_loss: 1.4940 - val_tof_gate_loss: 0.0313\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 2.2342 - main_output_accuracy: 0.4932 - main_output_loss: 1.9360 - tof_gate_loss: 0.2086 - val_loss: 1.7160 - val_main_output_accuracy: 0.6089 - val_main_output_loss: 1.4555 - val_tof_gate_loss: 0.0493\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 2.2246 - main_output_accuracy: 0.5048 - main_output_loss: 1.9314 - tof_gate_loss: 0.2269 - val_loss: 1.7383 - val_main_output_accuracy: 0.5888 - val_main_output_loss: 1.4863 - val_tof_gate_loss: 0.0552\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 177ms/step - loss: 2.1838 - main_output_accuracy: 0.5162 - main_output_loss: 1.9004 - tof_gate_loss: 0.2280 - val_loss: 1.6783 - val_main_output_accuracy: 0.6281 - val_main_output_loss: 1.4352 - val_tof_gate_loss: 0.0559\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 2.1242 - main_output_accuracy: 0.5464 - main_output_loss: 1.8530 - tof_gate_loss: 0.2204 - val_loss: 1.6434 - val_main_output_accuracy: 0.6359 - val_main_output_loss: 1.4116 - val_tof_gate_loss: 0.0411\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 182ms/step - loss: 2.1267 - main_output_accuracy: 0.5426 - main_output_loss: 1.8568 - tof_gate_loss: 0.2438 - val_loss: 1.6504 - val_main_output_accuracy: 0.6124 - val_main_output_loss: 1.4254 - val_tof_gate_loss: 0.0450\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 2.0620 - main_output_accuracy: 0.5789 - main_output_loss: 1.8027 - tof_gate_loss: 0.2287 - val_loss: 1.6207 - val_main_output_accuracy: 0.6447 - val_main_output_loss: 1.4004 - val_tof_gate_loss: 0.0548\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 181ms/step - loss: 1.9722 - main_output_accuracy: 0.5973 - main_output_loss: 1.7269 - tof_gate_loss: 0.1941 - val_loss: 1.5646 - val_main_output_accuracy: 0.6438 - val_main_output_loss: 1.3556 - val_tof_gate_loss: 0.0319\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 2.0435 - main_output_accuracy: 0.5918 - main_output_loss: 1.7968 - tof_gate_loss: 0.2317 - val_loss: 1.5593 - val_main_output_accuracy: 0.6565 - val_main_output_loss: 1.3550 - val_tof_gate_loss: 0.0368\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 178ms/step - loss: 2.0071 - main_output_accuracy: 0.5968 - main_output_loss: 1.7692 - tof_gate_loss: 0.2145 - val_loss: 1.5188 - val_main_output_accuracy: 0.6840 - val_main_output_loss: 1.3186 - val_tof_gate_loss: 0.0417\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 2.0666 - main_output_accuracy: 0.5861 - main_output_loss: 1.8259 - tof_gate_loss: 0.2543 - val_loss: 1.5181 - val_main_output_accuracy: 0.6624 - val_main_output_loss: 1.3243 - val_tof_gate_loss: 0.0334\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.9247 - main_output_accuracy: 0.6176 - main_output_loss: 1.6995 - tof_gate_loss: 0.2015 - val_loss: 1.5045 - val_main_output_accuracy: 0.6688 - val_main_output_loss: 1.3162 - val_tof_gate_loss: 0.0278\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.9076 - main_output_accuracy: 0.6241 - main_output_loss: 1.6853 - tof_gate_loss: 0.2086 - val_loss: 1.4647 - val_main_output_accuracy: 0.6943 - val_main_output_loss: 1.2791 - val_tof_gate_loss: 0.0347\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.8494 - main_output_accuracy: 0.6372 - main_output_loss: 1.6347 - tof_gate_loss: 0.1906 - val_loss: 1.4615 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.2763 - val_tof_gate_loss: 0.0533\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.8719 - main_output_accuracy: 0.6436 - main_output_loss: 1.6542 - tof_gate_loss: 0.2105 - val_loss: 1.4855 - val_main_output_accuracy: 0.6757 - val_main_output_loss: 1.3068 - val_tof_gate_loss: 0.0380\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.8530 - main_output_accuracy: 0.6458 - main_output_loss: 1.6437 - tof_gate_loss: 0.2009 - val_loss: 1.4536 - val_main_output_accuracy: 0.6919 - val_main_output_loss: 1.2791 - val_tof_gate_loss: 0.0324\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.8766 - main_output_accuracy: 0.6472 - main_output_loss: 1.6715 - tof_gate_loss: 0.2136 - val_loss: 1.4258 - val_main_output_accuracy: 0.7080 - val_main_output_loss: 1.2524 - val_tof_gate_loss: 0.0410\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.8259 - main_output_accuracy: 0.6651 - main_output_loss: 1.6203 - tof_gate_loss: 0.2096 - val_loss: 1.4704 - val_main_output_accuracy: 0.6963 - val_main_output_loss: 1.3010 - val_tof_gate_loss: 0.0365\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 175ms/step - loss: 1.9100 - main_output_accuracy: 0.6534 - main_output_loss: 1.7032 - tof_gate_loss: 0.2405 - val_loss: 1.4542 - val_main_output_accuracy: 0.6997 - val_main_output_loss: 1.2881 - val_tof_gate_loss: 0.0333\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.7883 - main_output_accuracy: 0.6646 - main_output_loss: 1.5907 - tof_gate_loss: 0.2049 - val_loss: 1.4383 - val_main_output_accuracy: 0.6894 - val_main_output_loss: 1.2754 - val_tof_gate_loss: 0.0296\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.7892 - main_output_accuracy: 0.6689 - main_output_loss: 1.5938 - tof_gate_loss: 0.2018 - val_loss: 1.4141 - val_main_output_accuracy: 0.7095 - val_main_output_loss: 1.2518 - val_tof_gate_loss: 0.0364\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.8237 - main_output_accuracy: 0.6703 - main_output_loss: 1.6260 - tof_gate_loss: 0.2226 - val_loss: 1.3985 - val_main_output_accuracy: 0.7228 - val_main_output_loss: 1.2378 - val_tof_gate_loss: 0.0353\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.7514 - main_output_accuracy: 0.6696 - main_output_loss: 1.5612 - tof_gate_loss: 0.1931 - val_loss: 1.4021 - val_main_output_accuracy: 0.7046 - val_main_output_loss: 1.2450 - val_tof_gate_loss: 0.0291\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 180ms/step - loss: 1.7263 - main_output_accuracy: 0.6998 - main_output_loss: 1.5401 - tof_gate_loss: 0.1785 - val_loss: 1.3984 - val_main_output_accuracy: 0.7223 - val_main_output_loss: 1.2403 - val_tof_gate_loss: 0.0413\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.7868 - main_output_accuracy: 0.6821 - main_output_loss: 1.5949 - tof_gate_loss: 0.2171 - val_loss: 1.3933 - val_main_output_accuracy: 0.7179 - val_main_output_loss: 1.2404 - val_tof_gate_loss: 0.0260\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.7127 - main_output_accuracy: 0.7012 - main_output_loss: 1.5301 - tof_gate_loss: 0.1771 - val_loss: 1.4038 - val_main_output_accuracy: 0.7046 - val_main_output_loss: 1.2529 - val_tof_gate_loss: 0.0236\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.8032 - main_output_accuracy: 0.6894 - main_output_loss: 1.6179 - tof_gate_loss: 0.2192 - val_loss: 1.3877 - val_main_output_accuracy: 0.7139 - val_main_output_loss: 1.2378 - val_tof_gate_loss: 0.0269\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.6792 - main_output_accuracy: 0.7125 - main_output_loss: 1.5002 - tof_gate_loss: 0.1846 - val_loss: 1.4066 - val_main_output_accuracy: 0.6982 - val_main_output_loss: 1.2556 - val_tof_gate_loss: 0.0394\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.7535 - main_output_accuracy: 0.6965 - main_output_loss: 1.5703 - tof_gate_loss: 0.2071 - val_loss: 1.4000 - val_main_output_accuracy: 0.7036 - val_main_output_loss: 1.2525 - val_tof_gate_loss: 0.0302\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.7403 - main_output_accuracy: 0.7052 - main_output_loss: 1.5606 - tof_gate_loss: 0.2248 - val_loss: 1.3787 - val_main_output_accuracy: 0.7066 - val_main_output_loss: 1.2326 - val_tof_gate_loss: 0.0314\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.6568 - main_output_accuracy: 0.7265 - main_output_loss: 1.4790 - tof_gate_loss: 0.1951 - val_loss: 1.3630 - val_main_output_accuracy: 0.7193 - val_main_output_loss: 1.2172 - val_tof_gate_loss: 0.0350\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.7220 - main_output_accuracy: 0.7088 - main_output_loss: 1.5426 - tof_gate_loss: 0.2173 - val_loss: 1.3934 - val_main_output_accuracy: 0.7095 - val_main_output_loss: 1.2489 - val_tof_gate_loss: 0.0346\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.5528 - main_output_accuracy: 0.7452 - main_output_loss: 1.3848 - tof_gate_loss: 0.1577 - val_loss: 1.3333 - val_main_output_accuracy: 0.7360 - val_main_output_loss: 1.1923 - val_tof_gate_loss: 0.0251\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.7812 - main_output_accuracy: 0.6970 - main_output_loss: 1.5973 - tof_gate_loss: 0.2434 - val_loss: 1.3619 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.2201 - val_tof_gate_loss: 0.0323\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.5768 - main_output_accuracy: 0.7390 - main_output_loss: 1.4088 - tof_gate_loss: 0.1700 - val_loss: 1.3665 - val_main_output_accuracy: 0.7198 - val_main_output_loss: 1.2276 - val_tof_gate_loss: 0.0243\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.7384 - main_output_accuracy: 0.7280 - main_output_loss: 1.5576 - tof_gate_loss: 0.2420 - val_loss: 1.3844 - val_main_output_accuracy: 0.7144 - val_main_output_loss: 1.2433 - val_tof_gate_loss: 0.0391\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.6256 - main_output_accuracy: 0.7292 - main_output_loss: 1.4563 - tof_gate_loss: 0.1862 - val_loss: 1.3573 - val_main_output_accuracy: 0.7296 - val_main_output_loss: 1.2177 - val_tof_gate_loss: 0.0371\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5852 - main_output_accuracy: 0.7463 - main_output_loss: 1.4196 - tof_gate_loss: 0.1838 - val_loss: 1.3357 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1999 - val_tof_gate_loss: 0.0263\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.6156 - main_output_accuracy: 0.7489 - main_output_loss: 1.4470 - tof_gate_loss: 0.1968 - val_loss: 1.3359 - val_main_output_accuracy: 0.7345 - val_main_output_loss: 1.1998 - val_tof_gate_loss: 0.0313\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.5447 - main_output_accuracy: 0.7767 - main_output_loss: 1.3819 - tof_gate_loss: 0.1698 - val_loss: 1.3777 - val_main_output_accuracy: 0.7110 - val_main_output_loss: 1.2426 - val_tof_gate_loss: 0.0298\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.5464 - main_output_accuracy: 0.7625 - main_output_loss: 1.3861 - tof_gate_loss: 0.1688 - val_loss: 1.4175 - val_main_output_accuracy: 0.7066 - val_main_output_loss: 1.2827 - val_tof_gate_loss: 0.0331\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - loss: 1.6134 - main_output_accuracy: 0.7538 - main_output_loss: 1.4480 - tof_gate_loss: 0.1897 - val_loss: 1.3436 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2115 - val_tof_gate_loss: 0.0238\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.6687 - main_output_accuracy: 0.7562 - main_output_loss: 1.4995 - tof_gate_loss: 0.2140 - val_loss: 1.3158 - val_main_output_accuracy: 0.7380 - val_main_output_loss: 1.1831 - val_tof_gate_loss: 0.0289\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5689 - main_output_accuracy: 0.7696 - main_output_loss: 1.4021 - tof_gate_loss: 0.2008 - val_loss: 1.3468 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.2163 - val_tof_gate_loss: 0.0238\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.5744 - main_output_accuracy: 0.7593 - main_output_loss: 1.4131 - tof_gate_loss: 0.1809 - val_loss: 1.3274 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1957 - val_tof_gate_loss: 0.0323\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 175ms/step - loss: 1.5077 - main_output_accuracy: 0.7774 - main_output_loss: 1.3469 - tof_gate_loss: 0.1810 - val_loss: 1.3264 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1972 - val_tof_gate_loss: 0.0231\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.6836 - main_output_accuracy: 0.7460 - main_output_loss: 1.5119 - tof_gate_loss: 0.2282 - val_loss: 1.3169 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.1870 - val_tof_gate_loss: 0.0312\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5640 - main_output_accuracy: 0.7697 - main_output_loss: 1.4014 - tof_gate_loss: 0.1920 - val_loss: 1.3853 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.2560 - val_tof_gate_loss: 0.0278\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.6527 - main_output_accuracy: 0.7632 - main_output_loss: 1.4849 - tof_gate_loss: 0.2231 - val_loss: 1.3314 - val_main_output_accuracy: 0.7385 - val_main_output_loss: 1.2038 - val_tof_gate_loss: 0.0238\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.4926 - main_output_accuracy: 0.7881 - main_output_loss: 1.3374 - tof_gate_loss: 0.1706 - val_loss: 1.3130 - val_main_output_accuracy: 0.7468 - val_main_output_loss: 1.1866 - val_tof_gate_loss: 0.0233\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5556 - main_output_accuracy: 0.7825 - main_output_loss: 1.3947 - tof_gate_loss: 0.1942 - val_loss: 1.3117 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1860 - val_tof_gate_loss: 0.0225\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.5517 - main_output_accuracy: 0.7799 - main_output_loss: 1.3913 - tof_gate_loss: 0.1994 - val_loss: 1.3261 - val_main_output_accuracy: 0.7399 - val_main_output_loss: 1.2013 - val_tof_gate_loss: 0.0220\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.4921 - main_output_accuracy: 0.8012 - main_output_loss: 1.3377 - tof_gate_loss: 0.1751 - val_loss: 1.3024 - val_main_output_accuracy: 0.7566 - val_main_output_loss: 1.1786 - val_tof_gate_loss: 0.0217\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 181ms/step - loss: 1.6066 - main_output_accuracy: 0.7539 - main_output_loss: 1.4445 - tof_gate_loss: 0.2168 - val_loss: 1.3156 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 1.1913 - val_tof_gate_loss: 0.0244\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 182ms/step - loss: 1.4410 - main_output_accuracy: 0.8157 - main_output_loss: 1.2914 - tof_gate_loss: 0.1642 - val_loss: 1.3221 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.1998 - val_tof_gate_loss: 0.0219\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.5352 - main_output_accuracy: 0.7900 - main_output_loss: 1.3839 - tof_gate_loss: 0.1893 - val_loss: 1.3740 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.2508 - val_tof_gate_loss: 0.0270\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4097 - main_output_accuracy: 0.8156 - main_output_loss: 1.2633 - tof_gate_loss: 0.1547 - val_loss: 1.3420 - val_main_output_accuracy: 0.7399 - val_main_output_loss: 1.2204 - val_tof_gate_loss: 0.0202\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.4693 - main_output_accuracy: 0.8122 - main_output_loss: 1.3156 - tof_gate_loss: 0.1823 - val_loss: 1.3288 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.2069 - val_tof_gate_loss: 0.0248\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.5906 - main_output_accuracy: 0.7724 - main_output_loss: 1.4294 - tof_gate_loss: 0.2247 - val_loss: 1.3769 - val_main_output_accuracy: 0.7345 - val_main_output_loss: 1.2546 - val_tof_gate_loss: 0.0290\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4643 - main_output_accuracy: 0.8081 - main_output_loss: 1.3106 - tof_gate_loss: 0.1884 - val_loss: 1.3071 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1846 - val_tof_gate_loss: 0.0314\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5362 - main_output_accuracy: 0.7871 - main_output_loss: 1.3783 - tof_gate_loss: 0.2090 - val_loss: 1.3025 - val_main_output_accuracy: 0.7532 - val_main_output_loss: 1.1817 - val_tof_gate_loss: 0.0273\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.5164 - main_output_accuracy: 0.7934 - main_output_loss: 1.3622 - tof_gate_loss: 0.1846 - val_loss: 1.3852 - val_main_output_accuracy: 0.7267 - val_main_output_loss: 1.2660 - val_tof_gate_loss: 0.0217\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4658 - main_output_accuracy: 0.8039 - main_output_loss: 1.3157 - tof_gate_loss: 0.1867 - val_loss: 1.3200 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.2006 - val_tof_gate_loss: 0.0237\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.4898 - main_output_accuracy: 0.8101 - main_output_loss: 1.3345 - tof_gate_loss: 0.2064 - val_loss: 1.3064 - val_main_output_accuracy: 0.7522 - val_main_output_loss: 1.1875 - val_tof_gate_loss: 0.0256\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.5158 - main_output_accuracy: 0.8107 - main_output_loss: 1.3591 - tof_gate_loss: 0.2108 - val_loss: 1.3249 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.2070 - val_tof_gate_loss: 0.0234\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.5842 - main_output_accuracy: 0.7875 - main_output_loss: 1.4281 - tof_gate_loss: 0.2345 - val_loss: 1.3236 - val_main_output_accuracy: 0.7434 - val_main_output_loss: 1.2050 - val_tof_gate_loss: 0.0275\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 183ms/step - loss: 1.3635 - main_output_accuracy: 0.8237 - main_output_loss: 1.2290 - tof_gate_loss: 0.1632 - val_loss: 1.3228 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.2060 - val_tof_gate_loss: 0.0232\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.3137 - main_output_accuracy: 0.8433 - main_output_loss: 1.1774 - tof_gate_loss: 0.1331 - val_loss: 1.3154 - val_main_output_accuracy: 0.7498 - val_main_output_loss: 1.2000 - val_tof_gate_loss: 0.0207\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.5256 - main_output_accuracy: 0.8035 - main_output_loss: 1.3757 - tof_gate_loss: 0.1967 - val_loss: 1.2930 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1767 - val_tof_gate_loss: 0.0249\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.4475 - main_output_accuracy: 0.8234 - main_output_loss: 1.3072 - tof_gate_loss: 0.1932 - val_loss: 1.2961 - val_main_output_accuracy: 0.7547 - val_main_output_loss: 1.1806 - val_tof_gate_loss: 0.0233\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.4254 - main_output_accuracy: 0.8335 - main_output_loss: 1.2792 - tof_gate_loss: 0.1855 - val_loss: 1.3108 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1960 - val_tof_gate_loss: 0.0215\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5064 - main_output_accuracy: 0.8225 - main_output_loss: 1.3562 - tof_gate_loss: 0.2057 - val_loss: 1.3357 - val_main_output_accuracy: 0.7429 - val_main_output_loss: 1.2221 - val_tof_gate_loss: 0.0193\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.4333 - main_output_accuracy: 0.8303 - main_output_loss: 1.2864 - tof_gate_loss: 0.1844 - val_loss: 1.3378 - val_main_output_accuracy: 0.7419 - val_main_output_loss: 1.2221 - val_tof_gate_loss: 0.0299\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.4606 - main_output_accuracy: 0.8111 - main_output_loss: 1.3160 - tof_gate_loss: 0.1817 - val_loss: 1.3105 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.1963 - val_tof_gate_loss: 0.0244\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - loss: 1.4119 - main_output_accuracy: 0.8160 - main_output_loss: 1.2722 - tof_gate_loss: 0.1842 - val_loss: 1.2998 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.1862 - val_tof_gate_loss: 0.0229\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.4056 - main_output_accuracy: 0.8273 - main_output_loss: 1.2615 - tof_gate_loss: 0.1723 - val_loss: 1.2878 - val_main_output_accuracy: 0.7605 - val_main_output_loss: 1.1757 - val_tof_gate_loss: 0.0185\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.4224 - main_output_accuracy: 0.8327 - main_output_loss: 1.2811 - tof_gate_loss: 0.1772 - val_loss: 1.3197 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.2074 - val_tof_gate_loss: 0.0233\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.3533 - main_output_accuracy: 0.8528 - main_output_loss: 1.2160 - tof_gate_loss: 0.1609 - val_loss: 1.3099 - val_main_output_accuracy: 0.7532 - val_main_output_loss: 1.1978 - val_tof_gate_loss: 0.0232\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4583 - main_output_accuracy: 0.8278 - main_output_loss: 1.3186 - tof_gate_loss: 0.1928 - val_loss: 1.2905 - val_main_output_accuracy: 0.7655 - val_main_output_loss: 1.1797 - val_tof_gate_loss: 0.0190\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.4573 - main_output_accuracy: 0.8268 - main_output_loss: 1.3140 - tof_gate_loss: 0.1779 - val_loss: 1.2813 - val_main_output_accuracy: 0.7650 - val_main_output_loss: 1.1706 - val_tof_gate_loss: 0.0219\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.2983 - main_output_accuracy: 0.8659 - main_output_loss: 1.1589 - tof_gate_loss: 0.1604 - val_loss: 1.3528 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.2418 - val_tof_gate_loss: 0.0233\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.4004 - main_output_accuracy: 0.8466 - main_output_loss: 1.2612 - tof_gate_loss: 0.1778 - val_loss: 1.3172 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.2062 - val_tof_gate_loss: 0.0235\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.4747 - main_output_accuracy: 0.8152 - main_output_loss: 1.3322 - tof_gate_loss: 0.1956 - val_loss: 1.3033 - val_main_output_accuracy: 0.7625 - val_main_output_loss: 1.1931 - val_tof_gate_loss: 0.0222\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.4806 - main_output_accuracy: 0.8160 - main_output_loss: 1.3286 - tof_gate_loss: 0.2058 - val_loss: 1.3274 - val_main_output_accuracy: 0.7566 - val_main_output_loss: 1.2180 - val_tof_gate_loss: 0.0217\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 182ms/step - loss: 1.4158 - main_output_accuracy: 0.8460 - main_output_loss: 1.2752 - tof_gate_loss: 0.1770 - val_loss: 1.3080 - val_main_output_accuracy: 0.7605 - val_main_output_loss: 1.1990 - val_tof_gate_loss: 0.0216\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.3868 - main_output_accuracy: 0.8445 - main_output_loss: 1.2453 - tof_gate_loss: 0.1849 - val_loss: 1.3264 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.2173 - val_tof_gate_loss: 0.0223\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.4466 - main_output_accuracy: 0.8346 - main_output_loss: 1.3049 - tof_gate_loss: 0.2109 - val_loss: 1.2949 - val_main_output_accuracy: 0.7645 - val_main_output_loss: 1.1860 - val_tof_gate_loss: 0.0226\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.2510 - main_output_accuracy: 0.8824 - main_output_loss: 1.1183 - tof_gate_loss: 0.1420 - val_loss: 1.3157 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.2076 - val_tof_gate_loss: 0.0196\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.3222 - main_output_accuracy: 0.8591 - main_output_loss: 1.1883 - tof_gate_loss: 0.1555 - val_loss: 1.3390 - val_main_output_accuracy: 0.7552 - val_main_output_loss: 1.2310 - val_tof_gate_loss: 0.0205\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.4008 - main_output_accuracy: 0.8476 - main_output_loss: 1.2611 - tof_gate_loss: 0.1796 - val_loss: 1.3156 - val_main_output_accuracy: 0.7625 - val_main_output_loss: 1.2080 - val_tof_gate_loss: 0.0211\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.4919 - main_output_accuracy: 0.8400 - main_output_loss: 1.3464 - tof_gate_loss: 0.2149 - val_loss: 1.2836 - val_main_output_accuracy: 0.7704 - val_main_output_loss: 1.1764 - val_tof_gate_loss: 0.0203\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4679 - main_output_accuracy: 0.8405 - main_output_loss: 1.3297 - tof_gate_loss: 0.2018 - val_loss: 1.2984 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1912 - val_tof_gate_loss: 0.0219\n",
      "Epoch 101/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.3410 - main_output_accuracy: 0.8583 - main_output_loss: 1.2044 - tof_gate_loss: 0.1700 - val_loss: 1.2901 - val_main_output_accuracy: 0.7674 - val_main_output_loss: 1.1837 - val_tof_gate_loss: 0.0198\n",
      "Epoch 102/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.4002 - main_output_accuracy: 0.8427 - main_output_loss: 1.2606 - tof_gate_loss: 0.1861 - val_loss: 1.3107 - val_main_output_accuracy: 0.7630 - val_main_output_loss: 1.2042 - val_tof_gate_loss: 0.0210\n",
      "Epoch 103/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.2256 - main_output_accuracy: 0.8797 - main_output_loss: 1.0918 - tof_gate_loss: 0.1361 - val_loss: 1.3059 - val_main_output_accuracy: 0.7605 - val_main_output_loss: 1.1997 - val_tof_gate_loss: 0.0211\n",
      "Epoch 104/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.3218 - main_output_accuracy: 0.8720 - main_output_loss: 1.1887 - tof_gate_loss: 0.1642 - val_loss: 1.3028 - val_main_output_accuracy: 0.7630 - val_main_output_loss: 1.1965 - val_tof_gate_loss: 0.0214\n",
      "Epoch 105/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4361 - main_output_accuracy: 0.8469 - main_output_loss: 1.2934 - tof_gate_loss: 0.2055 - val_loss: 1.3103 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.2048 - val_tof_gate_loss: 0.0203\n",
      "Epoch 106/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.3189 - main_output_accuracy: 0.8598 - main_output_loss: 1.1923 - tof_gate_loss: 0.1636 - val_loss: 1.3003 - val_main_output_accuracy: 0.7640 - val_main_output_loss: 1.1953 - val_tof_gate_loss: 0.0197\n",
      "Epoch 107/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.3812 - main_output_accuracy: 0.8539 - main_output_loss: 1.2428 - tof_gate_loss: 0.1787 - val_loss: 1.3054 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1999 - val_tof_gate_loss: 0.0209\n",
      "Epoch 108/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.3348 - main_output_accuracy: 0.8560 - main_output_loss: 1.2003 - tof_gate_loss: 0.1694 - val_loss: 1.3141 - val_main_output_accuracy: 0.7547 - val_main_output_loss: 1.2092 - val_tof_gate_loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Saving artifacts for Fold 1 ---\n",
      "Scaler, feature_cols, maxlen, and classes saved.\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step\n",
      "Fold 1 Accuracy: 0.7650\n",
      "\n",
      "=== Fold 2/4 ===\n",
      "Loading data for fold 2...\n",
      "Fold data loaded.\n",
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 221ms/step - loss: 3.7903 - main_output_accuracy: 0.1039 - main_output_loss: 3.2797 - tof_gate_loss: 0.6200 - val_loss: 2.9819 - val_main_output_accuracy: 0.2581 - val_main_output_loss: 2.5273 - val_tof_gate_loss: 0.3910\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 3.1338 - main_output_accuracy: 0.2152 - main_output_loss: 2.6998 - tof_gate_loss: 0.3106 - val_loss: 2.6030 - val_main_output_accuracy: 0.3842 - val_main_output_loss: 2.1994 - val_tof_gate_loss: 0.2243\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 2.8743 - main_output_accuracy: 0.2870 - main_output_loss: 2.4678 - tof_gate_loss: 0.2616 - val_loss: 2.2281 - val_main_output_accuracy: 0.4843 - val_main_output_loss: 1.8661 - val_tof_gate_loss: 0.1168\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 2.6774 - main_output_accuracy: 0.3319 - main_output_loss: 2.2997 - tof_gate_loss: 0.2148 - val_loss: 1.9936 - val_main_output_accuracy: 0.5402 - val_main_output_loss: 1.6583 - val_tof_gate_loss: 0.0794\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 2.6043 - main_output_accuracy: 0.3701 - main_output_loss: 2.2403 - tof_gate_loss: 0.2552 - val_loss: 1.8984 - val_main_output_accuracy: 0.5667 - val_main_output_loss: 1.5824 - val_tof_gate_loss: 0.0703\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 2.5144 - main_output_accuracy: 0.3965 - main_output_loss: 2.1636 - tof_gate_loss: 0.2606 - val_loss: 1.8367 - val_main_output_accuracy: 0.5819 - val_main_output_loss: 1.5396 - val_tof_gate_loss: 0.0548\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 2.4244 - main_output_accuracy: 0.4380 - main_output_loss: 2.0913 - tof_gate_loss: 0.2572 - val_loss: 1.7540 - val_main_output_accuracy: 0.6163 - val_main_output_loss: 1.4717 - val_tof_gate_loss: 0.0531\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 2.3708 - main_output_accuracy: 0.4525 - main_output_loss: 2.0462 - tof_gate_loss: 0.2563 - val_loss: 1.7047 - val_main_output_accuracy: 0.6217 - val_main_output_loss: 1.4372 - val_tof_gate_loss: 0.0426\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 2.2982 - main_output_accuracy: 0.4743 - main_output_loss: 1.9915 - tof_gate_loss: 0.2476 - val_loss: 1.7440 - val_main_output_accuracy: 0.6001 - val_main_output_loss: 1.4885 - val_tof_gate_loss: 0.0440\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 2.2818 - main_output_accuracy: 0.4841 - main_output_loss: 1.9850 - tof_gate_loss: 0.2507 - val_loss: 1.6530 - val_main_output_accuracy: 0.6394 - val_main_output_loss: 1.4104 - val_tof_gate_loss: 0.0332\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 2.1938 - main_output_accuracy: 0.5137 - main_output_loss: 1.9142 - tof_gate_loss: 0.2208 - val_loss: 1.6526 - val_main_output_accuracy: 0.6138 - val_main_output_loss: 1.4204 - val_tof_gate_loss: 0.0329\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 2.1646 - main_output_accuracy: 0.5262 - main_output_loss: 1.8941 - tof_gate_loss: 0.2289 - val_loss: 1.5798 - val_main_output_accuracy: 0.6614 - val_main_output_loss: 1.3563 - val_tof_gate_loss: 0.0344\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 2.0514 - main_output_accuracy: 0.5439 - main_output_loss: 1.7977 - tof_gate_loss: 0.2027 - val_loss: 1.5766 - val_main_output_accuracy: 0.6580 - val_main_output_loss: 1.3607 - val_tof_gate_loss: 0.0356\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 2.0927 - main_output_accuracy: 0.5505 - main_output_loss: 1.8413 - tof_gate_loss: 0.2188 - val_loss: 1.5340 - val_main_output_accuracy: 0.6811 - val_main_output_loss: 1.3241 - val_tof_gate_loss: 0.0432\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 2.0864 - main_output_accuracy: 0.5387 - main_output_loss: 1.8392 - tof_gate_loss: 0.2383 - val_loss: 1.5155 - val_main_output_accuracy: 0.6668 - val_main_output_loss: 1.3130 - val_tof_gate_loss: 0.0385\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 2.0419 - main_output_accuracy: 0.5828 - main_output_loss: 1.8040 - tof_gate_loss: 0.2150 - val_loss: 1.5063 - val_main_output_accuracy: 0.6683 - val_main_output_loss: 1.3099 - val_tof_gate_loss: 0.0374\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 2.0183 - main_output_accuracy: 0.5877 - main_output_loss: 1.7835 - tof_gate_loss: 0.2156 - val_loss: 1.5052 - val_main_output_accuracy: 0.6732 - val_main_output_loss: 1.3150 - val_tof_gate_loss: 0.0325\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.9947 - main_output_accuracy: 0.5827 - main_output_loss: 1.7720 - tof_gate_loss: 0.1993 - val_loss: 1.4890 - val_main_output_accuracy: 0.6879 - val_main_output_loss: 1.3040 - val_tof_gate_loss: 0.0336\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.9752 - main_output_accuracy: 0.5969 - main_output_loss: 1.7529 - tof_gate_loss: 0.2160 - val_loss: 1.4555 - val_main_output_accuracy: 0.6938 - val_main_output_loss: 1.2744 - val_tof_gate_loss: 0.0351\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 2.0540 - main_output_accuracy: 0.5769 - main_output_loss: 1.8244 - tof_gate_loss: 0.2676 - val_loss: 1.4279 - val_main_output_accuracy: 0.7080 - val_main_output_loss: 1.2511 - val_tof_gate_loss: 0.0288\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.9068 - main_output_accuracy: 0.6125 - main_output_loss: 1.6969 - tof_gate_loss: 0.1903 - val_loss: 1.4565 - val_main_output_accuracy: 0.7056 - val_main_output_loss: 1.2832 - val_tof_gate_loss: 0.0302\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.8930 - main_output_accuracy: 0.6233 - main_output_loss: 1.6838 - tof_gate_loss: 0.2077 - val_loss: 1.3891 - val_main_output_accuracy: 0.7291 - val_main_output_loss: 1.2183 - val_tof_gate_loss: 0.0331\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.7980 - main_output_accuracy: 0.6513 - main_output_loss: 1.5953 - tof_gate_loss: 0.1730 - val_loss: 1.4084 - val_main_output_accuracy: 0.7002 - val_main_output_loss: 1.2417 - val_tof_gate_loss: 0.0292\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.8161 - main_output_accuracy: 0.6469 - main_output_loss: 1.6149 - tof_gate_loss: 0.1957 - val_loss: 1.3894 - val_main_output_accuracy: 0.7125 - val_main_output_loss: 1.2262 - val_tof_gate_loss: 0.0268\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.8304 - main_output_accuracy: 0.6485 - main_output_loss: 1.6309 - tof_gate_loss: 0.2051 - val_loss: 1.4127 - val_main_output_accuracy: 0.7012 - val_main_output_loss: 1.2514 - val_tof_gate_loss: 0.0296\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.8297 - main_output_accuracy: 0.6503 - main_output_loss: 1.6322 - tof_gate_loss: 0.2050 - val_loss: 1.3862 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 1.2274 - val_tof_gate_loss: 0.0280\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.7454 - main_output_accuracy: 0.6552 - main_output_loss: 1.5564 - tof_gate_loss: 0.1684 - val_loss: 1.3731 - val_main_output_accuracy: 0.7174 - val_main_output_loss: 1.2156 - val_tof_gate_loss: 0.0334\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.8861 - main_output_accuracy: 0.6626 - main_output_loss: 1.6885 - tof_gate_loss: 0.2491 - val_loss: 1.3609 - val_main_output_accuracy: 0.7223 - val_main_output_loss: 1.2048 - val_tof_gate_loss: 0.0371\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.7550 - main_output_accuracy: 0.6772 - main_output_loss: 1.5652 - tof_gate_loss: 0.1907 - val_loss: 1.3940 - val_main_output_accuracy: 0.7007 - val_main_output_loss: 1.2417 - val_tof_gate_loss: 0.0268\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.7200 - main_output_accuracy: 0.6980 - main_output_loss: 1.5370 - tof_gate_loss: 0.1739 - val_loss: 1.3373 - val_main_output_accuracy: 0.7336 - val_main_output_loss: 1.1863 - val_tof_gate_loss: 0.0293\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.7868 - main_output_accuracy: 0.6749 - main_output_loss: 1.6012 - tof_gate_loss: 0.1951 - val_loss: 1.3877 - val_main_output_accuracy: 0.7046 - val_main_output_loss: 1.2380 - val_tof_gate_loss: 0.0310\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.7584 - main_output_accuracy: 0.6751 - main_output_loss: 1.5709 - tof_gate_loss: 0.2033 - val_loss: 1.3529 - val_main_output_accuracy: 0.7242 - val_main_output_loss: 1.2058 - val_tof_gate_loss: 0.0246\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.7530 - main_output_accuracy: 0.7050 - main_output_loss: 1.5708 - tof_gate_loss: 0.1994 - val_loss: 1.3220 - val_main_output_accuracy: 0.7434 - val_main_output_loss: 1.1762 - val_tof_gate_loss: 0.0240\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 175ms/step - loss: 1.7215 - main_output_accuracy: 0.7052 - main_output_loss: 1.5366 - tof_gate_loss: 0.2010 - val_loss: 1.3359 - val_main_output_accuracy: 0.7350 - val_main_output_loss: 1.1907 - val_tof_gate_loss: 0.0300\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.6984 - main_output_accuracy: 0.7028 - main_output_loss: 1.5322 - tof_gate_loss: 0.1895 - val_loss: 1.3242 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1801 - val_tof_gate_loss: 0.0311\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - loss: 1.6955 - main_output_accuracy: 0.7005 - main_output_loss: 1.5167 - tof_gate_loss: 0.1965 - val_loss: 1.3245 - val_main_output_accuracy: 0.7370 - val_main_output_loss: 1.1823 - val_tof_gate_loss: 0.0261\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.7418 - main_output_accuracy: 0.6887 - main_output_loss: 1.5662 - tof_gate_loss: 0.1982 - val_loss: 1.2980 - val_main_output_accuracy: 0.7542 - val_main_output_loss: 1.1558 - val_tof_gate_loss: 0.0332\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.6249 - main_output_accuracy: 0.7376 - main_output_loss: 1.4577 - tof_gate_loss: 0.1724 - val_loss: 1.3190 - val_main_output_accuracy: 0.7385 - val_main_output_loss: 1.1799 - val_tof_gate_loss: 0.0217\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5691 - main_output_accuracy: 0.7330 - main_output_loss: 1.4029 - tof_gate_loss: 0.1532 - val_loss: 1.2930 - val_main_output_accuracy: 0.7429 - val_main_output_loss: 1.1548 - val_tof_gate_loss: 0.0240\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.6295 - main_output_accuracy: 0.7300 - main_output_loss: 1.4577 - tof_gate_loss: 0.1727 - val_loss: 1.3013 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.1653 - val_tof_gate_loss: 0.0171\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 1.6965 - main_output_accuracy: 0.7228 - main_output_loss: 1.5239 - tof_gate_loss: 0.2094 - val_loss: 1.3010 - val_main_output_accuracy: 0.7336 - val_main_output_loss: 1.1642 - val_tof_gate_loss: 0.0262\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.5749 - main_output_accuracy: 0.7458 - main_output_loss: 1.4117 - tof_gate_loss: 0.1660 - val_loss: 1.2888 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.1542 - val_tof_gate_loss: 0.0194\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.5652 - main_output_accuracy: 0.7542 - main_output_loss: 1.3995 - tof_gate_loss: 0.1623 - val_loss: 1.3059 - val_main_output_accuracy: 0.7355 - val_main_output_loss: 1.1724 - val_tof_gate_loss: 0.0193\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6458 - main_output_accuracy: 0.7395 - main_output_loss: 1.4745 - tof_gate_loss: 0.1998 - val_loss: 1.3155 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1803 - val_tof_gate_loss: 0.0317\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.6130 - main_output_accuracy: 0.7528 - main_output_loss: 1.4522 - tof_gate_loss: 0.1954 - val_loss: 1.2815 - val_main_output_accuracy: 0.7576 - val_main_output_loss: 1.1491 - val_tof_gate_loss: 0.0217\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.5362 - main_output_accuracy: 0.7697 - main_output_loss: 1.3736 - tof_gate_loss: 0.1696 - val_loss: 1.2828 - val_main_output_accuracy: 0.7522 - val_main_output_loss: 1.1522 - val_tof_gate_loss: 0.0160\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.5937 - main_output_accuracy: 0.7710 - main_output_loss: 1.4267 - tof_gate_loss: 0.1942 - val_loss: 1.2812 - val_main_output_accuracy: 0.7576 - val_main_output_loss: 1.1483 - val_tof_gate_loss: 0.0335\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.6318 - main_output_accuracy: 0.7341 - main_output_loss: 1.4635 - tof_gate_loss: 0.2065 - val_loss: 1.2611 - val_main_output_accuracy: 0.7576 - val_main_output_loss: 1.1308 - val_tof_gate_loss: 0.0231\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.4930 - main_output_accuracy: 0.7795 - main_output_loss: 1.3358 - tof_gate_loss: 0.1696 - val_loss: 1.2905 - val_main_output_accuracy: 0.7478 - val_main_output_loss: 1.1601 - val_tof_gate_loss: 0.0260\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.6447 - main_output_accuracy: 0.7584 - main_output_loss: 1.4766 - tof_gate_loss: 0.2100 - val_loss: 1.2734 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1433 - val_tof_gate_loss: 0.0267\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.6053 - main_output_accuracy: 0.7786 - main_output_loss: 1.4349 - tof_gate_loss: 0.2086 - val_loss: 1.2718 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.1435 - val_tof_gate_loss: 0.0221\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.5670 - main_output_accuracy: 0.7623 - main_output_loss: 1.4053 - tof_gate_loss: 0.1898 - val_loss: 1.2746 - val_main_output_accuracy: 0.7532 - val_main_output_loss: 1.1475 - val_tof_gate_loss: 0.0190\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5213 - main_output_accuracy: 0.7860 - main_output_loss: 1.3618 - tof_gate_loss: 0.1796 - val_loss: 1.2743 - val_main_output_accuracy: 0.7640 - val_main_output_loss: 1.1474 - val_tof_gate_loss: 0.0214\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5323 - main_output_accuracy: 0.7885 - main_output_loss: 1.3737 - tof_gate_loss: 0.1691 - val_loss: 1.2656 - val_main_output_accuracy: 0.7674 - val_main_output_loss: 1.1396 - val_tof_gate_loss: 0.0194\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.6037 - main_output_accuracy: 0.7711 - main_output_loss: 1.4412 - tof_gate_loss: 0.2137 - val_loss: 1.2624 - val_main_output_accuracy: 0.7709 - val_main_output_loss: 1.1364 - val_tof_gate_loss: 0.0223\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.5471 - main_output_accuracy: 0.7771 - main_output_loss: 1.3849 - tof_gate_loss: 0.1995 - val_loss: 1.2951 - val_main_output_accuracy: 0.7444 - val_main_output_loss: 1.1694 - val_tof_gate_loss: 0.0250\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.6374 - main_output_accuracy: 0.7743 - main_output_loss: 1.4702 - tof_gate_loss: 0.2282 - val_loss: 1.2533 - val_main_output_accuracy: 0.7723 - val_main_output_loss: 1.1275 - val_tof_gate_loss: 0.0299\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.4188 - main_output_accuracy: 0.8007 - main_output_loss: 1.2675 - tof_gate_loss: 0.1503 - val_loss: 1.2775 - val_main_output_accuracy: 0.7605 - val_main_output_loss: 1.1528 - val_tof_gate_loss: 0.0256\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.4803 - main_output_accuracy: 0.8032 - main_output_loss: 1.3273 - tof_gate_loss: 0.1736 - val_loss: 1.2740 - val_main_output_accuracy: 0.7493 - val_main_output_loss: 1.1520 - val_tof_gate_loss: 0.0162\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.4816 - main_output_accuracy: 0.7948 - main_output_loss: 1.3248 - tof_gate_loss: 0.1736 - val_loss: 1.2660 - val_main_output_accuracy: 0.7689 - val_main_output_loss: 1.1436 - val_tof_gate_loss: 0.0196\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.5744 - main_output_accuracy: 0.7759 - main_output_loss: 1.4125 - tof_gate_loss: 0.2068 - val_loss: 1.2891 - val_main_output_accuracy: 0.7502 - val_main_output_loss: 1.1658 - val_tof_gate_loss: 0.0287\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.4700 - main_output_accuracy: 0.7931 - main_output_loss: 1.3144 - tof_gate_loss: 0.1784 - val_loss: 1.2823 - val_main_output_accuracy: 0.7596 - val_main_output_loss: 1.1608 - val_tof_gate_loss: 0.0231\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 1.6056 - main_output_accuracy: 0.7805 - main_output_loss: 1.4486 - tof_gate_loss: 0.2206 - val_loss: 1.2940 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1720 - val_tof_gate_loss: 0.0254\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - loss: 1.5154 - main_output_accuracy: 0.8032 - main_output_loss: 1.3595 - tof_gate_loss: 0.1914 - val_loss: 1.2735 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1524 - val_tof_gate_loss: 0.0247\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.5239 - main_output_accuracy: 0.8030 - main_output_loss: 1.3675 - tof_gate_loss: 0.1908 - val_loss: 1.2800 - val_main_output_accuracy: 0.7591 - val_main_output_loss: 1.1604 - val_tof_gate_loss: 0.0186\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.5015 - main_output_accuracy: 0.7893 - main_output_loss: 1.3494 - tof_gate_loss: 0.1803 - val_loss: 1.3154 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.1958 - val_tof_gate_loss: 0.0240\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 1.5782 - main_output_accuracy: 0.7937 - main_output_loss: 1.4181 - tof_gate_loss: 0.2175 - val_loss: 1.2446 - val_main_output_accuracy: 0.7709 - val_main_output_loss: 1.1250 - val_tof_gate_loss: 0.0231\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5758 - main_output_accuracy: 0.8015 - main_output_loss: 1.4177 - tof_gate_loss: 0.2097 - val_loss: 1.2605 - val_main_output_accuracy: 0.7620 - val_main_output_loss: 1.1407 - val_tof_gate_loss: 0.0258\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - loss: 1.6235 - main_output_accuracy: 0.7610 - main_output_loss: 1.4672 - tof_gate_loss: 0.2370 - val_loss: 1.2955 - val_main_output_accuracy: 0.7517 - val_main_output_loss: 1.1766 - val_tof_gate_loss: 0.0255\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.3816 - main_output_accuracy: 0.8327 - main_output_loss: 1.2353 - tof_gate_loss: 0.1579 - val_loss: 1.2632 - val_main_output_accuracy: 0.7674 - val_main_output_loss: 1.1450 - val_tof_gate_loss: 0.0230\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.4707 - main_output_accuracy: 0.8193 - main_output_loss: 1.3190 - tof_gate_loss: 0.1870 - val_loss: 1.2466 - val_main_output_accuracy: 0.7758 - val_main_output_loss: 1.1292 - val_tof_gate_loss: 0.0200\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5216 - main_output_accuracy: 0.8244 - main_output_loss: 1.3622 - tof_gate_loss: 0.2068 - val_loss: 1.2530 - val_main_output_accuracy: 0.7704 - val_main_output_loss: 1.1355 - val_tof_gate_loss: 0.0235\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.4238 - main_output_accuracy: 0.8252 - main_output_loss: 1.2751 - tof_gate_loss: 0.1705 - val_loss: 1.2574 - val_main_output_accuracy: 0.7674 - val_main_output_loss: 1.1413 - val_tof_gate_loss: 0.0211\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.4030 - main_output_accuracy: 0.8393 - main_output_loss: 1.2487 - tof_gate_loss: 0.1821 - val_loss: 1.2928 - val_main_output_accuracy: 0.7522 - val_main_output_loss: 1.1771 - val_tof_gate_loss: 0.0190\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.4374 - main_output_accuracy: 0.8245 - main_output_loss: 1.2884 - tof_gate_loss: 0.1776 - val_loss: 1.2780 - val_main_output_accuracy: 0.7601 - val_main_output_loss: 1.1630 - val_tof_gate_loss: 0.0185\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.5464 - main_output_accuracy: 0.7788 - main_output_loss: 1.3869 - tof_gate_loss: 0.2104 - val_loss: 1.2636 - val_main_output_accuracy: 0.7713 - val_main_output_loss: 1.1488 - val_tof_gate_loss: 0.0199\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.4439 - main_output_accuracy: 0.8343 - main_output_loss: 1.2977 - tof_gate_loss: 0.1813 - val_loss: 1.2905 - val_main_output_accuracy: 0.7581 - val_main_output_loss: 1.1749 - val_tof_gate_loss: 0.0242\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4609 - main_output_accuracy: 0.8198 - main_output_loss: 1.3103 - tof_gate_loss: 0.1932 - val_loss: 1.2700 - val_main_output_accuracy: 0.7674 - val_main_output_loss: 1.1561 - val_tof_gate_loss: 0.0185\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.3860 - main_output_accuracy: 0.8281 - main_output_loss: 1.2434 - tof_gate_loss: 0.1654 - val_loss: 1.2800 - val_main_output_accuracy: 0.7630 - val_main_output_loss: 1.1658 - val_tof_gate_loss: 0.0265\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4087 - main_output_accuracy: 0.8347 - main_output_loss: 1.2559 - tof_gate_loss: 0.1916 - val_loss: 1.2400 - val_main_output_accuracy: 0.7797 - val_main_output_loss: 1.1251 - val_tof_gate_loss: 0.0287\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 1.3823 - main_output_accuracy: 0.8308 - main_output_loss: 1.2401 - tof_gate_loss: 0.1579 - val_loss: 1.2571 - val_main_output_accuracy: 0.7792 - val_main_output_loss: 1.1450 - val_tof_gate_loss: 0.0200\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.4285 - main_output_accuracy: 0.8342 - main_output_loss: 1.2819 - tof_gate_loss: 0.1826 - val_loss: 1.2696 - val_main_output_accuracy: 0.7723 - val_main_output_loss: 1.1568 - val_tof_gate_loss: 0.0229\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.5287 - main_output_accuracy: 0.8113 - main_output_loss: 1.3869 - tof_gate_loss: 0.2150 - val_loss: 1.2590 - val_main_output_accuracy: 0.7772 - val_main_output_loss: 1.1468 - val_tof_gate_loss: 0.0223\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 181ms/step - loss: 1.4239 - main_output_accuracy: 0.8445 - main_output_loss: 1.2971 - tof_gate_loss: 0.1822 - val_loss: 1.2823 - val_main_output_accuracy: 0.7689 - val_main_output_loss: 1.1702 - val_tof_gate_loss: 0.0215\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4911 - main_output_accuracy: 0.8195 - main_output_loss: 1.3317 - tof_gate_loss: 0.2006 - val_loss: 1.2377 - val_main_output_accuracy: 0.7880 - val_main_output_loss: 1.1258 - val_tof_gate_loss: 0.0233\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.5019 - main_output_accuracy: 0.8153 - main_output_loss: 1.3480 - tof_gate_loss: 0.2092 - val_loss: 1.2480 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1376 - val_tof_gate_loss: 0.0190\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.3617 - main_output_accuracy: 0.8504 - main_output_loss: 1.2166 - tof_gate_loss: 0.1769 - val_loss: 1.2468 - val_main_output_accuracy: 0.7861 - val_main_output_loss: 1.1367 - val_tof_gate_loss: 0.0198\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4638 - main_output_accuracy: 0.8519 - main_output_loss: 1.3145 - tof_gate_loss: 0.2108 - val_loss: 1.2655 - val_main_output_accuracy: 0.7763 - val_main_output_loss: 1.1561 - val_tof_gate_loss: 0.0186\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.4037 - main_output_accuracy: 0.8427 - main_output_loss: 1.2607 - tof_gate_loss: 0.1724 - val_loss: 1.2665 - val_main_output_accuracy: 0.7723 - val_main_output_loss: 1.1561 - val_tof_gate_loss: 0.0238\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.4746 - main_output_accuracy: 0.8333 - main_output_loss: 1.3444 - tof_gate_loss: 0.2028 - val_loss: 1.2595 - val_main_output_accuracy: 0.7777 - val_main_output_loss: 1.1492 - val_tof_gate_loss: 0.0223\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.4606 - main_output_accuracy: 0.8336 - main_output_loss: 1.3143 - tof_gate_loss: 0.1964 - val_loss: 1.2646 - val_main_output_accuracy: 0.7816 - val_main_output_loss: 1.1544 - val_tof_gate_loss: 0.0248\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.3927 - main_output_accuracy: 0.8414 - main_output_loss: 1.2520 - tof_gate_loss: 0.1862 - val_loss: 1.2734 - val_main_output_accuracy: 0.7679 - val_main_output_loss: 1.1636 - val_tof_gate_loss: 0.0253\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.3403 - main_output_accuracy: 0.8649 - main_output_loss: 1.2032 - tof_gate_loss: 0.1744 - val_loss: 1.2486 - val_main_output_accuracy: 0.7753 - val_main_output_loss: 1.1398 - val_tof_gate_loss: 0.0200\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - loss: 1.4060 - main_output_accuracy: 0.8442 - main_output_loss: 1.2645 - tof_gate_loss: 0.1813 - val_loss: 1.2464 - val_main_output_accuracy: 0.7856 - val_main_output_loss: 1.1384 - val_tof_gate_loss: 0.0174\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.4603 - main_output_accuracy: 0.8418 - main_output_loss: 1.3137 - tof_gate_loss: 0.2088 - val_loss: 1.2362 - val_main_output_accuracy: 0.7851 - val_main_output_loss: 1.1280 - val_tof_gate_loss: 0.0218\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.4178 - main_output_accuracy: 0.8328 - main_output_loss: 1.2734 - tof_gate_loss: 0.2058 - val_loss: 1.2802 - val_main_output_accuracy: 0.7718 - val_main_output_loss: 1.1728 - val_tof_gate_loss: 0.0198\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.3477 - main_output_accuracy: 0.8533 - main_output_loss: 1.2088 - tof_gate_loss: 0.1732 - val_loss: 1.2606 - val_main_output_accuracy: 0.7802 - val_main_output_loss: 1.1537 - val_tof_gate_loss: 0.0185\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.3367 - main_output_accuracy: 0.8584 - main_output_loss: 1.1898 - tof_gate_loss: 0.1756 - val_loss: 1.2596 - val_main_output_accuracy: 0.7738 - val_main_output_loss: 1.1527 - val_tof_gate_loss: 0.0205\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.3920 - main_output_accuracy: 0.8570 - main_output_loss: 1.2590 - tof_gate_loss: 0.1852 - val_loss: 1.2643 - val_main_output_accuracy: 0.7713 - val_main_output_loss: 1.1581 - val_tof_gate_loss: 0.0191\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4247 - main_output_accuracy: 0.8417 - main_output_loss: 1.2823 - tof_gate_loss: 0.1939 - val_loss: 1.2375 - val_main_output_accuracy: 0.7836 - val_main_output_loss: 1.1314 - val_tof_gate_loss: 0.0192\n",
      "Epoch 101/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.2828 - main_output_accuracy: 0.8683 - main_output_loss: 1.1548 - tof_gate_loss: 0.1535 - val_loss: 1.2652 - val_main_output_accuracy: 0.7718 - val_main_output_loss: 1.1592 - val_tof_gate_loss: 0.0197\n",
      "Epoch 102/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 1.4004 - main_output_accuracy: 0.8528 - main_output_loss: 1.2574 - tof_gate_loss: 0.1939 - val_loss: 1.2521 - val_main_output_accuracy: 0.7787 - val_main_output_loss: 1.1462 - val_tof_gate_loss: 0.0192\n",
      "Epoch 103/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 1.4057 - main_output_accuracy: 0.8583 - main_output_loss: 1.2653 - tof_gate_loss: 0.1830 - val_loss: 1.2632 - val_main_output_accuracy: 0.7792 - val_main_output_loss: 1.1581 - val_tof_gate_loss: 0.0182\n",
      "Epoch 104/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - loss: 1.2831 - main_output_accuracy: 0.8696 - main_output_loss: 1.1502 - tof_gate_loss: 0.1523 - val_loss: 1.2549 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1502 - val_tof_gate_loss: 0.0186\n",
      "Epoch 105/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4708 - main_output_accuracy: 0.8359 - main_output_loss: 1.3182 - tof_gate_loss: 0.2129 - val_loss: 1.2507 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1458 - val_tof_gate_loss: 0.0176\n",
      "Epoch 106/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.3722 - main_output_accuracy: 0.8680 - main_output_loss: 1.2339 - tof_gate_loss: 0.1955 - val_loss: 1.2501 - val_main_output_accuracy: 0.7802 - val_main_output_loss: 1.1450 - val_tof_gate_loss: 0.0207\n",
      "Epoch 107/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 179ms/step - loss: 1.3197 - main_output_accuracy: 0.8705 - main_output_loss: 1.1905 - tof_gate_loss: 0.1751 - val_loss: 1.2711 - val_main_output_accuracy: 0.7772 - val_main_output_loss: 1.1657 - val_tof_gate_loss: 0.0216\n",
      "Epoch 108/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 180ms/step - loss: 1.2859 - main_output_accuracy: 0.8651 - main_output_loss: 1.1520 - tof_gate_loss: 0.1628 - val_loss: 1.2624 - val_main_output_accuracy: 0.7802 - val_main_output_loss: 1.1586 - val_tof_gate_loss: 0.0179\n",
      "Epoch 109/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 182ms/step - loss: 1.4856 - main_output_accuracy: 0.8418 - main_output_loss: 1.3357 - tof_gate_loss: 0.2181 - val_loss: 1.2561 - val_main_output_accuracy: 0.7812 - val_main_output_loss: 1.1527 - val_tof_gate_loss: 0.0184\n",
      "Epoch 110/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.3943 - main_output_accuracy: 0.8578 - main_output_loss: 1.2556 - tof_gate_loss: 0.1823 - val_loss: 1.2557 - val_main_output_accuracy: 0.7836 - val_main_output_loss: 1.1518 - val_tof_gate_loss: 0.0193\n",
      "Epoch 111/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4617 - main_output_accuracy: 0.8284 - main_output_loss: 1.3179 - tof_gate_loss: 0.2151 - val_loss: 1.2517 - val_main_output_accuracy: 0.7816 - val_main_output_loss: 1.1481 - val_tof_gate_loss: 0.0193\n",
      "Epoch 112/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.3098 - main_output_accuracy: 0.8685 - main_output_loss: 1.1758 - tof_gate_loss: 0.1661 - val_loss: 1.2444 - val_main_output_accuracy: 0.7846 - val_main_output_loss: 1.1408 - val_tof_gate_loss: 0.0176\n",
      "Epoch 113/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.4840 - main_output_accuracy: 0.8304 - main_output_loss: 1.3408 - tof_gate_loss: 0.2166 - val_loss: 1.2440 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1407 - val_tof_gate_loss: 0.0181\n",
      "Epoch 114/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.3972 - main_output_accuracy: 0.8622 - main_output_loss: 1.2561 - tof_gate_loss: 0.1931 - val_loss: 1.2395 - val_main_output_accuracy: 0.7885 - val_main_output_loss: 1.1363 - val_tof_gate_loss: 0.0196\n",
      "Epoch 115/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.3503 - main_output_accuracy: 0.8588 - main_output_loss: 1.2249 - tof_gate_loss: 0.1907 - val_loss: 1.2417 - val_main_output_accuracy: 0.7895 - val_main_output_loss: 1.1385 - val_tof_gate_loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Saving artifacts for Fold 2 ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step\n",
      "Fold 2 Accuracy: 0.7851\n",
      "\n",
      "=== Fold 3/4 ===\n",
      "Loading data for fold 3...\n",
      "Fold data loaded.\n",
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 230ms/step - loss: 3.8073 - main_output_accuracy: 0.0982 - main_output_loss: 3.2963 - tof_gate_loss: 0.6589 - val_loss: 3.0597 - val_main_output_accuracy: 0.2689 - val_main_output_loss: 2.6027 - val_tof_gate_loss: 0.3965\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 3.1136 - main_output_accuracy: 0.2277 - main_output_loss: 2.6743 - tof_gate_loss: 0.3269 - val_loss: 2.6001 - val_main_output_accuracy: 0.3837 - val_main_output_loss: 2.1916 - val_tof_gate_loss: 0.2292\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 2.9160 - main_output_accuracy: 0.2652 - main_output_loss: 2.5012 - tof_gate_loss: 0.2863 - val_loss: 2.2480 - val_main_output_accuracy: 0.4622 - val_main_output_loss: 1.8851 - val_tof_gate_loss: 0.0844\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.7190 - main_output_accuracy: 0.3050 - main_output_loss: 2.3285 - tof_gate_loss: 0.2435 - val_loss: 2.0957 - val_main_output_accuracy: 0.4921 - val_main_output_loss: 1.7563 - val_tof_gate_loss: 0.0505\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 2.6081 - main_output_accuracy: 0.3468 - main_output_loss: 2.2356 - tof_gate_loss: 0.2371 - val_loss: 1.9688 - val_main_output_accuracy: 0.5373 - val_main_output_loss: 1.6449 - val_tof_gate_loss: 0.0531\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 2.5156 - main_output_accuracy: 0.3976 - main_output_loss: 2.1583 - tof_gate_loss: 0.2390 - val_loss: 1.8671 - val_main_output_accuracy: 0.5726 - val_main_output_loss: 1.5609 - val_tof_gate_loss: 0.0411\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.4327 - main_output_accuracy: 0.4282 - main_output_loss: 2.0917 - tof_gate_loss: 0.2378 - val_loss: 1.8251 - val_main_output_accuracy: 0.6011 - val_main_output_loss: 1.5311 - val_tof_gate_loss: 0.0535\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 2.3940 - main_output_accuracy: 0.4521 - main_output_loss: 2.0640 - tof_gate_loss: 0.2532 - val_loss: 1.7821 - val_main_output_accuracy: 0.6026 - val_main_output_loss: 1.5023 - val_tof_gate_loss: 0.0519\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.2555 - main_output_accuracy: 0.4872 - main_output_loss: 1.9467 - tof_gate_loss: 0.2241 - val_loss: 1.7428 - val_main_output_accuracy: 0.6001 - val_main_output_loss: 1.4757 - val_tof_gate_loss: 0.0519\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 2.2012 - main_output_accuracy: 0.5059 - main_output_loss: 1.9052 - tof_gate_loss: 0.2109 - val_loss: 1.6652 - val_main_output_accuracy: 0.6384 - val_main_output_loss: 1.4113 - val_tof_gate_loss: 0.0453\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 2.1684 - main_output_accuracy: 0.4956 - main_output_loss: 1.8884 - tof_gate_loss: 0.2015 - val_loss: 1.6036 - val_main_output_accuracy: 0.6649 - val_main_output_loss: 1.3610 - val_tof_gate_loss: 0.0405\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 2.1824 - main_output_accuracy: 0.5067 - main_output_loss: 1.9071 - tof_gate_loss: 0.2191 - val_loss: 1.6519 - val_main_output_accuracy: 0.6153 - val_main_output_loss: 1.4211 - val_tof_gate_loss: 0.0322\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.1331 - main_output_accuracy: 0.5220 - main_output_loss: 1.8651 - tof_gate_loss: 0.2218 - val_loss: 1.5466 - val_main_output_accuracy: 0.6737 - val_main_output_loss: 1.3227 - val_tof_gate_loss: 0.0399\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 2.1245 - main_output_accuracy: 0.5530 - main_output_loss: 1.8645 - tof_gate_loss: 0.2357 - val_loss: 1.5415 - val_main_output_accuracy: 0.6649 - val_main_output_loss: 1.3264 - val_tof_gate_loss: 0.0356\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 2.0434 - main_output_accuracy: 0.5649 - main_output_loss: 1.7951 - tof_gate_loss: 0.2166 - val_loss: 1.5327 - val_main_output_accuracy: 0.6678 - val_main_output_loss: 1.3260 - val_tof_gate_loss: 0.0309\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.0895 - main_output_accuracy: 0.5601 - main_output_loss: 1.8441 - tof_gate_loss: 0.2332 - val_loss: 1.5358 - val_main_output_accuracy: 0.6536 - val_main_output_loss: 1.3345 - val_tof_gate_loss: 0.0359\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.9142 - main_output_accuracy: 0.5961 - main_output_loss: 1.6858 - tof_gate_loss: 0.1799 - val_loss: 1.4678 - val_main_output_accuracy: 0.6766 - val_main_output_loss: 1.2731 - val_tof_gate_loss: 0.0346\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.9471 - main_output_accuracy: 0.5915 - main_output_loss: 1.7233 - tof_gate_loss: 0.1872 - val_loss: 1.4562 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.2655 - val_tof_gate_loss: 0.0433\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.9746 - main_output_accuracy: 0.6067 - main_output_loss: 1.7474 - tof_gate_loss: 0.2292 - val_loss: 1.4739 - val_main_output_accuracy: 0.6879 - val_main_output_loss: 1.2885 - val_tof_gate_loss: 0.0423\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.9254 - main_output_accuracy: 0.6102 - main_output_loss: 1.7069 - tof_gate_loss: 0.2150 - val_loss: 1.4438 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.2604 - val_tof_gate_loss: 0.0533\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.8592 - main_output_accuracy: 0.6287 - main_output_loss: 1.6518 - tof_gate_loss: 0.1910 - val_loss: 1.4290 - val_main_output_accuracy: 0.6933 - val_main_output_loss: 1.2531 - val_tof_gate_loss: 0.0367\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.8627 - main_output_accuracy: 0.6313 - main_output_loss: 1.6540 - tof_gate_loss: 0.2062 - val_loss: 1.4725 - val_main_output_accuracy: 0.6698 - val_main_output_loss: 1.3010 - val_tof_gate_loss: 0.0342\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.9259 - main_output_accuracy: 0.6292 - main_output_loss: 1.7186 - tof_gate_loss: 0.2239 - val_loss: 1.4312 - val_main_output_accuracy: 0.6982 - val_main_output_loss: 1.2624 - val_tof_gate_loss: 0.0352\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.9188 - main_output_accuracy: 0.6288 - main_output_loss: 1.7121 - tof_gate_loss: 0.2314 - val_loss: 1.4067 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.2414 - val_tof_gate_loss: 0.0344\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.8593 - main_output_accuracy: 0.6384 - main_output_loss: 1.6613 - tof_gate_loss: 0.2026 - val_loss: 1.4025 - val_main_output_accuracy: 0.6909 - val_main_output_loss: 1.2409 - val_tof_gate_loss: 0.0328\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.8819 - main_output_accuracy: 0.6421 - main_output_loss: 1.6848 - tof_gate_loss: 0.2159 - val_loss: 1.3804 - val_main_output_accuracy: 0.7130 - val_main_output_loss: 1.2198 - val_tof_gate_loss: 0.0385\n",
      "Epoch 27/150\n",
      "\u001b[1m69/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 1.9119 - main_output_accuracy: 0.6257 - main_output_loss: 1.7105 - tof_gate_loss: 0.2375"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    unet_se_cnn,\n",
    "    features_processing, \n",
    "    GatedMixupGenerator, \n",
    "    tof_block, \n",
    "    match_time_steps, \n",
    "    time_sum, \n",
    "    squeeze_last_axis,\n",
    "    expand_last_axis,\n",
    "    crop_or_pad_output_shape\n",
    ")\n",
    "\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    create_sequence_dataset,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "# =====================================================================================\n",
    "# MASTER CONTROL FLAG\n",
    "# =====================================================================================\n",
    "TRAIN = False\n",
    "TRAIN = True \n",
    "\n",
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "PARQUET_FILE = 'output/final_model_input_dataset.parquet'\n",
    "# PARQUET_FILE = \"data/extended_features_df.parquet\"\n",
    "PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION (Your existing function)\n",
    "# =====================================================================================\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=64, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "if TRAIN:\n",
    "    schema_df = pl.read_parquet(PARQUET_FILE, n_rows=0)\n",
    "    all_columns = schema_df.columns\n",
    "    meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                    'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "    feature_cols = [c for c in all_columns if c not in meta_cols]\n",
    "    imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "    tof_cols  = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "\n",
    "    print(\"Scanning Parquet file for sequence IDs...\")\n",
    "    all_sequence_ids = (\n",
    "        pl.scan_parquet(PARQUET_FILE)\n",
    "        .select('sequence_id')\n",
    "        .unique()\n",
    "        .collect()\n",
    "        .to_numpy()\n",
    "        .ravel()\n",
    "    )\n",
    "    print(f\"Found {len(all_sequence_ids)} unique sequences.\")\n",
    "\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    imu_dim = len(imu_cols)\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        print(f\"Loading data for fold {fold_idx + 1}...\")\n",
    "        train_df = pl.read_parquet(PARQUET_FILE).filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = pl.read_parquet(PARQUET_FILE).filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        print(\"Fold data loaded.\")\n",
    "\n",
    "        train_gate_df = generate_gate_targets(train_df, tof_cols)\n",
    "        val_gate_df = generate_gate_targets(val_df, tof_cols)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_df['gesture'])\n",
    "        train_df = train_df.with_columns(pl.Series(\"gesture_int\", le.transform(train_df['gesture'])))\n",
    "        val_df = val_df.with_columns(pl.Series(\"gesture_int\", le.transform(val_df['gesture'])))\n",
    "\n",
    "        # --- StandardScaler Logic ---\n",
    "        scaler = StandardScaler()\n",
    "        # Fit on training data and transform both\n",
    "        train_features_scaled = scaler.fit_transform(train_df[imu_cols + tof_cols])\n",
    "        val_features_scaled = scaler.transform(val_df[imu_cols + tof_cols])\n",
    "        # Create Polars DataFrames from the scaled numpy arrays\n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=imu_cols + tof_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=imu_cols + tof_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "        gc.collect()\n",
    "\n",
    "        X_train, y_train, train_gate_target = create_sequence_dataset(train_df_final, imu_cols + tof_cols, train_gate_df)\n",
    "        X_val, y_val, val_gate_target = create_sequence_dataset(val_df_final, imu_cols + tof_cols, val_gate_df)\n",
    "\n",
    "        del train_df_final, val_df_final\n",
    "        gc.collect()\n",
    "\n",
    "        X_train_padded = perform_padding(X_train, MAX_PAD_LEN)\n",
    "        X_val_padded = perform_padding(X_val, MAX_PAD_LEN)\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "        train_dataset = GatedMixupGenerator(\n",
    "            X=X_train_padded, y=y_train_cat, gate_targets=train_gate_target,\n",
    "            batch_size=BATCH_SIZE, imu_dim=imu_dim, alpha=0.2, masking_prob=0.25\n",
    "        )\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            X_val_padded, {'main_output': y_val_cat, 'tof_gate': val_gate_target[:, np.newaxis]}\n",
    "        )).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        del X_val, y_val, X_train, y_train, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        model = create_model(train_dataset, len(imu_cols))\n",
    "        train_model(model, train_dataset, val_dataset, 150, LR_INIT, WD)\n",
    "\n",
    "        # --- SAVE ARTIFACTS ---\n",
    "        print(f\"--- Saving artifacts for Fold {fold_idx + 1} ---\")\n",
    "        model.save(PRETRAINED_DIR / f\"gesture_model_fold_{fold_idx}.h5\")\n",
    "        \n",
    "        # Save scaler and other metadata only from the first fold\n",
    "        if fold_idx == 0:\n",
    "            joblib.dump(scaler, PRETRAINED_DIR / \"scaler.pkl\")\n",
    "            np.save(PRETRAINED_DIR / \"feature_cols.npy\", np.array(imu_cols + tof_cols))\n",
    "            np.save(PRETRAINED_DIR / \"sequence_maxlen.npy\", MAX_PAD_LEN)\n",
    "            np.save(PRETRAINED_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "            print(\"Scaler, feature_cols, maxlen, and classes saved.\")\n",
    "\n",
    "        # --- EVALUATION ---\n",
    "        val_preds = model.predict(val_dataset)\n",
    "        main_output_preds = val_preds['main_output']\n",
    "        y_pred_fold = np.argmax(main_output_preds, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT ---\n",
    "    print(\"\\n=== Cross-validation Summary ===\")\n",
    "    print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# =====================================================================================\n",
    "# INFERENCE LOGIC\n",
    "# =====================================================================================\n",
    "else:\n",
    "    import pandas as pd \n",
    "    from src.metric import CompetitionMetric \n",
    "    from tensorflow import argmax, minimum, shape\n",
    "\n",
    "    def crop_or_pad(inputs):\n",
    "        x, skip = inputs\n",
    "        x_len = shape(x)[1]\n",
    "        skip_len = shape(skip)[1]\n",
    "        min_len = minimum(x_len, skip_len)\n",
    "        return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "    \n",
    "    # --- 1. Load All Inference Artifacts ---\n",
    "    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "    pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "    scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "    print(\"Scaler expects:\", list(scaler.feature_names_in_))\n",
    "    print(\"We have:\", final_feature_cols)\n",
    "    print(\"Missing:\", set(scaler.feature_names_in_) - set(final_feature_cols))\n",
    "    print(\"Extra:\", set(final_feature_cols) - set(scaler.feature_names_in_))\n",
    "\n",
    "    models = []\n",
    "    print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "    for fold in range(N_SPLITS):\n",
    "        model_path = PRETRAINED_DIR / f\"gesture_model_fold_{fold}.h5\"\n",
    "        \n",
    "        model = load_model(model_path, compile=False, custom_objects={\n",
    "            'unet_se_cnn': unet_se_cnn,\n",
    "            'tof_block': tof_block,\n",
    "            'features_processing': features_processing,\n",
    "            'match_time_steps': match_time_steps,\n",
    "            'crop_or_pad': crop_or_pad,\n",
    "            'squeeze_last_axis': squeeze_last_axis,\n",
    "            'expand_last_axis': expand_last_axis,\n",
    "            'time_sum': time_sum,\n",
    "            'crop_or_pad_output_shape': crop_or_pad_output_shape\n",
    "        })\n",
    "        models.append(model)\n",
    "    print(\"  Models, scaler, and metadata loaded – ready for evaluation.\")\n",
    "\n",
    "    # --- 2. Define TTA Parameters and Predict Function ---\n",
    "    TTA_STEPS = 10\n",
    "    TTA_NOISE_STDDEV = 0.01\n",
    "\n",
    "    from src.tof_feats import remove_gravity_from_acc, calculate_angular_velocity_from_quat, calculate_angular_distance\n",
    "\n",
    "    def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "        # Convert to pandas for the processing pipeline\n",
    "        df_seq = sequence.to_pandas()\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 1: Sanitize Raw Inputs ---\n",
    "        # =================================================================================\n",
    "        # This is a robust guard against non-numeric data in the hidden test set.\n",
    "        sensor_cols = [c for c in df_seq.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "        for col in sensor_cols:\n",
    "            if df_seq[col].dtype == 'object':\n",
    "                df_seq[col] = pd.to_numeric(df_seq[col], errors='coerce')\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 2: Feature Engineering (Must match training pipeline exactly) ---\n",
    "        # =================================================================================\n",
    "        # Create features in a dictionary to avoid fragmenting the DataFrame.\n",
    "        new_features = {}\n",
    "\n",
    "        # --- IMU Features ---\n",
    "        linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "        new_features['linear_acc_x'] = linear_accel[:, 0]\n",
    "        new_features['linear_acc_y'] = linear_accel[:, 1]\n",
    "        new_features['linear_acc_z'] = linear_accel[:, 2]\n",
    "        \n",
    "        linear_acc_mag = np.sqrt(np.square(linear_accel).sum(axis=1))\n",
    "        new_features['linear_acc_mag'] = linear_acc_mag\n",
    "        new_features['linear_acc_mag_jerk'] = pd.Series(linear_acc_mag).diff().fillna(0).values\n",
    "        \n",
    "        angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "        new_features['angular_vel_x'] = angular_vel[:, 0]\n",
    "        new_features['angular_vel_y'] = angular_vel[:, 1]\n",
    "        new_features['angular_vel_z'] = angular_vel[:, 2]\n",
    "        \n",
    "        new_features['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "\n",
    "        # --- ToF Aggregated Features ---\n",
    "        # This is the part that was missing.\n",
    "        for i in range(1, 6):\n",
    "            pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "            # The underlying tof_v... columns are already sanitized.\n",
    "            # We still replace -1 as it's a specific code, not bad data.\n",
    "            tof_data = df_seq[pixel_cols].replace(-1, np.nan) \n",
    "            new_features[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "            new_features[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "            new_features[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "            new_features[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "\n",
    "        # Add all new features to the DataFrame in one efficient operation\n",
    "        df_seq = df_seq.assign(**new_features)\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 3: Final Processing (Scaling and Padding) ---\n",
    "        # =================================================================================\n",
    "\n",
    "        mat_unscaled_df = df_seq[final_feature_cols]\n",
    "        mat_unscaled_filled = mat_unscaled_df.ffill().bfill().fillna(0)\n",
    "        mat_scaled = scaler.transform(mat_unscaled_filled)\n",
    "        pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 4: TTA and Ensemble Prediction ---\n",
    "        # =================================================================================\n",
    "        all_tta_predictions = []\n",
    "        for i in range(TTA_STEPS):\n",
    "            noisy_input = pad_input\n",
    "            if i > 0:\n",
    "                noise = tf.random.normal(shape=tf.shape(pad_input), mean=0.0, stddev=TTA_NOISE_STDDEV)\n",
    "                noisy_input = pad_input + noise\n",
    "\n",
    "            all_fold_predictions = []\n",
    "            for model in models:\n",
    "                # Correctly unpack the dictionary returned by the model\n",
    "                predictions_dict = model.predict(noisy_input, verbose=0)\n",
    "                main_preds = predictions_dict['main_output']\n",
    "                all_fold_predictions.append(main_preds)\n",
    "            \n",
    "            avg_fold_prediction = np.mean(all_fold_predictions, axis=0)\n",
    "            all_tta_predictions.append(avg_fold_prediction)\n",
    "\n",
    "        # =================================================================================\n",
    "        # --- Step 5: Final Averaging and Prediction ---\n",
    "        # =================================================================================\n",
    "        final_avg_prediction = np.mean(all_tta_predictions, axis=0)\n",
    "        idx = int(final_avg_prediction.argmax())\n",
    "        \n",
    "        return str(gesture_classes[idx])\n",
    "    \n",
    "    # --- 3. Run Kaggle Evaluation Server ---\n",
    "    import kaggle_evaluation.cmi_inference_server\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        # For local testing, you need to provide the paths to the test data\n",
    "        print(\"Running local gateway for testing...\")\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                'input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "                'input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ LOCAL DEBUG MODE – loading artefacts from output/artifacts\n",
      "  Loading 4 models for ensemble inference...\n",
      "  Models, scaler, and metadata loaded.\n",
      "\n",
      "--- Starting Local Test ---\n",
      "Testing with sequence_id: SEQ_000001\n",
      "\n",
      "Calling predict function directly...\n",
      "\n",
      "✅ SUCCESS! The function ran without errors on a sample.\n",
      "Predicted Gesture: Eyelash - pull hair\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # =====================================================================================\n",
    "# # --- INFERENCE & LOCAL DEBUGGING SCRIPT ---\n",
    "# # =====================================================================================\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# import traceback\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# import os\n",
    "# import gc\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import polars as pl\n",
    "# import tensorflow as tf\n",
    "# from pathlib import Path\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "# from tensorflow import argmax, minimum, shape\n",
    "\n",
    "# # --- Your existing function imports ---\n",
    "# from src.nn_blocks import (\n",
    "#     unet_se_cnn,\n",
    "#     features_processing, \n",
    "#     GatedMixupGenerator, \n",
    "#     tof_block, \n",
    "#     match_time_steps, \n",
    "#     time_sum, \n",
    "#     squeeze_last_axis,\n",
    "#     expand_last_axis,\n",
    "#     crop_or_pad_output_shape\n",
    "# )\n",
    "\n",
    "# from src.functions import (\n",
    "#     train_model, \n",
    "#     create_sequence_dataset,\n",
    "#     perform_padding,\n",
    "#     generate_gate_targets\n",
    "# )\n",
    "# from src.constants import DATA_PATH\n",
    "# from src.tof_feats import remove_gravity_from_acc, calculate_angular_velocity_from_quat, calculate_angular_distance\n",
    "\n",
    "# def crop_or_pad(inputs):\n",
    "#     x, skip = inputs\n",
    "#     x_len = shape(x)[1]\n",
    "#     skip_len = shape(skip)[1]\n",
    "#     min_len = minimum(x_len, skip_len)\n",
    "#     return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MASTER CONTROL FLAG\n",
    "# # =====================================================================================\n",
    "# TRAIN = True \n",
    "# TRAIN = False\n",
    "\n",
    "# # =====================================================================================\n",
    "# # CONFIGURATION\n",
    "# # =====================================================================================\n",
    "# PARQUET_FILE = 'output/final_processed_train_data.parquet'\n",
    "# PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "# PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "# LR_INIT = 5e-4\n",
    "# WD = 3e-3\n",
    "# NUM_CLASSES = 18\n",
    "# BATCH_SIZE = 64\n",
    "# N_SPLITS = 4 \n",
    "# MAX_PAD_LEN = 128\n",
    "\n",
    "# # --- 2. Define TTA Parameters and Predict Function ---\n",
    "# TTA_STEPS = 10\n",
    "# TTA_NOISE_STDDEV = 0.01\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MODEL DEFINITION (Your existing function)\n",
    "# # =====================================================================================\n",
    "# def create_model(dataset, imu_dim, wd=1e-4):\n",
    "#     sample_batch = next(iter(dataset))\n",
    "#     input_shape = sample_batch[0].shape[1:]\n",
    "#     inp = tf.keras.layers.Input(shape=input_shape)\n",
    "#     imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "#     tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "#     x1 = unet_se_cnn(imu, 3, base_filters=64, kernel_size=3)\n",
    "#     x2 = tof_block(tof, wd)\n",
    "\n",
    "#     x = features_processing(x1, x2)\n",
    "#     x = tf.keras.layers.Dropout(0.3)(x) \n",
    "#     main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "#     gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "#     return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# # --- 1. Load All Inference Artifacts ---\n",
    "# print(\"▶ LOCAL DEBUG MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "# try:\n",
    "#     final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "#     pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "#     scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "#     gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "#     models = []\n",
    "#     print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "#     for fold in range(N_SPLITS):\n",
    "#         model_path = PRETRAINED_DIR / f\"gesture_model_fold_{fold}.h5\"\n",
    "#         model = load_model(model_path, compile=False, custom_objects={\n",
    "#             'unet_se_cnn': unet_se_cnn,\n",
    "#             'tof_block': tof_block,\n",
    "#             'features_processing': features_processing,\n",
    "#             'match_time_steps': match_time_steps,\n",
    "#             'crop_or_pad': crop_or_pad,\n",
    "#             'squeeze_last_axis': squeeze_last_axis,\n",
    "#             'expand_last_axis': expand_last_axis,\n",
    "#             'time_sum': time_sum,\n",
    "#             'crop_or_pad_output_shape': crop_or_pad_output_shape\n",
    "#         })\n",
    "#         models.append(model)\n",
    "#     print(\"  Models, scaler, and metadata loaded.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"ERROR loading artifacts: {e}\")\n",
    "#     # Stop execution if artifacts can't be loaded\n",
    "#     exit()\n",
    "\n",
    "# # --- 2. Define the Predict Function (Using the most robust version) ---\n",
    "# def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#     # ... (All your feature engineering code is correct and can remain the same) ...\n",
    "#     df_seq = sequence.to_pandas()\n",
    "#     # ... (Sanitization, feature creation, scaling, padding) ...\n",
    "#     sensor_cols = [c for c in df_seq.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "#     for col in sensor_cols:\n",
    "#         if df_seq[col].dtype == 'object':\n",
    "#             df_seq[col] = pd.to_numeric(df_seq[col], errors='coerce')\n",
    "#     new_features = {}\n",
    "#     linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "#     new_features['linear_acc_x'] = linear_accel[:, 0]\n",
    "#     new_features['linear_acc_y'] = linear_accel[:, 1]\n",
    "#     new_features['linear_acc_z'] = linear_accel[:, 2]\n",
    "#     linear_acc_mag = np.sqrt(np.square(linear_accel).sum(axis=1))\n",
    "#     new_features['linear_acc_mag'] = linear_acc_mag\n",
    "#     new_features['linear_acc_mag_jerk'] = pd.Series(linear_acc_mag).diff().fillna(0).values\n",
    "#     angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "#     new_features['angular_vel_x'] = angular_vel[:, 0]\n",
    "#     new_features['angular_vel_y'] = angular_vel[:, 1]\n",
    "#     new_features['angular_vel_z'] = angular_vel[:, 2]\n",
    "#     new_features['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "#         tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "#         new_features[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "#         new_features[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "#         new_features[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "#         new_features[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "#     df_seq = df_seq.assign(**new_features)\n",
    "#     mat_unscaled_df = df_seq[final_feature_cols].ffill().bfill().fillna(0)\n",
    "#     mat_scaled = scaler.transform(mat_unscaled_df)\n",
    "#     pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "#     # --- TTA Loop ---\n",
    "#     all_tta_predictions = []\n",
    "#     for i in range(TTA_STEPS):\n",
    "#         noisy_input = pad_input\n",
    "#         if i > 0:\n",
    "#             noise = tf.random.normal(shape=tf.shape(pad_input), mean=0.0, stddev=TTA_NOISE_STDDEV)\n",
    "#             noisy_input = pad_input + noise\n",
    "\n",
    "#         # Ensemble predictions from all fold models\n",
    "#         all_fold_predictions = []\n",
    "#         for model in models:\n",
    "            \n",
    "#             # =========================================================================\n",
    "#             # --- THE FINAL FIX IS HERE ---\n",
    "#             # =========================================================================\n",
    "#             # model.predict returns a dictionary, access the 'main_output' key\n",
    "#             predictions_dict = model.predict(noisy_input, verbose=0)\n",
    "#             main_preds = predictions_dict['main_output']\n",
    "            \n",
    "#             all_fold_predictions.append(main_preds)\n",
    "        \n",
    "#         avg_fold_prediction = np.mean(all_fold_predictions, axis=0)\n",
    "#         all_tta_predictions.append(avg_fold_prediction)\n",
    "\n",
    "#     # --- Final Averaging and Prediction (Unchanged) ---\n",
    "#     final_avg_prediction = np.mean(all_tta_predictions, axis=0)\n",
    "#     idx = int(final_avg_prediction.argmax())\n",
    "    \n",
    "#     return str(gesture_classes[idx])\n",
    "\n",
    "# # =====================================================================================\n",
    "# # --- LOCAL TEST HARNESS ---\n",
    "# # =====================================================================================\n",
    "# print(\"\\n--- Starting Local Test ---\")\n",
    "\n",
    "# # Load the actual test data\n",
    "# TEST_CSV_PATH = 'input/cmi-detect-behavior-with-sensor-data/test.csv'\n",
    "# TEST_DEM_PATH = 'input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n",
    "\n",
    "# try:\n",
    "#     test_df = pl.read_csv(TEST_CSV_PATH)\n",
    "#     test_dem_df = pl.read_csv(TEST_DEM_PATH)\n",
    "    \n",
    "#     # Pick the first sequence from the test set\n",
    "#     target_sequence_id = test_df.get_column(\"sequence_id\").unique()[0]\n",
    "#     print(f\"Testing with sequence_id: {target_sequence_id}\")\n",
    "    \n",
    "#     # Isolate the data for that single sequence\n",
    "#     sample_sequence_pl = test_df.filter(pl.col(\"sequence_id\") == target_sequence_id)\n",
    "    \n",
    "#     # Find the corresponding subject and their demographics\n",
    "#     subject_id = sample_sequence_pl.get_column(\"subject\")[0]\n",
    "#     sample_demographics_pl = test_dem_df.filter(pl.col(\"subject\") == subject_id)\n",
    "    \n",
    "#     # --- Call the predict function directly and catch the REAL error ---\n",
    "#     print(\"\\nCalling predict function directly...\")\n",
    "#     predicted_gesture = predict(sample_sequence_pl, sample_demographics_pl)\n",
    "    \n",
    "#     print(\"\\n✅ SUCCESS! The function ran without errors on a sample.\")\n",
    "#     print(f\"Predicted Gesture: {predicted_gesture}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"\\n❌ ERROR! The function failed. Here is the full Python traceback:\")\n",
    "#     traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
