{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46207181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 12:22:46.240411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757244166.262266 2196047 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757244166.268879 2196047 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757244166.291738 2196047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757244166.291772 2196047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757244166.291774 2196047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757244166.291776 2196047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-07 12:22:46.298957: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import gc\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "\n",
    "def remove_gravity_polars(acc_df: pl.DataFrame, rot_df: pl.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Removes the gravity component from accelerometer data using quaternion rotations.\"\"\"\n",
    "    acc_values = acc_df.select(['acc_x', 'acc_y', 'acc_z']).to_numpy()\n",
    "    quat_values = rot_df.select(['rot_x', 'rot_y', 'rot_z', 'rot_w']).to_numpy()\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i] = acc_values[i]\n",
    "            continue\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i] = acc_values[i] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "            linear_accel[i] = acc_values[i]\n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity(rot_df: pl.DataFrame, sampling_rate_hz: int) -> np.ndarray:\n",
    "    \"\"\"Calculates angular velocity from quaternion data.\"\"\"\n",
    "    quats = rot_df.select(['rot_x', 'rot_y', 'rot_z', 'rot_w']).to_numpy()\n",
    "    angular_velocity = np.zeros_like(quats[:, :3])\n",
    "    dt = 1.0 / sampling_rate_hz\n",
    "    for i in range(1, len(quats)):\n",
    "        try:\n",
    "            q1 = R.from_quat(quats[i - 1])\n",
    "            q2 = R.from_quat(quats[i])\n",
    "            q_delta = q2 * q1.inv()\n",
    "            rot_vec = q_delta.as_rotvec()\n",
    "            angular_velocity[i] = rot_vec / dt\n",
    "        except ValueError:\n",
    "            angular_velocity[i] = 0\n",
    "    return angular_velocity\n",
    "\n",
    "def calculate_angular_acceleration(angular_velocity: np.ndarray, sampling_rate_hz: int) -> np.ndarray:\n",
    "    \"\"\"Calculates angular acceleration from angular velocity.\"\"\"\n",
    "    angular_accel = np.zeros_like(angular_velocity)\n",
    "    dt = 1.0 / sampling_rate_hz\n",
    "    angular_accel[1:] = np.diff(angular_velocity, axis=0) / dt\n",
    "    return angular_accel\n",
    "\n",
    "def calculate_gravity_orientation(rot_df: pl.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Calculates the orientation of each sensor axis with respect to the world gravity vector.\"\"\"\n",
    "    quat_values = rot_df.select(['rot_x', 'rot_y', 'rot_z', 'rot_w']).to_numpy()\n",
    "    num_samples = quat_values.shape[0]\n",
    "    orientation_angles = np.zeros((num_samples, 3))\n",
    "    gravity_world = np.array([0, 0, 1.0])\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            continue\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            sensor_axes_world = rotation.apply(np.eye(3))\n",
    "            for j in range(3):\n",
    "                dot_product = np.dot(sensor_axes_world[j], gravity_world)\n",
    "                orientation_angles[i, j] = np.arccos(np.clip(dot_product, -1.0, 1.0))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return orientation_angles\n",
    "\n",
    "def calculate_angular_distance(rot_df: pl.DataFrame) -> np.ndarray:\n",
    "    quat_values = rot_df.select(['rot_x', 'rot_y', 'rot_z', 'rot_w']).to_numpy()\n",
    "    angular_dist = np.zeros(len(quat_values))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q1, q2 = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isnan(q2)):\n",
    "            continue\n",
    "        try:\n",
    "            r1, r2 = R.from_quat(q1), R.from_quat(q2)\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            angular_dist[i] = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return angular_dist    \n",
    "\n",
    "# =====================================================================================\n",
    "# MAIN PROCESSING FUNCTION\n",
    "# =====================================================================================\n",
    "def add_all_imu_features_polars(df: pl.DataFrame, sampling_rate_hz: int) -> pl.DataFrame:\n",
    "    \"\"\"Main function to add all IMU features to the DataFrame.\"\"\"\n",
    "    df = df.sort([\"sequence_id\", \"sequence_counter\"])\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"acc_x\")**2 + pl.col(\"acc_y\")**2 + pl.col(\"acc_z\")**2).sqrt().alias(\"acc_mag\"),\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"acc_mag\").diff().over(\"sequence_id\").fill_null(0).alias(\"acc_mag_jerk\"),\n",
    "    )\n",
    "\n",
    "    grouped = df.partition_by(\"sequence_id\", maintain_order=True)\n",
    "    all_feature_dfs = []\n",
    "    for group in grouped:\n",
    "        acc_df = group.select([\"acc_x\", \"acc_y\", \"acc_z\"])\n",
    "        rot_df = group.select([\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"])\n",
    "        feature_df_group = pl.DataFrame({\n",
    "            \"sequence_counter\": group[\"sequence_counter\"],\n",
    "            \"sequence_id\": group[\"sequence_id\"]\n",
    "        })\n",
    "        linear_acc = remove_gravity_polars(acc_df, rot_df)\n",
    "        feature_df_group = feature_df_group.with_columns(\n",
    "            pl.DataFrame(linear_acc, schema=[\"linear_acc_x\", \"linear_acc_y\", \"linear_acc_z\"])\n",
    "        )\n",
    "        angular_vel = calculate_angular_velocity(rot_df, sampling_rate_hz)\n",
    "        feature_df_group = feature_df_group.with_columns(\n",
    "            pl.DataFrame(angular_vel, schema=[\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"])\n",
    "        )\n",
    "        angular_accel = calculate_angular_acceleration(angular_vel, sampling_rate_hz)\n",
    "        feature_df_group = feature_df_group.with_columns(\n",
    "            pl.DataFrame(angular_accel, schema=[\"angular_accel_x\", \"angular_accel_y\", \"angular_accel_z\"])\n",
    "        )\n",
    "        angular_dist = calculate_angular_distance(rot_df)\n",
    "        feature_df_group = feature_df_group.with_columns(pl.DataFrame(angular_dist, schema=[\"angular_distance\"]))\n",
    "        \n",
    "        gravity_orientation = calculate_gravity_orientation(rot_df)\n",
    "        feature_df_group = feature_df_group.with_columns(\n",
    "            pl.DataFrame(gravity_orientation, schema=[\"grav_orient_x\", \"grav_orient_y\", \"grav_orient_z\"])\n",
    "        )\n",
    "        all_feature_dfs.append(feature_df_group)\n",
    "\n",
    "    if all_feature_dfs:\n",
    "        features_to_add = pl.concat(all_feature_dfs)\n",
    "        df = df.join(features_to_add, on=[\"sequence_id\", \"sequence_counter\"], how=\"left\")\n",
    "\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"linear_acc_x\")**2 + pl.col(\"linear_acc_y\")**2 + pl.col(\"linear_acc_z\")**2).sqrt().alias(\"linear_acc_mag\"),\n",
    "        (pl.col(\"angular_vel_x\")**2 + pl.col(\"angular_vel_y\")**2 + pl.col(\"angular_vel_z\")**2).sqrt().alias(\"angular_vel_mag\"),\n",
    "        (pl.col(\"angular_accel_x\")**2 + pl.col(\"angular_accel_y\")**2 + pl.col(\"angular_accel_z\")**2).sqrt().alias(\"angular_accel_mag\"),\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"linear_acc_mag\").diff().over(\"sequence_id\").fill_null(0).alias(\"linear_acc_mag_jerk\"),\n",
    "        pl.col(\"angular_vel_mag\").diff().over(\"sequence_id\").fill_null(0).alias(\"angular_vel_mag_jerk\"),\n",
    "        pl.col(\"angular_accel_mag\").diff().over(\"sequence_id\").fill_null(0).alias(\"angular_accel_mag_jerk\"),\n",
    "    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163af538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tof_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    tof_aggregated_cols_template = []\n",
    "    for i in range(1, 6): \n",
    "        tof_aggregated_cols_template.extend([\n",
    "            f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max',\n",
    "            f'tof_{i}_diff_mean', f'tof_{i}_mean_decay',\n",
    "            f'tof_{i}_active_pixels', f'tof_{i}_centroid_x', f'tof_{i}_centroid_y'\n",
    "        ])\n",
    "\n",
    "    final_feature_cols = tof_aggregated_cols_template\n",
    "    \n",
    "    metadata_cols = ['sequence_id', 'sequence_counter', 'subject', 'gesture']\n",
    "\n",
    "    print(f\"  Total {len(final_feature_cols)} ToF statistical features will be engineered.\")\n",
    "\n",
    "    decay_weights = np.power(0.9, np.arange(64))\n",
    "    x_coords, y_coords = np.meshgrid(np.arange(8), np.arange(8))\n",
    "\n",
    "    print(\"  Building and executing feature engineering expressions...\")\n",
    "    feature_expressions = []\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "        list_expr = pl.concat_list([pl.when(pl.col(c) == -1).then(None).otherwise(pl.col(c)) for c in pixel_cols]).alias(f\"tof_{i}_list\")\n",
    "        feature_expressions.extend([\n",
    "            list_expr.list.mean().alias(f'tof_{i}_mean'),\n",
    "            list_expr.list.std().alias(f'tof_{i}_std'),\n",
    "            list_expr.list.min().alias(f'tof_{i}_min'),\n",
    "            list_expr.list.max().alias(f'tof_{i}_max'),\n",
    "            list_expr.list.diff().list.mean().alias(f'tof_{i}_diff_mean'),\n",
    "            list_expr.list.drop_nulls().list.len().alias(f'tof_{i}_active_pixels'),\n",
    "        ])\n",
    "        tof_data_exprs = [pl.when(pl.col(c) == -1).then(None).otherwise(pl.col(c)) for c in pixel_cols]\n",
    "        feature_expressions.append(pl.sum_horizontal([(expr * weight).fill_null(0) for expr, weight in zip(tof_data_exprs, decay_weights)]).alias(f'tof_{i}_mean_decay'))\n",
    "        weights_exprs = [(1 / (expr + 1e-6)).fill_null(0) for expr in tof_data_exprs]\n",
    "        total_weight_expr = pl.sum_horizontal(weights_exprs)\n",
    "        centroid_x_expr = pl.when(total_weight_expr > 1e-9).then(pl.sum_horizontal([(w * c) for w, c in zip(weights_exprs, x_coords.ravel())]) / total_weight_expr).otherwise(None)\n",
    "        centroid_y_expr = pl.when(total_weight_expr > 1e-9).then(pl.sum_horizontal([(w * c) for w, c in zip(weights_exprs, y_coords.ravel())]) / total_weight_expr).otherwise(None)\n",
    "        feature_expressions.extend([centroid_x_expr.alias(f'tof_{i}_centroid_x'), centroid_y_expr.alias(f'tof_{i}_centroid_y')])\n",
    "\n",
    "    base_feats = [f'thm_{i}' for i in range (1,6)] + ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "    df_featured = df.with_columns(feature_expressions)\n",
    "    \n",
    "    float_cols = [c for c in final_feature_cols if c.endswith(('_mean', '_std', '_min', '_max', '_diff_mean', '_mean_decay', '_centroid_x', '_centroid_y'))]\n",
    "    int_cols = [c for c in final_feature_cols if c.endswith('_active_pixels')]\n",
    "\n",
    "    float_imputation = pl.col(float_cols).replace([np.inf, -np.inf], None).fill_nan(None).forward_fill().backward_fill().fill_null(0).over(\"sequence_id\")\n",
    "    int_imputation = pl.col(int_cols).forward_fill().backward_fill().fill_null(0).over(\"sequence_id\")\n",
    "\n",
    "    final_df_imputed = df_featured.with_columns(float_imputation, int_imputation)\n",
    "\n",
    "    final_df = final_df_imputed.select(metadata_cols + base_feats + final_feature_cols)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86a3571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Starting Raw Data Cleaning Script...\n",
      "  Initial merged shape: (574945, 348)\n",
      "  Shape after removing SEQ_011975: (574861, 348)\n",
      "  Shape after removing problem subjects: (562604, 348)\n",
      "  Replaced -1 TOF values with 500.\n",
      "\n",
      "  Performing final imputation sweep...\n",
      "  Final imputation complete.\n",
      "  Total 45 ToF statistical features will be engineered.\n",
      "  Building and executing feature engineering expressions...\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = Path(\"input/cmi-detect-behavior-with-sensor-data\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_DATA_FILE = OUTPUT_DIR / \"cleaned_base_train_data.parquet\"\n",
    "FILTER_PROBLEM_SUBJECTS = True\n",
    "\n",
    "\n",
    "print(\"▶ Starting Raw Data Cleaning Script...\")\n",
    "\n",
    "# --- Step 1: Load and Merge Raw Data ---\n",
    "df = pl.read_csv(RAW_DIR / \"train.csv\")\n",
    "# df = df[:10_000]\n",
    "demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "df = df.join(demographics_df, on='subject', how='left')\n",
    "print(f\"  Initial merged shape: {df.shape}\")\n",
    "\n",
    "# --- Step 2: Filtering ---\n",
    "df = df.filter(pl.col(\"sequence_id\") != \"SEQ_011975\")\n",
    "print(f\"  Shape after removing SEQ_011975: {df.shape}\")\n",
    "\n",
    "# Define all 320 raw ToF columns\n",
    "raw_tof_cols = [f'tof_{i}_v{j}' for i in range(1, 6) for j in range(64)]\n",
    "\n",
    "# # Calculate the ratio of valid ToF readings for each sequence\n",
    "# df = df.with_columns(\n",
    "#     # Step 1: Count the number of valid ToF readings in each ROW.\n",
    "#     # A reading is valid if it's not null AND not -1.\n",
    "#     pl.sum_horizontal(\n",
    "#         pl.col(c).is_not_null() & (pl.col(c) != -1) for c in raw_tof_cols\n",
    "#     ).alias(\"valid_tofs_per_row\")\n",
    "# ).with_columns(\n",
    "#     # Step 2: Calculate the ratio for the entire SEQUENCE.\n",
    "#     # Sum the valid counts per row and divide by the total possible readings.\n",
    "#     (\n",
    "#         pl.col(\"valid_tofs_per_row\").sum().over(\"sequence_id\") / (pl.len().over(\"sequence_id\") * len(raw_tof_cols))\n",
    "#     ).alias(\"valid_tof_ratio\")\n",
    "# ).filter(\n",
    "#     # Step 3: Apply the filter\n",
    "#     pl.col(\"valid_tof_ratio\") >= 0.2\n",
    "# ).drop(\"valid_tofs_per_row\", \"valid_tof_ratio\") # Clean up temporary columns\n",
    "\n",
    "# print(f\"  Shape after valid ToF data ratio filter (>= 0.2): {df.shape}\")\n",
    "\n",
    "if FILTER_PROBLEM_SUBJECTS:\n",
    "    problem_subjects = [\"SUBJ_045235\", \"SUBJ_019262\"]\n",
    "    df = df.filter(~pl.col(\"subject\").is_in(problem_subjects))\n",
    "    print(f\"  Shape after removing problem subjects: {df.shape}\")\n",
    "\n",
    "# --- Step 3: Value Transformation ---\n",
    "\n",
    "df = df.with_columns(\n",
    "    [pl.when(pl.col(c) == -1).then(500).otherwise(pl.col(c)).alias(c) for c in raw_tof_cols]\n",
    ")\n",
    "print(\"  Replaced -1 TOF values with 500.\")\n",
    "\n",
    "# --- Step 4: Ultimate NaN Filling ---\n",
    "print(\"\\n  Performing final imputation sweep...\")\n",
    "cols_to_impute = [c for c in df.columns if c not in ['row_id', 'sequence_id', 'subject', 'gesture', 'behavior', 'orientation']]\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(cols_to_impute)\n",
    "        .forward_fill()\n",
    "        .backward_fill()\n",
    "        .fill_null(0)\n",
    "        .over(\"sequence_id\")\n",
    ")\n",
    "print(\"  Final imputation complete.\")\n",
    "\n",
    "df = process_tof_features(df)\n",
    "df = add_all_imu_features_polars(df, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0a98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow import argmax, minimum, shape\n",
    "from tensorflow.data import AUTOTUNE, Dataset\n",
    "from tensorflow.keras import Layer, Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import pad_sequences, Sequence, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Concatenate,\n",
    "    BatchNormalization, GRU, Dropout, add, Activation, Multiply, Reshape,\n",
    "    LayerNormalization, Add, Bidirectional, LSTM, UpSampling1D, Lambda, GaussianNoise,\n",
    "    Input, GlobalMaxPooling1D\n",
    ")\n",
    "\n",
    "def generate_gate_targets(df: pl.DataFrame, tof_cols: list) -> pl.DataFrame:\n",
    "    gate_df = df.group_by(\"sequence_id\").agg(\n",
    "        pl.any_horizontal(pl.col(tof_cols).is_not_null().any()).alias(\"has_tof\")\n",
    "    )\n",
    "    return gate_df.with_columns(pl.col(\"has_tof\").cast(pl.Float32))\n",
    "\n",
    "def create_sequence_dataset(df: pl.DataFrame, feature_cols: list, gate_df: pl.DataFrame):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    gate_targets = [] \n",
    "\n",
    "    df_with_gate = df.join(gate_df, on='sequence_id', how='left')\n",
    "\n",
    "    for seq_id, group in df_with_gate.group_by('sequence_id', maintain_order=True):\n",
    "        sequences.append(group.select(feature_cols).to_numpy())\n",
    "        labels.append(group.select('gesture_int').item(0, 0))\n",
    "        gate_targets.append(group.select('has_tof').item(0, 0))\n",
    "\n",
    "    return np.array(sequences, dtype=object), np.array(labels), np.array(gate_targets)    \n",
    "\n",
    "class GatedMixupGenerator(Sequence):\n",
    "    def __init__(self, X, y, gate_targets, batch_size, imu_dim, class_weight=None, alpha=0.2, masking_prob=0.0):\n",
    "        self.X, self.y = X, y\n",
    "        self.gate_targets = gate_targets  \n",
    "        self.batch = batch_size\n",
    "        self.imu_dim = imu_dim\n",
    "        self.class_weight = class_weight\n",
    "        self.alpha = alpha\n",
    "        self.masking_prob = masking_prob\n",
    "        self.indices = np.arange(len(X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i*self.batch:(i+1)*self.batch]\n",
    "        Xb, yb = self.X[idx].copy(), self.y[idx].copy()\n",
    "        \n",
    "        gate_target = self.gate_targets[idx].copy()\n",
    "\n",
    "        if self.masking_prob > 0:\n",
    "            for i in range(len(Xb)):\n",
    "                # If the gate is 1.0 (has ToF) AND we hit the random chance...\n",
    "                if gate_target[i] == 1.0 and np.random.rand() < self.masking_prob:\n",
    "                    Xb[i, :, self.imu_dim:] = 0  # Zero out the ToF features\n",
    "                    gate_target[i] = 0.0         # Set the gate to 0 for this augmented sample\n",
    "\n",
    "        # The rest of the logic (class weights, mixup) can remain the same\n",
    "        sample_weights = np.ones(len(Xb), dtype='float32')\n",
    "        if self.class_weight:\n",
    "            y_integers = yb.argmax(axis=1)\n",
    "            sample_weights = np.array([self.class_weight[i] for i in y_integers])\n",
    "\n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            perm = np.random.permutation(len(Xb))\n",
    "            X_mix = lam * Xb + (1 - lam) * Xb[perm]\n",
    "            y_mix = lam * yb + (1 - lam) * yb[perm]\n",
    "            gate_target_mix = lam * gate_target + (1 - lam) * gate_target[perm]\n",
    "            sample_weights_mix = lam * sample_weights + (1 - lam) * sample_weights[perm]\n",
    "            return X_mix, {'main_output': y_mix, 'tof_gate': gate_target_mix[:, np.newaxis]}, sample_weights_mix\n",
    "\n",
    "        return Xb, {'main_output': yb, 'tof_gate': gate_target[:, np.newaxis]}, sample_weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "914e6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_info = df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "# all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "# tr_ix, val_ix = train_test_split(all_sequence_ids, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee76ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_or_pad(inputs):\n",
    "    x, skip = inputs\n",
    "    x_len = shape(x)[1]\n",
    "    skip_len = shape(skip)[1]\n",
    "    min_len = minimum(x_len, skip_len)\n",
    "    return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "\n",
    "def crop_or_pad_output_shape(input_shapes):\n",
    "    shape1, shape2 = input_shapes\n",
    "    min_time_steps = min(shape1[1], shape2[1])\n",
    "    num_features = shape1[2]\n",
    "    output_shape = (None, min_time_steps, num_features)\n",
    "    return [output_shape, output_shape]\n",
    "\n",
    "def match_time_steps(x, skip):    \n",
    "    x, skip = Lambda(\n",
    "        crop_or_pad, \n",
    "        output_shape=crop_or_pad_output_shape \n",
    "    )([x, skip])\n",
    "    return x, skip\n",
    "\n",
    "def se_block(x, reduction=8):\n",
    "    ch = x.shape[-1]\n",
    "    se = GlobalAveragePooling1D()(x)\n",
    "    se = Dense(ch // reduction, activation='relu')(se)\n",
    "    se = Dense(ch, activation='sigmoid')(se)\n",
    "    se = Reshape((1, ch))(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "def residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n",
    "    \"\"\"\n",
    "    Output: (B, T, # filters)\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "    for _ in range(2):\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(wd))(x)\n",
    "        x = LayerNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x = se_block(x)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n",
    "                          kernel_regularizer=l2(wd))(shortcut)\n",
    "        shortcut = LayerNormalization()(shortcut)\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n",
    "    shortcut = x\n",
    "    for _ in range(2):\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x = se_block(x)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n",
    "                          kernel_regularizer=l2(wd))(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def res_se_cnn_decoder_block(x, filters, kernel_size, drop=0.3, wd=1e-4, skip_connection=None):\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "               kernel_regularizer=l2(wd))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if skip_connection is not None:\n",
    "        x, skip_connection = match_time_steps(x, skip_connection)\n",
    "        x = Concatenate()([x, skip_connection])\n",
    "\n",
    "    x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "               kernel_regularizer=l2(wd))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = se_block(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def unet_se_cnn(x, unet_depth=3, base_filters=64, kernel_size=3, drop=0.3):\n",
    "    filters = base_filters\n",
    "    skips = []\n",
    "    \n",
    "    # Encoder\n",
    "    for _ in range(unet_depth):\n",
    "        x = residual_se_cnn_block(x, filters, kernel_size, drop=drop)\n",
    "        skips.append(x)\n",
    "        filters *= 2\n",
    "    \n",
    "    # Bottleneck\n",
    "    c_shape = x.shape[-1]\n",
    "    x = Dense(128)(x)\n",
    "    x = Dense(c_shape)(x)\n",
    "    \n",
    "    # Decoder \n",
    "    for skip in reversed(skips):\n",
    "        filters //= 2\n",
    "        x = res_se_cnn_decoder_block(x, filters, kernel_size, drop=drop, skip_connection=skip)\n",
    "    \n",
    "    return x\n",
    "        \n",
    "class GatedMixupGenerator(Sequence):\n",
    "    def __init__(self, X, y, gate_targets, batch_size, imu_dim, class_weight=None, alpha=0.2, masking_prob=0.0):\n",
    "        self.X, self.y = X, y\n",
    "        self.gate_targets = gate_targets  \n",
    "        self.batch = batch_size\n",
    "        self.imu_dim = imu_dim\n",
    "        self.class_weight = class_weight\n",
    "        self.alpha = alpha\n",
    "        self.masking_prob = masking_prob\n",
    "        self.indices = np.arange(len(X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i*self.batch:(i+1)*self.batch]\n",
    "        Xb, yb = self.X[idx].copy(), self.y[idx].copy()\n",
    "        \n",
    "        gate_target = self.gate_targets[idx].copy()\n",
    "\n",
    "        if self.masking_prob > 0:\n",
    "            for i in range(len(Xb)):\n",
    "                # If the gate is 1.0 (has ToF) AND we hit the random chance...\n",
    "                if gate_target[i] == 1.0 and np.random.rand() < self.masking_prob:\n",
    "                    Xb[i, :, self.imu_dim:] = 0  # Zero out the ToF features\n",
    "                    gate_target[i] = 0.0         # Set the gate to 0 for this augmented sample\n",
    "\n",
    "        # The rest of the logic (class weights, mixup) can remain the same\n",
    "        sample_weights = np.ones(len(Xb), dtype='float32')\n",
    "        if self.class_weight:\n",
    "            y_integers = yb.argmax(axis=1)\n",
    "            sample_weights = np.array([self.class_weight[i] for i in y_integers])\n",
    "\n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            perm = np.random.permutation(len(Xb))\n",
    "            X_mix = lam * Xb + (1 - lam) * Xb[perm]\n",
    "            y_mix = lam * yb + (1 - lam) * yb[perm]\n",
    "            gate_target_mix = lam * gate_target + (1 - lam) * gate_target[perm]\n",
    "            sample_weights_mix = lam * sample_weights + (1 - lam) * sample_weights[perm]\n",
    "            return X_mix, {'main_output': y_mix, 'tof_gate': gate_target_mix[:, np.newaxis]}, sample_weights_mix\n",
    "\n",
    "        return Xb, {'main_output': yb, 'tof_gate': gate_target[:, np.newaxis]}, sample_weights    \n",
    "\n",
    "def on_epoch_end(self):\n",
    "    np.random.shuffle(self.indices)    \n",
    "\n",
    "def time_sum(x):\n",
    "    return k.sum(x, axis=1)\n",
    "\n",
    "def squeeze_last_axis(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def expand_last_axis(x):\n",
    "    return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "def tof_block(tof_inputs, wd=1e-4):\n",
    "    x2_base = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof_inputs)\n",
    "    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n",
    "    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n",
    "    x2_base = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2_base)\n",
    "    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n",
    "\n",
    "    gate_input = GlobalAveragePooling1D()(tof_inputs)\n",
    "    gate_input = Dense(16, activation='relu')(gate_input)\n",
    "\n",
    "    gate = Dense(1, activation='sigmoid', name='tof_gate_dense')(gate_input)\n",
    "    return Multiply()([x2_base, gate])\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    score = Dense(1, activation='tanh')(inputs)\n",
    "    score = Lambda(squeeze_last_axis)(score)\n",
    "    weights = Activation('softmax')(score)\n",
    "    weights = Lambda(expand_last_axis)(weights)\n",
    "    context = Multiply()([inputs, weights])\n",
    "    context = Lambda(time_sum)(context)\n",
    "    return context    \n",
    "\n",
    "def features_processing(x1, x2, wd=1e-4):\n",
    "    merged = Concatenate()([x1, x2])\n",
    "    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xc = GaussianNoise(0.09)(merged)\n",
    "    xc = Dense(16, activation='elu')(xc)\n",
    "    \n",
    "    x = Concatenate()([xa, xb, xc])\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953fd4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ PHASE: Training on train_val split...\n",
      "\n",
      "  Engineering all features from the clean base data...\n",
      "  Encoding labels...\n",
      "  Fitting final scaler on all training data...\n",
      "  Preparing full dataset for training...\n",
      "['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance', 'angular_accel_x', 'angular_accel_y', 'angular_accel_z']\n",
      "['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_mean', 'tof_1_std', 'tof_1_min', 'tof_1_max', 'tof_1_diff_mean', 'tof_1_mean_decay', 'tof_1_active_pixels', 'tof_1_centroid_x', 'tof_1_centroid_y', 'tof_2_mean', 'tof_2_std', 'tof_2_min', 'tof_2_max', 'tof_2_diff_mean', 'tof_2_mean_decay', 'tof_2_active_pixels', 'tof_2_centroid_x', 'tof_2_centroid_y', 'tof_3_mean', 'tof_3_std', 'tof_3_min', 'tof_3_max', 'tof_3_diff_mean', 'tof_3_mean_decay', 'tof_3_active_pixels', 'tof_3_centroid_x', 'tof_3_centroid_y', 'tof_4_mean', 'tof_4_std', 'tof_4_min', 'tof_4_max', 'tof_4_diff_mean', 'tof_4_mean_decay', 'tof_4_active_pixels', 'tof_4_centroid_x', 'tof_4_centroid_y', 'tof_5_mean', 'tof_5_std', 'tof_5_min', 'tof_5_max', 'tof_5_diff_mean', 'tof_5_mean_decay', 'tof_5_active_pixels', 'tof_5_centroid_x', 'tof_5_centroid_y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "I0000 00:00:1757244405.763903 2196047 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-09-07 12:26:45.769853: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56171520 exceeds 10% of free system memory.\n",
      "2025-09-07 12:26:46.043547: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56171520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1757244428.311502 2196860 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-09-07 12:27:12.005679: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:12.473195: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:12.754171: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:12.833379: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:13.134211: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:13.604550: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 81/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 4.0788 - main_output_accuracy: 0.1136 - main_output_loss: 3.2311 - tof_gate_loss: 0.4702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 12:27:31.226321: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:31.517985: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:31.676522: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-07 12:27:31.714025: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 4.0040 - main_output_accuracy: 0.1235 - main_output_loss: 3.1693 - tof_gate_loss: 0.4459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 12:27:35.738267: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56171520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 256ms/step - loss: 4.0005 - main_output_accuracy: 0.1240 - main_output_loss: 3.1664 - tof_gate_loss: 0.4448 - val_loss: 3.2743 - val_main_output_accuracy: 0.1698 - val_main_output_loss: 2.5627 - val_tof_gate_loss: 0.2796\n",
      "Epoch 2/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - loss: 3.0296 - main_output_accuracy: 0.2772 - main_output_loss: 2.3627 - tof_gate_loss: 0.2290 - val_loss: 2.3478 - val_main_output_accuracy: 0.3660 - val_main_output_loss: 1.7911 - val_tof_gate_loss: 0.0982\n",
      "Epoch 3/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - loss: 2.7633 - main_output_accuracy: 0.3376 - main_output_loss: 2.1605 - tof_gate_loss: 0.2203 - val_loss: 2.0282 - val_main_output_accuracy: 0.4547 - val_main_output_loss: 1.5347 - val_tof_gate_loss: 0.0899\n",
      "Epoch 4/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 2.5234 - main_output_accuracy: 0.3910 - main_output_loss: 1.9766 - tof_gate_loss: 0.2201 - val_loss: 1.7677 - val_main_output_accuracy: 0.5164 - val_main_output_loss: 1.3233 - val_tof_gate_loss: 0.0869\n",
      "Epoch 5/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 2.2898 - main_output_accuracy: 0.4473 - main_output_loss: 1.8032 - tof_gate_loss: 0.1922 - val_loss: 1.5188 - val_main_output_accuracy: 0.5843 - val_main_output_loss: 1.1345 - val_tof_gate_loss: 0.0480\n",
      "Epoch 6/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 198ms/step - loss: 2.1517 - main_output_accuracy: 0.4704 - main_output_loss: 1.7035 - tof_gate_loss: 0.1906 - val_loss: 1.3818 - val_main_output_accuracy: 0.6113 - val_main_output_loss: 1.0397 - val_tof_gate_loss: 0.0267\n",
      "Epoch 7/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 2.0456 - main_output_accuracy: 0.4978 - main_output_loss: 1.6278 - tof_gate_loss: 0.1861 - val_loss: 1.2923 - val_main_output_accuracy: 0.6365 - val_main_output_loss: 0.9725 - val_tof_gate_loss: 0.0329\n",
      "Epoch 8/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - loss: 1.8630 - main_output_accuracy: 0.5367 - main_output_loss: 1.4890 - tof_gate_loss: 0.1489 - val_loss: 1.2770 - val_main_output_accuracy: 0.6403 - val_main_output_loss: 0.9803 - val_tof_gate_loss: 0.0281\n",
      "Epoch 9/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - loss: 1.9029 - main_output_accuracy: 0.5441 - main_output_loss: 1.5383 - tof_gate_loss: 0.1758 - val_loss: 1.3363 - val_main_output_accuracy: 0.5830 - val_main_output_loss: 1.0502 - val_tof_gate_loss: 0.0393\n",
      "Epoch 10/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 210ms/step - loss: 1.8430 - main_output_accuracy: 0.5654 - main_output_loss: 1.4875 - tof_gate_loss: 0.1793 - val_loss: 1.1905 - val_main_output_accuracy: 0.6566 - val_main_output_loss: 0.9225 - val_tof_gate_loss: 0.0343\n",
      "Epoch 11/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.8105 - main_output_accuracy: 0.5674 - main_output_loss: 1.4693 - tof_gate_loss: 0.1861 - val_loss: 1.1266 - val_main_output_accuracy: 0.6755 - val_main_output_loss: 0.8728 - val_tof_gate_loss: 0.0309\n",
      "Epoch 12/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 1.8552 - main_output_accuracy: 0.5653 - main_output_loss: 1.5143 - tof_gate_loss: 0.2091 - val_loss: 1.0958 - val_main_output_accuracy: 0.6730 - val_main_output_loss: 0.8556 - val_tof_gate_loss: 0.0243\n",
      "Epoch 13/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 1.6731 - main_output_accuracy: 0.5962 - main_output_loss: 1.3725 - tof_gate_loss: 0.1729 - val_loss: 1.1126 - val_main_output_accuracy: 0.6635 - val_main_output_loss: 0.8808 - val_tof_gate_loss: 0.0259\n",
      "Epoch 14/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 1.8380 - main_output_accuracy: 0.5829 - main_output_loss: 1.4970 - tof_gate_loss: 0.2375 - val_loss: 1.0753 - val_main_output_accuracy: 0.6767 - val_main_output_loss: 0.8460 - val_tof_gate_loss: 0.0361\n",
      "Epoch 15/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - loss: 1.6293 - main_output_accuracy: 0.6139 - main_output_loss: 1.3353 - tof_gate_loss: 0.1678 - val_loss: 1.0883 - val_main_output_accuracy: 0.6818 - val_main_output_loss: 0.8703 - val_tof_gate_loss: 0.0290\n",
      "Epoch 16/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 220ms/step - loss: 1.5654 - main_output_accuracy: 0.6244 - main_output_loss: 1.2793 - tof_gate_loss: 0.1608 - val_loss: 1.0551 - val_main_output_accuracy: 0.6881 - val_main_output_loss: 0.8431 - val_tof_gate_loss: 0.0259\n",
      "Epoch 17/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 226ms/step - loss: 1.7135 - main_output_accuracy: 0.6102 - main_output_loss: 1.4090 - tof_gate_loss: 0.2120 - val_loss: 1.0430 - val_main_output_accuracy: 0.6811 - val_main_output_loss: 0.8339 - val_tof_gate_loss: 0.0311\n",
      "Epoch 18/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 205ms/step - loss: 1.7330 - main_output_accuracy: 0.6218 - main_output_loss: 1.4288 - tof_gate_loss: 0.2309 - val_loss: 1.0214 - val_main_output_accuracy: 0.6887 - val_main_output_loss: 0.8181 - val_tof_gate_loss: 0.0293\n",
      "Epoch 19/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 1.6531 - main_output_accuracy: 0.6292 - main_output_loss: 1.3527 - tof_gate_loss: 0.2214 - val_loss: 0.9824 - val_main_output_accuracy: 0.7189 - val_main_output_loss: 0.7863 - val_tof_gate_loss: 0.0235\n",
      "Epoch 20/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - loss: 1.4814 - main_output_accuracy: 0.6529 - main_output_loss: 1.2142 - tof_gate_loss: 0.1645 - val_loss: 0.9871 - val_main_output_accuracy: 0.6975 - val_main_output_loss: 0.7929 - val_tof_gate_loss: 0.0267\n",
      "Epoch 21/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 1.5115 - main_output_accuracy: 0.6556 - main_output_loss: 1.2401 - tof_gate_loss: 0.1798 - val_loss: 1.0259 - val_main_output_accuracy: 0.6969 - val_main_output_loss: 0.8356 - val_tof_gate_loss: 0.0240\n",
      "Epoch 22/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.5008 - main_output_accuracy: 0.6551 - main_output_loss: 1.2403 - tof_gate_loss: 0.1697 - val_loss: 0.9592 - val_main_output_accuracy: 0.7082 - val_main_output_loss: 0.7720 - val_tof_gate_loss: 0.0240\n",
      "Epoch 23/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - loss: 1.5832 - main_output_accuracy: 0.6421 - main_output_loss: 1.3091 - tof_gate_loss: 0.1993 - val_loss: 0.9466 - val_main_output_accuracy: 0.7189 - val_main_output_loss: 0.7591 - val_tof_gate_loss: 0.0279\n",
      "Epoch 24/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 1.5203 - main_output_accuracy: 0.6628 - main_output_loss: 1.2502 - tof_gate_loss: 0.1878 - val_loss: 0.9825 - val_main_output_accuracy: 0.6918 - val_main_output_loss: 0.8032 - val_tof_gate_loss: 0.0206\n",
      "Epoch 25/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - loss: 1.5537 - main_output_accuracy: 0.6600 - main_output_loss: 1.2853 - tof_gate_loss: 0.1975 - val_loss: 0.8844 - val_main_output_accuracy: 0.7270 - val_main_output_loss: 0.7085 - val_tof_gate_loss: 0.0171\n",
      "Epoch 26/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - loss: 1.4205 - main_output_accuracy: 0.6859 - main_output_loss: 1.1693 - tof_gate_loss: 0.1672 - val_loss: 0.8981 - val_main_output_accuracy: 0.7239 - val_main_output_loss: 0.7192 - val_tof_gate_loss: 0.0261\n",
      "Epoch 27/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 1.2247 - main_output_accuracy: 0.7160 - main_output_loss: 0.9942 - tof_gate_loss: 0.1282 - val_loss: 0.9750 - val_main_output_accuracy: 0.7069 - val_main_output_loss: 0.8026 - val_tof_gate_loss: 0.0167\n",
      "Epoch 28/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 205ms/step - loss: 1.4145 - main_output_accuracy: 0.7032 - main_output_loss: 1.1632 - tof_gate_loss: 0.1734 - val_loss: 0.9627 - val_main_output_accuracy: 0.7145 - val_main_output_loss: 0.7885 - val_tof_gate_loss: 0.0253\n",
      "Epoch 29/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 210ms/step - loss: 1.3910 - main_output_accuracy: 0.7093 - main_output_loss: 1.1316 - tof_gate_loss: 0.1801 - val_loss: 0.8800 - val_main_output_accuracy: 0.7384 - val_main_output_loss: 0.7067 - val_tof_gate_loss: 0.0266\n",
      "Epoch 30/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - loss: 1.2896 - main_output_accuracy: 0.7380 - main_output_loss: 1.0506 - tof_gate_loss: 0.1592 - val_loss: 1.0127 - val_main_output_accuracy: 0.6969 - val_main_output_loss: 0.8434 - val_tof_gate_loss: 0.0241\n",
      "Epoch 31/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 1.3462 - main_output_accuracy: 0.7094 - main_output_loss: 1.0984 - tof_gate_loss: 0.1661 - val_loss: 0.8814 - val_main_output_accuracy: 0.7447 - val_main_output_loss: 0.7129 - val_tof_gate_loss: 0.0223\n",
      "Epoch 32/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 1.4402 - main_output_accuracy: 0.7045 - main_output_loss: 1.1845 - tof_gate_loss: 0.1923 - val_loss: 0.8545 - val_main_output_accuracy: 0.7421 - val_main_output_loss: 0.6909 - val_tof_gate_loss: 0.0140\n",
      "Epoch 33/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - loss: 1.4375 - main_output_accuracy: 0.7174 - main_output_loss: 1.1754 - tof_gate_loss: 0.2016 - val_loss: 0.9041 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 0.7393 - val_tof_gate_loss: 0.0197\n",
      "Epoch 34/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 224ms/step - loss: 1.3395 - main_output_accuracy: 0.7125 - main_output_loss: 1.0867 - tof_gate_loss: 0.1724 - val_loss: 0.9052 - val_main_output_accuracy: 0.7270 - val_main_output_loss: 0.7377 - val_tof_gate_loss: 0.0271\n",
      "Epoch 35/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 1.4483 - main_output_accuracy: 0.6996 - main_output_loss: 1.1987 - tof_gate_loss: 0.1889 - val_loss: 0.8836 - val_main_output_accuracy: 0.7447 - val_main_output_loss: 0.7199 - val_tof_gate_loss: 0.0223\n",
      "Epoch 36/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - loss: 1.2948 - main_output_accuracy: 0.7422 - main_output_loss: 1.0534 - tof_gate_loss: 0.1746 - val_loss: 0.9254 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 0.7625 - val_tof_gate_loss: 0.0233\n",
      "Epoch 37/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - loss: 1.3198 - main_output_accuracy: 0.7362 - main_output_loss: 1.0809 - tof_gate_loss: 0.1741 - val_loss: 0.8605 - val_main_output_accuracy: 0.7472 - val_main_output_loss: 0.6978 - val_tof_gate_loss: 0.0217\n",
      "Epoch 38/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - loss: 1.3056 - main_output_accuracy: 0.7416 - main_output_loss: 1.0692 - tof_gate_loss: 0.1647 - val_loss: 0.8326 - val_main_output_accuracy: 0.7597 - val_main_output_loss: 0.6739 - val_tof_gate_loss: 0.0174\n",
      "Epoch 39/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 227ms/step - loss: 1.4821 - main_output_accuracy: 0.7155 - main_output_loss: 1.2258 - tof_gate_loss: 0.2074 - val_loss: 0.8153 - val_main_output_accuracy: 0.7648 - val_main_output_loss: 0.6559 - val_tof_gate_loss: 0.0207\n",
      "Epoch 40/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 1.2650 - main_output_accuracy: 0.7428 - main_output_loss: 1.0248 - tof_gate_loss: 0.1637 - val_loss: 0.8283 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 0.6730 - val_tof_gate_loss: 0.0138\n",
      "Epoch 41/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 1.4287 - main_output_accuracy: 0.7167 - main_output_loss: 1.1858 - tof_gate_loss: 0.1901 - val_loss: 0.8306 - val_main_output_accuracy: 0.7616 - val_main_output_loss: 0.6680 - val_tof_gate_loss: 0.0302\n",
      "Epoch 42/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - loss: 1.1688 - main_output_accuracy: 0.7825 - main_output_loss: 0.9425 - tof_gate_loss: 0.1576 - val_loss: 0.8365 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 0.6821 - val_tof_gate_loss: 0.0162\n",
      "Epoch 43/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 224ms/step - loss: 1.2853 - main_output_accuracy: 0.7446 - main_output_loss: 1.0602 - tof_gate_loss: 0.1570 - val_loss: 0.8218 - val_main_output_accuracy: 0.7648 - val_main_output_loss: 0.6656 - val_tof_gate_loss: 0.0239\n",
      "Epoch 44/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 1.3426 - main_output_accuracy: 0.7412 - main_output_loss: 1.1041 - tof_gate_loss: 0.1832 - val_loss: 0.7908 - val_main_output_accuracy: 0.7629 - val_main_output_loss: 0.6412 - val_tof_gate_loss: 0.0110\n",
      "Epoch 45/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 225ms/step - loss: 1.2788 - main_output_accuracy: 0.7463 - main_output_loss: 1.0675 - tof_gate_loss: 0.1672 - val_loss: 0.8248 - val_main_output_accuracy: 0.7528 - val_main_output_loss: 0.6698 - val_tof_gate_loss: 0.0210\n",
      "Epoch 46/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 215ms/step - loss: 1.0677 - main_output_accuracy: 0.7939 - main_output_loss: 0.8558 - tof_gate_loss: 0.1300 - val_loss: 0.7891 - val_main_output_accuracy: 0.7824 - val_main_output_loss: 0.6299 - val_tof_gate_loss: 0.0298\n",
      "Epoch 47/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - loss: 1.3654 - main_output_accuracy: 0.7420 - main_output_loss: 1.1179 - tof_gate_loss: 0.2048 - val_loss: 0.8558 - val_main_output_accuracy: 0.7553 - val_main_output_loss: 0.7056 - val_tof_gate_loss: 0.0129\n",
      "Epoch 48/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 213ms/step - loss: 1.1274 - main_output_accuracy: 0.7839 - main_output_loss: 0.9082 - tof_gate_loss: 0.1524 - val_loss: 0.8137 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 0.6631 - val_tof_gate_loss: 0.0159\n",
      "Epoch 49/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - loss: 1.1052 - main_output_accuracy: 0.7918 - main_output_loss: 0.8883 - tof_gate_loss: 0.1432 - val_loss: 0.8595 - val_main_output_accuracy: 0.7415 - val_main_output_loss: 0.7124 - val_tof_gate_loss: 0.0104\n",
      "Epoch 50/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.1320 - main_output_accuracy: 0.7889 - main_output_loss: 0.9127 - tof_gate_loss: 0.1402 - val_loss: 0.8095 - val_main_output_accuracy: 0.7604 - val_main_output_loss: 0.6591 - val_tof_gate_loss: 0.0189\n",
      "Epoch 51/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 1.1291 - main_output_accuracy: 0.7980 - main_output_loss: 0.9071 - tof_gate_loss: 0.1495 - val_loss: 0.7969 - val_main_output_accuracy: 0.7774 - val_main_output_loss: 0.6459 - val_tof_gate_loss: 0.0210\n",
      "Epoch 52/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 227ms/step - loss: 1.1656 - main_output_accuracy: 0.7769 - main_output_loss: 0.9438 - tof_gate_loss: 0.1626 - val_loss: 0.8825 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 0.7371 - val_tof_gate_loss: 0.0115\n",
      "Epoch 53/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 228ms/step - loss: 1.2209 - main_output_accuracy: 0.7849 - main_output_loss: 0.9978 - tof_gate_loss: 0.1652 - val_loss: 0.8467 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 0.6980 - val_tof_gate_loss: 0.0175\n",
      "Epoch 54/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 1.1509 - main_output_accuracy: 0.7831 - main_output_loss: 0.9294 - tof_gate_loss: 0.1543 - val_loss: 0.7939 - val_main_output_accuracy: 0.7761 - val_main_output_loss: 0.6479 - val_tof_gate_loss: 0.0131\n",
      "Epoch 55/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - loss: 1.1684 - main_output_accuracy: 0.7904 - main_output_loss: 0.9521 - tof_gate_loss: 0.1615 - val_loss: 0.7669 - val_main_output_accuracy: 0.7767 - val_main_output_loss: 0.6201 - val_tof_gate_loss: 0.0157\n",
      "Epoch 56/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 1.0519 - main_output_accuracy: 0.8042 - main_output_loss: 0.8610 - tof_gate_loss: 0.1455 - val_loss: 0.7557 - val_main_output_accuracy: 0.7987 - val_main_output_loss: 0.6080 - val_tof_gate_loss: 0.0164\n",
      "Epoch 57/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 1.2050 - main_output_accuracy: 0.7934 - main_output_loss: 0.9783 - tof_gate_loss: 0.1700 - val_loss: 0.8336 - val_main_output_accuracy: 0.7654 - val_main_output_loss: 0.6905 - val_tof_gate_loss: 0.0127\n",
      "Epoch 58/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - loss: 1.2256 - main_output_accuracy: 0.7855 - main_output_loss: 1.0006 - tof_gate_loss: 0.1726 - val_loss: 0.8066 - val_main_output_accuracy: 0.7767 - val_main_output_loss: 0.6607 - val_tof_gate_loss: 0.0155\n",
      "Epoch 59/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - loss: 1.3809 - main_output_accuracy: 0.7592 - main_output_loss: 1.1310 - tof_gate_loss: 0.2070 - val_loss: 0.8168 - val_main_output_accuracy: 0.7654 - val_main_output_loss: 0.6700 - val_tof_gate_loss: 0.0178\n",
      "Epoch 60/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 226ms/step - loss: 1.1385 - main_output_accuracy: 0.8161 - main_output_loss: 0.9161 - tof_gate_loss: 0.1619 - val_loss: 0.7994 - val_main_output_accuracy: 0.7767 - val_main_output_loss: 0.6562 - val_tof_gate_loss: 0.0127\n",
      "Epoch 61/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 220ms/step - loss: 1.0400 - main_output_accuracy: 0.8126 - main_output_loss: 0.8270 - tof_gate_loss: 0.1388 - val_loss: 0.8311 - val_main_output_accuracy: 0.7553 - val_main_output_loss: 0.6872 - val_tof_gate_loss: 0.0163\n",
      "Epoch 62/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.0425 - main_output_accuracy: 0.8099 - main_output_loss: 0.8340 - tof_gate_loss: 0.1381 - val_loss: 0.7427 - val_main_output_accuracy: 0.7855 - val_main_output_loss: 0.5940 - val_tof_gate_loss: 0.0248\n",
      "Epoch 63/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 232ms/step - loss: 1.1427 - main_output_accuracy: 0.7875 - main_output_loss: 0.9417 - tof_gate_loss: 0.1676 - val_loss: 0.7842 - val_main_output_accuracy: 0.7692 - val_main_output_loss: 0.6381 - val_tof_gate_loss: 0.0184\n",
      "Epoch 64/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - loss: 1.0548 - main_output_accuracy: 0.8164 - main_output_loss: 0.8450 - tof_gate_loss: 0.1429 - val_loss: 0.7816 - val_main_output_accuracy: 0.7792 - val_main_output_loss: 0.6397 - val_tof_gate_loss: 0.0119\n",
      "Epoch 65/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 222ms/step - loss: 1.1312 - main_output_accuracy: 0.8190 - main_output_loss: 0.9134 - tof_gate_loss: 0.1610 - val_loss: 0.7574 - val_main_output_accuracy: 0.7881 - val_main_output_loss: 0.6139 - val_tof_gate_loss: 0.0153\n",
      "Epoch 66/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 231ms/step - loss: 0.9790 - main_output_accuracy: 0.8380 - main_output_loss: 0.7785 - tof_gate_loss: 0.1293 - val_loss: 0.8259 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 0.6848 - val_tof_gate_loss: 0.0121\n",
      "Epoch 67/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - loss: 1.0665 - main_output_accuracy: 0.8360 - main_output_loss: 0.8449 - tof_gate_loss: 0.1687 - val_loss: 0.7785 - val_main_output_accuracy: 0.7761 - val_main_output_loss: 0.6370 - val_tof_gate_loss: 0.0124\n",
      "Epoch 68/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 225ms/step - loss: 1.0057 - main_output_accuracy: 0.8548 - main_output_loss: 0.7980 - tof_gate_loss: 0.1425 - val_loss: 0.8047 - val_main_output_accuracy: 0.7799 - val_main_output_loss: 0.6616 - val_tof_gate_loss: 0.0130\n",
      "Epoch 69/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - loss: 1.0924 - main_output_accuracy: 0.7997 - main_output_loss: 0.8747 - tof_gate_loss: 0.1597 - val_loss: 0.7664 - val_main_output_accuracy: 0.7881 - val_main_output_loss: 0.6228 - val_tof_gate_loss: 0.0147\n",
      "Epoch 70/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 1.1447 - main_output_accuracy: 0.8184 - main_output_loss: 0.9255 - tof_gate_loss: 0.1651 - val_loss: 0.7784 - val_main_output_accuracy: 0.7918 - val_main_output_loss: 0.6352 - val_tof_gate_loss: 0.0173\n",
      "Epoch 71/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 1.2208 - main_output_accuracy: 0.8104 - main_output_loss: 0.9894 - tof_gate_loss: 0.1891 - val_loss: 0.7674 - val_main_output_accuracy: 0.7937 - val_main_output_loss: 0.6265 - val_tof_gate_loss: 0.0134\n",
      "Epoch 72/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 220ms/step - loss: 1.1872 - main_output_accuracy: 0.8117 - main_output_loss: 0.9634 - tof_gate_loss: 0.1808 - val_loss: 0.8297 - val_main_output_accuracy: 0.7704 - val_main_output_loss: 0.6868 - val_tof_gate_loss: 0.0216\n",
      "Epoch 73/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - loss: 0.9136 - main_output_accuracy: 0.8528 - main_output_loss: 0.7152 - tof_gate_loss: 0.1253 - val_loss: 0.7878 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 0.6461 - val_tof_gate_loss: 0.0161\n",
      "Epoch 74/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 1.1282 - main_output_accuracy: 0.8151 - main_output_loss: 0.9153 - tof_gate_loss: 0.1638 - val_loss: 0.7602 - val_main_output_accuracy: 0.7887 - val_main_output_loss: 0.6202 - val_tof_gate_loss: 0.0144\n",
      "Epoch 75/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 1.2573 - main_output_accuracy: 0.8058 - main_output_loss: 1.0242 - tof_gate_loss: 0.1951 - val_loss: 0.7718 - val_main_output_accuracy: 0.7918 - val_main_output_loss: 0.6281 - val_tof_gate_loss: 0.0205\n",
      "Epoch 76/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 1.0862 - main_output_accuracy: 0.8288 - main_output_loss: 0.8748 - tof_gate_loss: 0.1756 - val_loss: 0.7982 - val_main_output_accuracy: 0.7862 - val_main_output_loss: 0.6559 - val_tof_gate_loss: 0.0201\n"
     ]
    }
   ],
   "source": [
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "meta_cols = ['row_id', 'sequence_id', 'sequence_counter', 'subject']\n",
    "\n",
    "raw_tof_cols = [f'tof_{i}_v{j}' for i in range(1,6) for j in range(0, 64)]\n",
    "\n",
    "imu_cols = [\n",
    "    'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', \n",
    "    'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance',\n",
    "    'angular_accel_x', 'angular_accel_y', 'angular_accel_z'\n",
    "]\n",
    "\n",
    "tof_cols = [\n",
    "    'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5',\n",
    "    'tof_1_mean', 'tof_1_std', 'tof_1_min', 'tof_1_max', 'tof_1_diff_mean', 'tof_1_mean_decay', 'tof_1_active_pixels', 'tof_1_centroid_x', 'tof_1_centroid_y',\n",
    "    'tof_2_mean', 'tof_2_std', 'tof_2_min', 'tof_2_max', 'tof_2_diff_mean', 'tof_2_mean_decay', 'tof_2_active_pixels', 'tof_2_centroid_x', 'tof_2_centroid_y',\n",
    "    'tof_3_mean', 'tof_3_std', 'tof_3_min', 'tof_3_max', 'tof_3_diff_mean', 'tof_3_mean_decay', 'tof_3_active_pixels', 'tof_3_centroid_x', 'tof_3_centroid_y',\n",
    "    'tof_4_mean', 'tof_4_std', 'tof_4_min', 'tof_4_max', 'tof_4_diff_mean', 'tof_4_mean_decay', 'tof_4_active_pixels', 'tof_4_centroid_x', 'tof_4_centroid_y',\n",
    "    'tof_5_mean', 'tof_5_std', 'tof_5_min', 'tof_5_max', 'tof_5_diff_mean', 'tof_5_mean_decay', 'tof_5_active_pixels', 'tof_5_centroid_x', 'tof_5_centroid_y'\n",
    "]\n",
    "feature_cols = imu_cols + tof_cols\n",
    "imu_dim = len(imu_cols)\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION\n",
    "# =====================================================================================\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "print(\"\\n▶ PHASE: Training on train_val split...\")\n",
    "\n",
    "print(\"\\n  Engineering all features from the clean base data...\")\n",
    "imu_dim = len(imu_cols)\n",
    "\n",
    "print(\"  Encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "gesture_int_col = le.fit_transform(df['gesture'].to_pandas())\n",
    "df = df.with_columns(pl.Series(name=\"gesture_int\", values=gesture_int_col))\n",
    "\n",
    "cv_info = df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "train_ix, val_ix = train_test_split(all_sequence_ids, test_size=0.2)\n",
    "\n",
    "train_df, val_df = df.filter(pl.col('sequence_id').is_in(train_ix)), df.filter(pl.col('sequence_id').is_in(val_ix))\n",
    "\n",
    "print(\"  Fitting final scaler on all training data...\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[feature_cols].to_numpy())\n",
    "\n",
    "print(\"  Preparing full dataset for training...\")\n",
    "# Apply scaling to the full dataset\n",
    "train_scaled_features = scaler.transform(train_df[feature_cols])\n",
    "val_scaled_features = scaler.transform(val_df[feature_cols])\n",
    "\n",
    "X_train_scaled_features = pl.DataFrame(train_scaled_features, schema=feature_cols)\n",
    "X_val_scaled_features = pl.DataFrame(val_scaled_features, schema=feature_cols)\n",
    "\n",
    "# This print syntax is specific to your original code\n",
    "print(X_train_scaled_features[:, :imu_dim].columns)\n",
    "print(X_train_scaled_features[:, imu_dim:].columns)\n",
    "\n",
    "# Add gesture_int and sequence_id for sequence creation\n",
    "meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "# Generate gate targets for the full dataset\n",
    "train_gate_df = generate_gate_targets(train_df_final, tof_cols)\n",
    "val_gate_df = generate_gate_targets(val_df_final, tof_cols)\n",
    "\n",
    "# Create sequences from the full dataset\n",
    "X_train, y_train, train_gate_df = create_sequence_dataset(train_df_final, feature_cols, train_gate_df)\n",
    "X_val, y_val, val_gate_df = create_sequence_dataset(val_df_final, feature_cols, val_gate_df)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='pre', dtype='float32')\n",
    "X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='pre', dtype='float32')\n",
    "y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "\n",
    "del train_df_final, val_df_final, X_train_scaled_features, X_val_scaled_features, X_train, y_train, X_val, y_val\n",
    "gc.collect()    \n",
    "\n",
    "FINAL_EPOCHS = 150 \n",
    "\n",
    "full_train_dataset = GatedMixupGenerator(\n",
    "    X=X_train_padded, y=y_train_cat, gate_targets=train_gate_df,\n",
    "    batch_size=BATCH_SIZE, imu_dim=imu_dim, alpha=0.2, masking_prob=0.25\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    X_val_padded, {'main_output': y_val_cat, 'tof_gate': val_gate_df[:, np.newaxis]}\n",
    ")).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_main_output_accuracy',\n",
    "    mode='max',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "callbacks = [early_stopping]\n",
    "model = create_model(full_train_dataset, imu_dim)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=LR_INIT, weight_decay=WD)\n",
    "model.compile(optimizer=optimizer, loss={'main_output': 'categorical_crossentropy', 'tof_gate': 'binary_crossentropy'},\n",
    "              loss_weights={'main_output': 1.0, 'tof_gate': 0.5}, metrics={\"main_output\": \"accuracy\"})\n",
    "history = model.fit(full_train_dataset, epochs=FINAL_EPOCHS, verbose=1, validation_data=val_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "252178aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(56)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(history.history['val_main_output_accuracy'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd26269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16981132328510284,\n",
       " 0.3660377264022827,\n",
       " 0.4547169804573059,\n",
       " 0.5163521766662598,\n",
       " 0.5842767357826233,\n",
       " 0.6113207340240479,\n",
       " 0.6364780068397522,\n",
       " 0.6402515769004822,\n",
       " 0.5830188393592834,\n",
       " 0.6566037535667419,\n",
       " 0.6754717230796814,\n",
       " 0.6729559898376465,\n",
       " 0.6635220050811768,\n",
       " 0.6767295598983765,\n",
       " 0.6817610263824463,\n",
       " 0.6880503296852112,\n",
       " 0.6811320781707764,\n",
       " 0.6886792182922363,\n",
       " 0.7188678979873657,\n",
       " 0.6974842548370361,\n",
       " 0.696855366230011,\n",
       " 0.7081760764122009,\n",
       " 0.7188678979873657,\n",
       " 0.6918238997459412,\n",
       " 0.7270440459251404,\n",
       " 0.7238993644714355,\n",
       " 0.7069182395935059,\n",
       " 0.7144653797149658,\n",
       " 0.7383647561073303,\n",
       " 0.696855366230011,\n",
       " 0.7446540594100952,\n",
       " 0.7421383857727051,\n",
       " 0.7163522243499756,\n",
       " 0.7270440459251404,\n",
       " 0.7446540594100952,\n",
       " 0.7163522243499756,\n",
       " 0.7471697926521301,\n",
       " 0.7597483992576599,\n",
       " 0.7647798657417297,\n",
       " 0.7622641324996948,\n",
       " 0.7616352438926697,\n",
       " 0.7610062956809998,\n",
       " 0.7647798657417297,\n",
       " 0.7628930807113647,\n",
       " 0.7528302073478699,\n",
       " 0.7823899388313293,\n",
       " 0.7553459405899048,\n",
       " 0.7672955989837646,\n",
       " 0.7415094375610352,\n",
       " 0.7603773474693298,\n",
       " 0.7773584723472595,\n",
       " 0.7389937043190002,\n",
       " 0.7452830076217651,\n",
       " 0.7761006355285645,\n",
       " 0.7767295837402344,\n",
       " 0.7987421154975891,\n",
       " 0.7654088139533997,\n",
       " 0.7767295837402344,\n",
       " 0.7654088139533997,\n",
       " 0.7767295837402344,\n",
       " 0.7553459405899048,\n",
       " 0.7855346202850342,\n",
       " 0.7691823840141296,\n",
       " 0.7792452573776245,\n",
       " 0.7880502939224243,\n",
       " 0.7672955989837646,\n",
       " 0.7761006355285645,\n",
       " 0.7798742055892944,\n",
       " 0.7880502939224243,\n",
       " 0.7918239235877991,\n",
       " 0.7937107086181641,\n",
       " 0.7704402804374695,\n",
       " 0.7842767238616943,\n",
       " 0.7886792421340942,\n",
       " 0.7918239235877991,\n",
       " 0.7861635088920593]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_main_output_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbad7751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7987421154975891)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_main_output_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
