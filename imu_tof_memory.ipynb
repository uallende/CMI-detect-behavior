{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07992aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 18:45:44.951170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754761544.970592   27537 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754761544.976422   27537 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754761545.006344   27537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754761545.006389   27537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754761545.006392   27537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754761545.006395   27537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-09 18:45:45.014060: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import argmax\n",
    "from tensorflow.data import AUTOTUNE, Dataset\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Input, \n",
    "    GlobalAveragePooling1D,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    Dropout,\n",
    "    Lambda\n",
    "    )\n",
    "\n",
    "from src.nn_blocks import unet_se_cnn, features_processing, GatedMixupGenerator, tof_block\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    perform_target_encoding, \n",
    "    build_dataset,\n",
    "    create_sequence_dataset,\n",
    "    pl_standard_scaling,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "from src.constants import DATA_PATH\n",
    "from tensorflow import argmax\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13fa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in train_dataset:\n",
    "#     x=e[0]\n",
    "#     y=e[1]\n",
    "#     break\n",
    "\n",
    "# original = x    \n",
    "# inputs = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01d3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_definition(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    # inp = Input(shape=(128, imu_dim+tof_dim))\n",
    "    inp = Input(shape=input_shape)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=64, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c19785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# def shape_debug(x, msg=\"\"):\n",
    "#     print(f\"{msg} -> {x.shape}\")\n",
    "#     return x\n",
    "\n",
    "# def shape_debug_layer(msg=\"\"):\n",
    "#     return Lambda(lambda t: tf.print(f\"{msg} ->\", tf.shape(t)) or t,\n",
    "#                   name=f\"debug_{msg.replace(' ', '_')}\")\n",
    "\n",
    "\n",
    "# def unet_se_cnn_debug(x, unet_depth=3, base_filters=64, kernel_size=3, drop=0.3):\n",
    "#     filters = base_filters\n",
    "#     skips = []\n",
    "\n",
    "#     for d in range(unet_depth):\n",
    "#         x = shape_debug(x, f\"IMU encoder start depth {d}\")\n",
    "#         x = residual_se_cnn_block(x, filters, kernel_size, drop=drop)\n",
    "#         x = shape_debug(x, f\"IMU after residual+pool depth {d}\")\n",
    "#         skips.append(x)\n",
    "#         filters *= 2\n",
    "\n",
    "#     c_shape = x.shape[-1]\n",
    "#     x = Dense(128)(x)\n",
    "#     x = Dense(c_shape)(x)\n",
    "#     x = shape_debug(x, \"IMU bottleneck\")\n",
    "\n",
    "#     for d, skip in enumerate(reversed(skips)):\n",
    "#         filters //= 2\n",
    "#         x = res_se_cnn_decoder_block(x, filters, kernel_size, drop=drop, skip_connection=skip)\n",
    "#         x = shape_debug(x, f\"IMU decoder after upsampling depth {d}\")\n",
    "\n",
    "#     return x\n",
    "\n",
    "# def tof_block_debug(tof, wd=1e-4):\n",
    "#     x = shape_debug(tof, \"ToF input\")\n",
    "#     x = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = shape_debug(x, \"ToF after Conv1D-1\")\n",
    "#     x = MaxPooling1D(2)(x)\n",
    "#     x = shape_debug(x, \"ToF after pool-1\")\n",
    "#     x = Dropout(0.2)(x)\n",
    "\n",
    "#     x = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = shape_debug(x, \"ToF after Conv1D-2\")\n",
    "#     x = MaxPooling1D(2)(x)\n",
    "#     x = shape_debug(x, \"ToF after pool-2\")\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c998fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model_definition(x)\n",
    "# for layer in model.layers:\n",
    "#     print(layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Parquet file for sequence IDs...\n",
      "Found 8151 unique sequences.\n",
      "\n",
      "=== Fold 1 ===\n",
      "Loading data for fold 1...\n",
      "Fold data loaded.\n",
      "Fully padded dataset shape: (6113, 128, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754761587.118613   27537 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1754761615.771390   27919 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 226ms/step - loss: 3.7619 - main_output_accuracy: 0.1005 - main_output_loss: 3.2613 - tof_gate_loss: 0.6081 - val_loss: 3.0722 - val_main_output_accuracy: 0.2439 - val_main_output_loss: 2.6052 - val_tof_gate_loss: 0.4871\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 3.1301 - main_output_accuracy: 0.2083 - main_output_loss: 2.6977 - tof_gate_loss: 0.3327 - val_loss: 2.8514 - val_main_output_accuracy: 0.2463 - val_main_output_loss: 2.4219 - val_tof_gate_loss: 0.3897\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.9226 - main_output_accuracy: 0.2453 - main_output_loss: 2.5223 - tof_gate_loss: 0.2956 - val_loss: 2.3786 - val_main_output_accuracy: 0.4239 - val_main_output_loss: 2.0031 - val_tof_gate_loss: 0.2159\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 2.7170 - main_output_accuracy: 0.2981 - main_output_loss: 2.3380 - tof_gate_loss: 0.2532 - val_loss: 2.1342 - val_main_output_accuracy: 0.4446 - val_main_output_loss: 1.8082 - val_tof_gate_loss: 0.0646\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 2.7187 - main_output_accuracy: 0.3085 - main_output_loss: 2.3531 - tof_gate_loss: 0.2882 - val_loss: 2.0639 - val_main_output_accuracy: 0.5034 - val_main_output_loss: 1.7534 - val_tof_gate_loss: 0.0809\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 2.5601 - main_output_accuracy: 0.3760 - main_output_loss: 2.2183 - tof_gate_loss: 0.2602 - val_loss: 1.9849 - val_main_output_accuracy: 0.5108 - val_main_output_loss: 1.6962 - val_tof_gate_loss: 0.0596\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 2.4490 - main_output_accuracy: 0.4242 - main_output_loss: 2.1287 - tof_gate_loss: 0.2403 - val_loss: 1.9161 - val_main_output_accuracy: 0.5285 - val_main_output_loss: 1.6464 - val_tof_gate_loss: 0.0442\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 2.3531 - main_output_accuracy: 0.4371 - main_output_loss: 2.0495 - tof_gate_loss: 0.2306 - val_loss: 1.8194 - val_main_output_accuracy: 0.5653 - val_main_output_loss: 1.5651 - val_tof_gate_loss: 0.0408\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - loss: 2.2956 - main_output_accuracy: 0.4537 - main_output_loss: 2.0043 - tof_gate_loss: 0.2365 - val_loss: 1.8161 - val_main_output_accuracy: 0.5613 - val_main_output_loss: 1.5724 - val_tof_gate_loss: 0.0520\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 2.2261 - main_output_accuracy: 0.4687 - main_output_loss: 1.9544 - tof_gate_loss: 0.2044 - val_loss: 1.7256 - val_main_output_accuracy: 0.5839 - val_main_output_loss: 1.4936 - val_tof_gate_loss: 0.0491\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 2.2308 - main_output_accuracy: 0.5100 - main_output_loss: 1.9609 - tof_gate_loss: 0.2522 - val_loss: 1.7152 - val_main_output_accuracy: 0.5868 - val_main_output_loss: 1.4926 - val_tof_gate_loss: 0.0526\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 2.1414 - main_output_accuracy: 0.5136 - main_output_loss: 1.8866 - tof_gate_loss: 0.2323 - val_loss: 1.6583 - val_main_output_accuracy: 0.6251 - val_main_output_loss: 1.4455 - val_tof_gate_loss: 0.0491\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 2.0861 - main_output_accuracy: 0.5204 - main_output_loss: 1.8438 - tof_gate_loss: 0.2016 - val_loss: 1.6912 - val_main_output_accuracy: 0.5903 - val_main_output_loss: 1.4855 - val_tof_gate_loss: 0.0507\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 2.0768 - main_output_accuracy: 0.5401 - main_output_loss: 1.8394 - tof_gate_loss: 0.2207 - val_loss: 1.7158 - val_main_output_accuracy: 0.5819 - val_main_output_loss: 1.5201 - val_tof_gate_loss: 0.0349\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 2.1356 - main_output_accuracy: 0.5304 - main_output_loss: 1.8990 - tof_gate_loss: 0.2428 - val_loss: 1.6214 - val_main_output_accuracy: 0.6241 - val_main_output_loss: 1.4300 - val_tof_gate_loss: 0.0464\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 2.0903 - main_output_accuracy: 0.5438 - main_output_loss: 1.8602 - tof_gate_loss: 0.2431 - val_loss: 1.5637 - val_main_output_accuracy: 0.6560 - val_main_output_loss: 1.3770 - val_tof_gate_loss: 0.0485\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.9738 - main_output_accuracy: 0.5670 - main_output_loss: 1.7585 - tof_gate_loss: 0.2010 - val_loss: 1.5238 - val_main_output_accuracy: 0.6668 - val_main_output_loss: 1.3433 - val_tof_gate_loss: 0.0425\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 1.9958 - main_output_accuracy: 0.5645 - main_output_loss: 1.7806 - tof_gate_loss: 0.2194 - val_loss: 1.5901 - val_main_output_accuracy: 0.6325 - val_main_output_loss: 1.4134 - val_tof_gate_loss: 0.0449\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.9228 - main_output_accuracy: 0.5913 - main_output_loss: 1.7166 - tof_gate_loss: 0.1974 - val_loss: 1.5328 - val_main_output_accuracy: 0.6673 - val_main_output_loss: 1.3602 - val_tof_gate_loss: 0.0417\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.8953 - main_output_accuracy: 0.6227 - main_output_loss: 1.6923 - tof_gate_loss: 0.1940 - val_loss: 1.4966 - val_main_output_accuracy: 0.6717 - val_main_output_loss: 1.3279 - val_tof_gate_loss: 0.0396\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.9006 - main_output_accuracy: 0.6056 - main_output_loss: 1.7014 - tof_gate_loss: 0.1967 - val_loss: 1.5031 - val_main_output_accuracy: 0.6747 - val_main_output_loss: 1.3378 - val_tof_gate_loss: 0.0385\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.8317 - main_output_accuracy: 0.6155 - main_output_loss: 1.6381 - tof_gate_loss: 0.1779 - val_loss: 1.4662 - val_main_output_accuracy: 0.6840 - val_main_output_loss: 1.3042 - val_tof_gate_loss: 0.0367\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 181ms/step - loss: 1.9529 - main_output_accuracy: 0.5920 - main_output_loss: 1.7500 - tof_gate_loss: 0.2459 - val_loss: 1.4908 - val_main_output_accuracy: 0.6712 - val_main_output_loss: 1.3314 - val_tof_gate_loss: 0.0355\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.9151 - main_output_accuracy: 0.6254 - main_output_loss: 1.7193 - tof_gate_loss: 0.2266 - val_loss: 1.4408 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.2852 - val_tof_gate_loss: 0.0312\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.9186 - main_output_accuracy: 0.6145 - main_output_loss: 1.7209 - tof_gate_loss: 0.2362 - val_loss: 1.4679 - val_main_output_accuracy: 0.6781 - val_main_output_loss: 1.3133 - val_tof_gate_loss: 0.0368\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.9215 - main_output_accuracy: 0.6268 - main_output_loss: 1.7270 - tof_gate_loss: 0.2418 - val_loss: 1.4769 - val_main_output_accuracy: 0.6771 - val_main_output_loss: 1.3229 - val_tof_gate_loss: 0.0440\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.8006 - main_output_accuracy: 0.6413 - main_output_loss: 1.6157 - tof_gate_loss: 0.1973 - val_loss: 1.4404 - val_main_output_accuracy: 0.6879 - val_main_output_loss: 1.2902 - val_tof_gate_loss: 0.0331\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.8273 - main_output_accuracy: 0.6357 - main_output_loss: 1.6430 - tof_gate_loss: 0.2086 - val_loss: 1.4273 - val_main_output_accuracy: 0.7061 - val_main_output_loss: 1.2744 - val_tof_gate_loss: 0.0551\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.8863 - main_output_accuracy: 0.6345 - main_output_loss: 1.6954 - tof_gate_loss: 0.2324 - val_loss: 1.4051 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.2571 - val_tof_gate_loss: 0.0372\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.7040 - main_output_accuracy: 0.6698 - main_output_loss: 1.5312 - tof_gate_loss: 0.1632 - val_loss: 1.4230 - val_main_output_accuracy: 0.6953 - val_main_output_loss: 1.2752 - val_tof_gate_loss: 0.0430\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.7203 - main_output_accuracy: 0.6688 - main_output_loss: 1.5461 - tof_gate_loss: 0.1768 - val_loss: 1.3976 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.2545 - val_tof_gate_loss: 0.0261\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.9026 - main_output_accuracy: 0.6415 - main_output_loss: 1.7136 - tof_gate_loss: 0.2544 - val_loss: 1.3984 - val_main_output_accuracy: 0.6992 - val_main_output_loss: 1.2543 - val_tof_gate_loss: 0.0385\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.6912 - main_output_accuracy: 0.6831 - main_output_loss: 1.5193 - tof_gate_loss: 0.1764 - val_loss: 1.3886 - val_main_output_accuracy: 0.7076 - val_main_output_loss: 1.2464 - val_tof_gate_loss: 0.0359\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 1.6735 - main_output_accuracy: 0.6932 - main_output_loss: 1.5036 - tof_gate_loss: 0.1756 - val_loss: 1.3974 - val_main_output_accuracy: 0.6973 - val_main_output_loss: 1.2563 - val_tof_gate_loss: 0.0376\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.7014 - main_output_accuracy: 0.6949 - main_output_loss: 1.5315 - tof_gate_loss: 0.1818 - val_loss: 1.3868 - val_main_output_accuracy: 0.6958 - val_main_output_loss: 1.2469 - val_tof_gate_loss: 0.0357\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.7733 - main_output_accuracy: 0.6731 - main_output_loss: 1.6009 - tof_gate_loss: 0.1994 - val_loss: 1.3824 - val_main_output_accuracy: 0.7134 - val_main_output_loss: 1.2440 - val_tof_gate_loss: 0.0338\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.6457 - main_output_accuracy: 0.7083 - main_output_loss: 1.4805 - tof_gate_loss: 0.1679 - val_loss: 1.3423 - val_main_output_accuracy: 0.7311 - val_main_output_loss: 1.2061 - val_tof_gate_loss: 0.0280\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.7576 - main_output_accuracy: 0.6762 - main_output_loss: 1.5824 - tof_gate_loss: 0.2233 - val_loss: 1.3689 - val_main_output_accuracy: 0.7233 - val_main_output_loss: 1.2330 - val_tof_gate_loss: 0.0264\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.7492 - main_output_accuracy: 0.6928 - main_output_loss: 1.5751 - tof_gate_loss: 0.2174 - val_loss: 1.3502 - val_main_output_accuracy: 0.7233 - val_main_output_loss: 1.2117 - val_tof_gate_loss: 0.0449\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.6870 - main_output_accuracy: 0.6911 - main_output_loss: 1.5286 - tof_gate_loss: 0.2082 - val_loss: 1.3624 - val_main_output_accuracy: 0.7100 - val_main_output_loss: 1.2274 - val_tof_gate_loss: 0.0335\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.7064 - main_output_accuracy: 0.6948 - main_output_loss: 1.5357 - tof_gate_loss: 0.2092 - val_loss: 1.3765 - val_main_output_accuracy: 0.7076 - val_main_output_loss: 1.2429 - val_tof_gate_loss: 0.0311\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.6502 - main_output_accuracy: 0.7188 - main_output_loss: 1.4850 - tof_gate_loss: 0.1885 - val_loss: 1.3597 - val_main_output_accuracy: 0.7179 - val_main_output_loss: 1.2246 - val_tof_gate_loss: 0.0439\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 180ms/step - loss: 1.6968 - main_output_accuracy: 0.7138 - main_output_loss: 1.5303 - tof_gate_loss: 0.2087 - val_loss: 1.3251 - val_main_output_accuracy: 0.7242 - val_main_output_loss: 1.1941 - val_tof_gate_loss: 0.0271\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 1.6842 - main_output_accuracy: 0.7107 - main_output_loss: 1.5210 - tof_gate_loss: 0.2175 - val_loss: 1.3560 - val_main_output_accuracy: 0.7139 - val_main_output_loss: 1.2238 - val_tof_gate_loss: 0.0366\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.6528 - main_output_accuracy: 0.7320 - main_output_loss: 1.4848 - tof_gate_loss: 0.2135 - val_loss: 1.3220 - val_main_output_accuracy: 0.7444 - val_main_output_loss: 1.1907 - val_tof_gate_loss: 0.0332\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.6398 - main_output_accuracy: 0.7144 - main_output_loss: 1.4790 - tof_gate_loss: 0.1820 - val_loss: 1.3156 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.1864 - val_tof_gate_loss: 0.0278\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.6578 - main_output_accuracy: 0.7371 - main_output_loss: 1.4936 - tof_gate_loss: 0.1988 - val_loss: 1.3918 - val_main_output_accuracy: 0.7080 - val_main_output_loss: 1.2633 - val_tof_gate_loss: 0.0268\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.6645 - main_output_accuracy: 0.7067 - main_output_loss: 1.4989 - tof_gate_loss: 0.2101 - val_loss: 1.3159 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1870 - val_tof_gate_loss: 0.0319\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5858 - main_output_accuracy: 0.7428 - main_output_loss: 1.4285 - tof_gate_loss: 0.1761 - val_loss: 1.3096 - val_main_output_accuracy: 0.7404 - val_main_output_loss: 1.1811 - val_tof_gate_loss: 0.0301\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.5680 - main_output_accuracy: 0.7331 - main_output_loss: 1.4085 - tof_gate_loss: 0.1727 - val_loss: 1.3421 - val_main_output_accuracy: 0.7179 - val_main_output_loss: 1.2137 - val_tof_gate_loss: 0.0323\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.4704 - main_output_accuracy: 0.7594 - main_output_loss: 1.3202 - tof_gate_loss: 0.1446 - val_loss: 1.3149 - val_main_output_accuracy: 0.7237 - val_main_output_loss: 1.1892 - val_tof_gate_loss: 0.0245\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.5532 - main_output_accuracy: 0.7522 - main_output_loss: 1.4022 - tof_gate_loss: 0.1766 - val_loss: 1.3043 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1766 - val_tof_gate_loss: 0.0345\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.6218 - main_output_accuracy: 0.7418 - main_output_loss: 1.4580 - tof_gate_loss: 0.1895 - val_loss: 1.3129 - val_main_output_accuracy: 0.7380 - val_main_output_loss: 1.1879 - val_tof_gate_loss: 0.0251\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.6118 - main_output_accuracy: 0.7483 - main_output_loss: 1.4505 - tof_gate_loss: 0.1949 - val_loss: 1.3116 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1862 - val_tof_gate_loss: 0.0303\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5652 - main_output_accuracy: 0.7538 - main_output_loss: 1.4104 - tof_gate_loss: 0.1797 - val_loss: 1.2836 - val_main_output_accuracy: 0.7502 - val_main_output_loss: 1.1596 - val_tof_gate_loss: 0.0278\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.6019 - main_output_accuracy: 0.7354 - main_output_loss: 1.4417 - tof_gate_loss: 0.1986 - val_loss: 1.3088 - val_main_output_accuracy: 0.7345 - val_main_output_loss: 1.1836 - val_tof_gate_loss: 0.0337\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.5424 - main_output_accuracy: 0.7683 - main_output_loss: 1.3890 - tof_gate_loss: 0.1749 - val_loss: 1.3030 - val_main_output_accuracy: 0.7444 - val_main_output_loss: 1.1809 - val_tof_gate_loss: 0.0215\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.5794 - main_output_accuracy: 0.7700 - main_output_loss: 1.4274 - tof_gate_loss: 0.1963 - val_loss: 1.3080 - val_main_output_accuracy: 0.7409 - val_main_output_loss: 1.1863 - val_tof_gate_loss: 0.0213\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.5873 - main_output_accuracy: 0.7633 - main_output_loss: 1.4328 - tof_gate_loss: 0.1880 - val_loss: 1.3007 - val_main_output_accuracy: 0.7419 - val_main_output_loss: 1.1796 - val_tof_gate_loss: 0.0241\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.5711 - main_output_accuracy: 0.7720 - main_output_loss: 1.4133 - tof_gate_loss: 0.2093 - val_loss: 1.3020 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.1787 - val_tof_gate_loss: 0.0347\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.6473 - main_output_accuracy: 0.7584 - main_output_loss: 1.4856 - tof_gate_loss: 0.2231 - val_loss: 1.2939 - val_main_output_accuracy: 0.7522 - val_main_output_loss: 1.1707 - val_tof_gate_loss: 0.0388\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 1.4407 - main_output_accuracy: 0.7870 - main_output_loss: 1.2947 - tof_gate_loss: 0.1488 - val_loss: 1.2993 - val_main_output_accuracy: 0.7409 - val_main_output_loss: 1.1796 - val_tof_gate_loss: 0.0234\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.5624 - main_output_accuracy: 0.7626 - main_output_loss: 1.4162 - tof_gate_loss: 0.1971 - val_loss: 1.2880 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1686 - val_tof_gate_loss: 0.0236\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.6478 - main_output_accuracy: 0.7627 - main_output_loss: 1.4838 - tof_gate_loss: 0.2259 - val_loss: 1.3167 - val_main_output_accuracy: 0.7395 - val_main_output_loss: 1.1966 - val_tof_gate_loss: 0.0289\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.5031 - main_output_accuracy: 0.7879 - main_output_loss: 1.3495 - tof_gate_loss: 0.1953 - val_loss: 1.3037 - val_main_output_accuracy: 0.7493 - val_main_output_loss: 1.1840 - val_tof_gate_loss: 0.0307\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.6135 - main_output_accuracy: 0.7635 - main_output_loss: 1.4604 - tof_gate_loss: 0.1972 - val_loss: 1.3041 - val_main_output_accuracy: 0.7434 - val_main_output_loss: 1.1853 - val_tof_gate_loss: 0.0284\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.5990 - main_output_accuracy: 0.7802 - main_output_loss: 1.4441 - tof_gate_loss: 0.2147 - val_loss: 1.2811 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.1619 - val_tof_gate_loss: 0.0298\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - loss: 1.5933 - main_output_accuracy: 0.7839 - main_output_loss: 1.4374 - tof_gate_loss: 0.2123 - val_loss: 1.3433 - val_main_output_accuracy: 0.7277 - val_main_output_loss: 1.2229 - val_tof_gate_loss: 0.0413\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.5489 - main_output_accuracy: 0.7862 - main_output_loss: 1.3945 - tof_gate_loss: 0.2118 - val_loss: 1.2753 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.1563 - val_tof_gate_loss: 0.0326\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5827 - main_output_accuracy: 0.7720 - main_output_loss: 1.4404 - tof_gate_loss: 0.2122 - val_loss: 1.2818 - val_main_output_accuracy: 0.7532 - val_main_output_loss: 1.1619 - val_tof_gate_loss: 0.0423\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.4025 - main_output_accuracy: 0.8154 - main_output_loss: 1.2603 - tof_gate_loss: 0.1538 - val_loss: 1.3027 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 1.1859 - val_tof_gate_loss: 0.0274\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.4510 - main_output_accuracy: 0.8108 - main_output_loss: 1.3060 - tof_gate_loss: 0.1661 - val_loss: 1.2640 - val_main_output_accuracy: 0.7601 - val_main_output_loss: 1.1478 - val_tof_gate_loss: 0.0253\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5040 - main_output_accuracy: 0.7854 - main_output_loss: 1.3586 - tof_gate_loss: 0.1980 - val_loss: 1.3002 - val_main_output_accuracy: 0.7483 - val_main_output_loss: 1.1842 - val_tof_gate_loss: 0.0283\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.5408 - main_output_accuracy: 0.7857 - main_output_loss: 1.3864 - tof_gate_loss: 0.1974 - val_loss: 1.2805 - val_main_output_accuracy: 0.7488 - val_main_output_loss: 1.1649 - val_tof_gate_loss: 0.0269\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.3886 - main_output_accuracy: 0.8178 - main_output_loss: 1.2426 - tof_gate_loss: 0.1685 - val_loss: 1.2595 - val_main_output_accuracy: 0.7547 - val_main_output_loss: 1.1449 - val_tof_gate_loss: 0.0228\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.4572 - main_output_accuracy: 0.8090 - main_output_loss: 1.3103 - tof_gate_loss: 0.1818 - val_loss: 1.2917 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.1783 - val_tof_gate_loss: 0.0203\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.4366 - main_output_accuracy: 0.8044 - main_output_loss: 1.3021 - tof_gate_loss: 0.1725 - val_loss: 1.2941 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.1800 - val_tof_gate_loss: 0.0244\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.5766 - main_output_accuracy: 0.7678 - main_output_loss: 1.4235 - tof_gate_loss: 0.2160 - val_loss: 1.2979 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.1828 - val_tof_gate_loss: 0.0329\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4292 - main_output_accuracy: 0.8242 - main_output_loss: 1.2872 - tof_gate_loss: 0.1728 - val_loss: 1.2678 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1549 - val_tof_gate_loss: 0.0231\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.4959 - main_output_accuracy: 0.8188 - main_output_loss: 1.3541 - tof_gate_loss: 0.1953 - val_loss: 1.2962 - val_main_output_accuracy: 0.7517 - val_main_output_loss: 1.1819 - val_tof_gate_loss: 0.0312\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.4710 - main_output_accuracy: 0.8106 - main_output_loss: 1.3222 - tof_gate_loss: 0.1877 - val_loss: 1.2818 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1690 - val_tof_gate_loss: 0.0275\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.4141 - main_output_accuracy: 0.8249 - main_output_loss: 1.2697 - tof_gate_loss: 0.1712 - val_loss: 1.2731 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1604 - val_tof_gate_loss: 0.0264\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.3619 - main_output_accuracy: 0.8170 - main_output_loss: 1.2234 - tof_gate_loss: 0.1535 - val_loss: 1.3013 - val_main_output_accuracy: 0.7478 - val_main_output_loss: 1.1902 - val_tof_gate_loss: 0.0233\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.5359 - main_output_accuracy: 0.8090 - main_output_loss: 1.3842 - tof_gate_loss: 0.2150 - val_loss: 1.2771 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1646 - val_tof_gate_loss: 0.0287\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.3206 - main_output_accuracy: 0.8404 - main_output_loss: 1.1831 - tof_gate_loss: 0.1501 - val_loss: 1.3085 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.1979 - val_tof_gate_loss: 0.0225\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4351 - main_output_accuracy: 0.8212 - main_output_loss: 1.2921 - tof_gate_loss: 0.1796 - val_loss: 1.2628 - val_main_output_accuracy: 0.7625 - val_main_output_loss: 1.1512 - val_tof_gate_loss: 0.0255\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - loss: 1.4000 - main_output_accuracy: 0.8411 - main_output_loss: 1.2628 - tof_gate_loss: 0.1729 - val_loss: 1.2795 - val_main_output_accuracy: 0.7576 - val_main_output_loss: 1.1685 - val_tof_gate_loss: 0.0248\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.4169 - main_output_accuracy: 0.8392 - main_output_loss: 1.2783 - tof_gate_loss: 0.1809 - val_loss: 1.2777 - val_main_output_accuracy: 0.7581 - val_main_output_loss: 1.1673 - val_tof_gate_loss: 0.0243\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.5126 - main_output_accuracy: 0.8106 - main_output_loss: 1.3680 - tof_gate_loss: 0.1970 - val_loss: 1.2636 - val_main_output_accuracy: 0.7650 - val_main_output_loss: 1.1531 - val_tof_gate_loss: 0.0258\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.4652 - main_output_accuracy: 0.8205 - main_output_loss: 1.3306 - tof_gate_loss: 0.1986 - val_loss: 1.2649 - val_main_output_accuracy: 0.7601 - val_main_output_loss: 1.1552 - val_tof_gate_loss: 0.0230\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.3469 - main_output_accuracy: 0.8450 - main_output_loss: 1.2102 - tof_gate_loss: 0.1608 - val_loss: 1.2781 - val_main_output_accuracy: 0.7591 - val_main_output_loss: 1.1690 - val_tof_gate_loss: 0.0217\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.4134 - main_output_accuracy: 0.8276 - main_output_loss: 1.2704 - tof_gate_loss: 0.1881 - val_loss: 1.2666 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.1569 - val_tof_gate_loss: 0.0268\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.4084 - main_output_accuracy: 0.8451 - main_output_loss: 1.2662 - tof_gate_loss: 0.1962 - val_loss: 1.2941 - val_main_output_accuracy: 0.7493 - val_main_output_loss: 1.1857 - val_tof_gate_loss: 0.0215\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.4999 - main_output_accuracy: 0.8236 - main_output_loss: 1.3513 - tof_gate_loss: 0.2234 - val_loss: 1.2751 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.1658 - val_tof_gate_loss: 0.0230\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5072 - main_output_accuracy: 0.8207 - main_output_loss: 1.3534 - tof_gate_loss: 0.2212 - val_loss: 1.2633 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1540 - val_tof_gate_loss: 0.0262\n",
      "--- Evaluating Fold 1 ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step\n",
      "Fold 1 Accuracy: 0.7547\n",
      "\n",
      "=== Fold 2 ===\n",
      "Loading data for fold 2...\n",
      "Fold data loaded.\n",
      "Fully padded dataset shape: (6113, 128, 38)\n",
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 211ms/step - loss: 3.7743 - main_output_accuracy: 0.0962 - main_output_loss: 3.2834 - tof_gate_loss: 0.5827 - val_loss: 3.1264 - val_main_output_accuracy: 0.1546 - val_main_output_loss: 2.6848 - val_tof_gate_loss: 0.3575\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 3.0679 - main_output_accuracy: 0.2223 - main_output_loss: 2.6446 - tof_gate_loss: 0.2925 - val_loss: 2.6363 - val_main_output_accuracy: 0.3150 - val_main_output_loss: 2.2428 - val_tof_gate_loss: 0.2151\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 2.8878 - main_output_accuracy: 0.2615 - main_output_loss: 2.4882 - tof_gate_loss: 0.2757 - val_loss: 2.3070 - val_main_output_accuracy: 0.4284 - val_main_output_loss: 1.9483 - val_tof_gate_loss: 0.1481\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 178ms/step - loss: 2.7394 - main_output_accuracy: 0.3079 - main_output_loss: 2.3654 - tof_gate_loss: 0.2443 - val_loss: 2.1349 - val_main_output_accuracy: 0.4755 - val_main_output_loss: 1.8061 - val_tof_gate_loss: 0.0954\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 2.5880 - main_output_accuracy: 0.3587 - main_output_loss: 2.2368 - tof_gate_loss: 0.2268 - val_loss: 2.0049 - val_main_output_accuracy: 0.5201 - val_main_output_loss: 1.6952 - val_tof_gate_loss: 0.0929\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 2.4744 - main_output_accuracy: 0.4056 - main_output_loss: 2.1389 - tof_gate_loss: 0.2348 - val_loss: 1.9284 - val_main_output_accuracy: 0.5363 - val_main_output_loss: 1.6376 - val_tof_gate_loss: 0.0789\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 2.4515 - main_output_accuracy: 0.4202 - main_output_loss: 2.1326 - tof_gate_loss: 0.2431 - val_loss: 1.8518 - val_main_output_accuracy: 0.5594 - val_main_output_loss: 1.5799 - val_tof_gate_loss: 0.0549\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 2.4397 - main_output_accuracy: 0.4342 - main_output_loss: 2.1264 - tof_gate_loss: 0.2716 - val_loss: 1.8096 - val_main_output_accuracy: 0.5672 - val_main_output_loss: 1.5505 - val_tof_gate_loss: 0.0578\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.2781 - main_output_accuracy: 0.4649 - main_output_loss: 1.9853 - tof_gate_loss: 0.2326 - val_loss: 1.8714 - val_main_output_accuracy: 0.5324 - val_main_output_loss: 1.6177 - val_tof_gate_loss: 0.0839\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 2.1861 - main_output_accuracy: 0.5011 - main_output_loss: 1.9065 - tof_gate_loss: 0.2181 - val_loss: 1.7752 - val_main_output_accuracy: 0.5564 - val_main_output_loss: 1.5405 - val_tof_gate_loss: 0.0390\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 2.1820 - main_output_accuracy: 0.5143 - main_output_loss: 1.9144 - tof_gate_loss: 0.2099 - val_loss: 1.7105 - val_main_output_accuracy: 0.6035 - val_main_output_loss: 1.4838 - val_tof_gate_loss: 0.0449\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 2.1788 - main_output_accuracy: 0.5183 - main_output_loss: 1.9250 - tof_gate_loss: 0.2320 - val_loss: 1.6637 - val_main_output_accuracy: 0.6227 - val_main_output_loss: 1.4432 - val_tof_gate_loss: 0.0581\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 2.0868 - main_output_accuracy: 0.5443 - main_output_loss: 1.8363 - tof_gate_loss: 0.2095 - val_loss: 1.6566 - val_main_output_accuracy: 0.6232 - val_main_output_loss: 1.4447 - val_tof_gate_loss: 0.0498\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 2.1472 - main_output_accuracy: 0.5472 - main_output_loss: 1.8996 - tof_gate_loss: 0.2390 - val_loss: 1.6388 - val_main_output_accuracy: 0.6237 - val_main_output_loss: 1.4301 - val_tof_gate_loss: 0.0678\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 2.0835 - main_output_accuracy: 0.5507 - main_output_loss: 1.8431 - tof_gate_loss: 0.2226 - val_loss: 1.5985 - val_main_output_accuracy: 0.6374 - val_main_output_loss: 1.4004 - val_tof_gate_loss: 0.0446\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 2.0979 - main_output_accuracy: 0.5656 - main_output_loss: 1.8631 - tof_gate_loss: 0.2370 - val_loss: 1.5814 - val_main_output_accuracy: 0.6443 - val_main_output_loss: 1.3880 - val_tof_gate_loss: 0.0490\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.9863 - main_output_accuracy: 0.5937 - main_output_loss: 1.7618 - tof_gate_loss: 0.2075 - val_loss: 1.5670 - val_main_output_accuracy: 0.6477 - val_main_output_loss: 1.3800 - val_tof_gate_loss: 0.0402\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 2.0006 - main_output_accuracy: 0.5787 - main_output_loss: 1.7787 - tof_gate_loss: 0.2181 - val_loss: 1.5484 - val_main_output_accuracy: 0.6506 - val_main_output_loss: 1.3656 - val_tof_gate_loss: 0.0433\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.9074 - main_output_accuracy: 0.6179 - main_output_loss: 1.6948 - tof_gate_loss: 0.1928 - val_loss: 1.5342 - val_main_output_accuracy: 0.6644 - val_main_output_loss: 1.3555 - val_tof_gate_loss: 0.0410\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.9263 - main_output_accuracy: 0.6257 - main_output_loss: 1.7177 - tof_gate_loss: 0.1949 - val_loss: 1.4868 - val_main_output_accuracy: 0.6860 - val_main_output_loss: 1.3119 - val_tof_gate_loss: 0.0408\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.9884 - main_output_accuracy: 0.6118 - main_output_loss: 1.7723 - tof_gate_loss: 0.2464 - val_loss: 1.5079 - val_main_output_accuracy: 0.6673 - val_main_output_loss: 1.3361 - val_tof_gate_loss: 0.0454\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.9496 - main_output_accuracy: 0.6090 - main_output_loss: 1.7417 - tof_gate_loss: 0.2274 - val_loss: 1.5036 - val_main_output_accuracy: 0.6605 - val_main_output_loss: 1.3371 - val_tof_gate_loss: 0.0336\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.9892 - main_output_accuracy: 0.6103 - main_output_loss: 1.7794 - tof_gate_loss: 0.2487 - val_loss: 1.4648 - val_main_output_accuracy: 0.6953 - val_main_output_loss: 1.3004 - val_tof_gate_loss: 0.0377\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.8163 - main_output_accuracy: 0.6522 - main_output_loss: 1.6192 - tof_gate_loss: 0.1986 - val_loss: 1.5425 - val_main_output_accuracy: 0.6541 - val_main_output_loss: 1.3779 - val_tof_gate_loss: 0.0465\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.8541 - main_output_accuracy: 0.6417 - main_output_loss: 1.6583 - tof_gate_loss: 0.2018 - val_loss: 1.4519 - val_main_output_accuracy: 0.6968 - val_main_output_loss: 1.2911 - val_tof_gate_loss: 0.0397\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.8382 - main_output_accuracy: 0.6407 - main_output_loss: 1.6462 - tof_gate_loss: 0.2050 - val_loss: 1.5233 - val_main_output_accuracy: 0.6457 - val_main_output_loss: 1.3668 - val_tof_gate_loss: 0.0333\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.8739 - main_output_accuracy: 0.6446 - main_output_loss: 1.6844 - tof_gate_loss: 0.2143 - val_loss: 1.4464 - val_main_output_accuracy: 0.6909 - val_main_output_loss: 1.2923 - val_tof_gate_loss: 0.0315\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.7799 - main_output_accuracy: 0.6656 - main_output_loss: 1.5933 - tof_gate_loss: 0.1927 - val_loss: 1.4379 - val_main_output_accuracy: 0.6781 - val_main_output_loss: 1.2852 - val_tof_gate_loss: 0.0308\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.8804 - main_output_accuracy: 0.6297 - main_output_loss: 1.6883 - tof_gate_loss: 0.2264 - val_loss: 1.4451 - val_main_output_accuracy: 0.6928 - val_main_output_loss: 1.2946 - val_tof_gate_loss: 0.0308\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.7730 - main_output_accuracy: 0.6659 - main_output_loss: 1.5922 - tof_gate_loss: 0.1737 - val_loss: 1.4059 - val_main_output_accuracy: 0.6997 - val_main_output_loss: 1.2583 - val_tof_gate_loss: 0.0240\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.7209 - main_output_accuracy: 0.6805 - main_output_loss: 1.5441 - tof_gate_loss: 0.1754 - val_loss: 1.4033 - val_main_output_accuracy: 0.7144 - val_main_output_loss: 1.2559 - val_tof_gate_loss: 0.0328\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.8133 - main_output_accuracy: 0.6618 - main_output_loss: 1.6252 - tof_gate_loss: 0.2207 - val_loss: 1.4649 - val_main_output_accuracy: 0.6786 - val_main_output_loss: 1.3183 - val_tof_gate_loss: 0.0352\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.7134 - main_output_accuracy: 0.6827 - main_output_loss: 1.5348 - tof_gate_loss: 0.1952 - val_loss: 1.3705 - val_main_output_accuracy: 0.7257 - val_main_output_loss: 1.2264 - val_tof_gate_loss: 0.0289\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.8329 - main_output_accuracy: 0.6692 - main_output_loss: 1.6494 - tof_gate_loss: 0.2226 - val_loss: 1.4440 - val_main_output_accuracy: 0.6884 - val_main_output_loss: 1.3011 - val_tof_gate_loss: 0.0296\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.7680 - main_output_accuracy: 0.6727 - main_output_loss: 1.5914 - tof_gate_loss: 0.2107 - val_loss: 1.3960 - val_main_output_accuracy: 0.7056 - val_main_output_loss: 1.2520 - val_tof_gate_loss: 0.0419\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.7435 - main_output_accuracy: 0.6753 - main_output_loss: 1.5683 - tof_gate_loss: 0.2065 - val_loss: 1.3796 - val_main_output_accuracy: 0.7169 - val_main_output_loss: 1.2399 - val_tof_gate_loss: 0.0262\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.7300 - main_output_accuracy: 0.6866 - main_output_loss: 1.5559 - tof_gate_loss: 0.1966 - val_loss: 1.3592 - val_main_output_accuracy: 0.7198 - val_main_output_loss: 1.2194 - val_tof_gate_loss: 0.0317\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.6581 - main_output_accuracy: 0.7160 - main_output_loss: 1.4855 - tof_gate_loss: 0.2001 - val_loss: 1.3748 - val_main_output_accuracy: 0.7203 - val_main_output_loss: 1.2367 - val_tof_gate_loss: 0.0266\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6782 - main_output_accuracy: 0.7151 - main_output_loss: 1.5086 - tof_gate_loss: 0.1814 - val_loss: 1.3803 - val_main_output_accuracy: 0.7046 - val_main_output_loss: 1.2453 - val_tof_gate_loss: 0.0214\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.6939 - main_output_accuracy: 0.7002 - main_output_loss: 1.5226 - tof_gate_loss: 0.1951 - val_loss: 1.3773 - val_main_output_accuracy: 0.7179 - val_main_output_loss: 1.2411 - val_tof_gate_loss: 0.0280\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.7392 - main_output_accuracy: 0.6923 - main_output_loss: 1.5660 - tof_gate_loss: 0.2091 - val_loss: 1.3832 - val_main_output_accuracy: 0.7056 - val_main_output_loss: 1.2484 - val_tof_gate_loss: 0.0260\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.5683 - main_output_accuracy: 0.7307 - main_output_loss: 1.4058 - tof_gate_loss: 0.1639 - val_loss: 1.3719 - val_main_output_accuracy: 0.7208 - val_main_output_loss: 1.2385 - val_tof_gate_loss: 0.0226\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.7525 - main_output_accuracy: 0.6962 - main_output_loss: 1.5774 - tof_gate_loss: 0.2330 - val_loss: 1.3705 - val_main_output_accuracy: 0.7154 - val_main_output_loss: 1.2349 - val_tof_gate_loss: 0.0342\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.6581 - main_output_accuracy: 0.7171 - main_output_loss: 1.4911 - tof_gate_loss: 0.1945 - val_loss: 1.3653 - val_main_output_accuracy: 0.7198 - val_main_output_loss: 1.2311 - val_tof_gate_loss: 0.0325\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.7063 - main_output_accuracy: 0.7078 - main_output_loss: 1.5362 - tof_gate_loss: 0.1959 - val_loss: 1.3447 - val_main_output_accuracy: 0.7237 - val_main_output_loss: 1.2121 - val_tof_gate_loss: 0.0319\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.6774 - main_output_accuracy: 0.7182 - main_output_loss: 1.5092 - tof_gate_loss: 0.2042 - val_loss: 1.3661 - val_main_output_accuracy: 0.7233 - val_main_output_loss: 1.2349 - val_tof_gate_loss: 0.0316\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.6313 - main_output_accuracy: 0.7269 - main_output_loss: 1.4671 - tof_gate_loss: 0.1925 - val_loss: 1.3460 - val_main_output_accuracy: 0.7301 - val_main_output_loss: 1.2162 - val_tof_gate_loss: 0.0267\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.6880 - main_output_accuracy: 0.7127 - main_output_loss: 1.5224 - tof_gate_loss: 0.2013 - val_loss: 1.3343 - val_main_output_accuracy: 0.7306 - val_main_output_loss: 1.2056 - val_tof_gate_loss: 0.0238\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.6084 - main_output_accuracy: 0.7342 - main_output_loss: 1.4526 - tof_gate_loss: 0.1806 - val_loss: 1.3259 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.1967 - val_tof_gate_loss: 0.0288\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.6989 - main_output_accuracy: 0.7233 - main_output_loss: 1.5373 - tof_gate_loss: 0.2061 - val_loss: 1.3845 - val_main_output_accuracy: 0.7130 - val_main_output_loss: 1.2560 - val_tof_gate_loss: 0.0286\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.6077 - main_output_accuracy: 0.7381 - main_output_loss: 1.4481 - tof_gate_loss: 0.1814 - val_loss: 1.3284 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2015 - val_tof_gate_loss: 0.0259\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.7261 - main_output_accuracy: 0.7321 - main_output_loss: 1.5645 - tof_gate_loss: 0.2219 - val_loss: 1.3368 - val_main_output_accuracy: 0.7272 - val_main_output_loss: 1.2098 - val_tof_gate_loss: 0.0314\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.6826 - main_output_accuracy: 0.7182 - main_output_loss: 1.5175 - tof_gate_loss: 0.2149 - val_loss: 1.3416 - val_main_output_accuracy: 0.7277 - val_main_output_loss: 1.2144 - val_tof_gate_loss: 0.0327\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.6841 - main_output_accuracy: 0.7348 - main_output_loss: 1.5240 - tof_gate_loss: 0.2255 - val_loss: 1.3298 - val_main_output_accuracy: 0.7252 - val_main_output_loss: 1.2041 - val_tof_gate_loss: 0.0297\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.6798 - main_output_accuracy: 0.7408 - main_output_loss: 1.5175 - tof_gate_loss: 0.2299 - val_loss: 1.3414 - val_main_output_accuracy: 0.7188 - val_main_output_loss: 1.2155 - val_tof_gate_loss: 0.0322\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.5929 - main_output_accuracy: 0.7515 - main_output_loss: 1.4346 - tof_gate_loss: 0.1876 - val_loss: 1.3588 - val_main_output_accuracy: 0.7282 - val_main_output_loss: 1.2348 - val_tof_gate_loss: 0.0275\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.6389 - main_output_accuracy: 0.7445 - main_output_loss: 1.4792 - tof_gate_loss: 0.2164 - val_loss: 1.3442 - val_main_output_accuracy: 0.7228 - val_main_output_loss: 1.2205 - val_tof_gate_loss: 0.0281\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.5125 - main_output_accuracy: 0.7838 - main_output_loss: 1.3596 - tof_gate_loss: 0.1710 - val_loss: 1.3285 - val_main_output_accuracy: 0.7291 - val_main_output_loss: 1.2065 - val_tof_gate_loss: 0.0220\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6070 - main_output_accuracy: 0.7527 - main_output_loss: 1.4481 - tof_gate_loss: 0.1997 - val_loss: 1.3181 - val_main_output_accuracy: 0.7360 - val_main_output_loss: 1.1952 - val_tof_gate_loss: 0.0292\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.4789 - main_output_accuracy: 0.7862 - main_output_loss: 1.3286 - tof_gate_loss: 0.1649 - val_loss: 1.3267 - val_main_output_accuracy: 0.7301 - val_main_output_loss: 1.2044 - val_tof_gate_loss: 0.0270\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5316 - main_output_accuracy: 0.7701 - main_output_loss: 1.3799 - tof_gate_loss: 0.1771 - val_loss: 1.3260 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.2031 - val_tof_gate_loss: 0.0334\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.4372 - main_output_accuracy: 0.7963 - main_output_loss: 1.2960 - tof_gate_loss: 0.1545 - val_loss: 1.3515 - val_main_output_accuracy: 0.7252 - val_main_output_loss: 1.2310 - val_tof_gate_loss: 0.0253\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.6009 - main_output_accuracy: 0.7547 - main_output_loss: 1.4492 - tof_gate_loss: 0.1819 - val_loss: 1.3316 - val_main_output_accuracy: 0.7262 - val_main_output_loss: 1.2129 - val_tof_gate_loss: 0.0196\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.5317 - main_output_accuracy: 0.7709 - main_output_loss: 1.3858 - tof_gate_loss: 0.1700 - val_loss: 1.3146 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.1948 - val_tof_gate_loss: 0.0238\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4742 - main_output_accuracy: 0.7845 - main_output_loss: 1.3272 - tof_gate_loss: 0.1671 - val_loss: 1.3059 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.1849 - val_tof_gate_loss: 0.0312\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4788 - main_output_accuracy: 0.7859 - main_output_loss: 1.3270 - tof_gate_loss: 0.1709 - val_loss: 1.3089 - val_main_output_accuracy: 0.7375 - val_main_output_loss: 1.1907 - val_tof_gate_loss: 0.0212\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.5165 - main_output_accuracy: 0.7890 - main_output_loss: 1.3688 - tof_gate_loss: 0.1702 - val_loss: 1.3308 - val_main_output_accuracy: 0.7306 - val_main_output_loss: 1.2146 - val_tof_gate_loss: 0.0165\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.5326 - main_output_accuracy: 0.7938 - main_output_loss: 1.3830 - tof_gate_loss: 0.1833 - val_loss: 1.2983 - val_main_output_accuracy: 0.7448 - val_main_output_loss: 1.1811 - val_tof_gate_loss: 0.0212\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.5228 - main_output_accuracy: 0.7772 - main_output_loss: 1.3703 - tof_gate_loss: 0.1996 - val_loss: 1.3535 - val_main_output_accuracy: 0.7282 - val_main_output_loss: 1.2371 - val_tof_gate_loss: 0.0207\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5285 - main_output_accuracy: 0.7718 - main_output_loss: 1.3796 - tof_gate_loss: 0.1831 - val_loss: 1.3101 - val_main_output_accuracy: 0.7424 - val_main_output_loss: 1.1937 - val_tof_gate_loss: 0.0214\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.4289 - main_output_accuracy: 0.8168 - main_output_loss: 1.2857 - tof_gate_loss: 0.1532 - val_loss: 1.3133 - val_main_output_accuracy: 0.7380 - val_main_output_loss: 1.1969 - val_tof_gate_loss: 0.0212\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.5845 - main_output_accuracy: 0.7784 - main_output_loss: 1.4289 - tof_gate_loss: 0.2230 - val_loss: 1.3308 - val_main_output_accuracy: 0.7291 - val_main_output_loss: 1.2147 - val_tof_gate_loss: 0.0247\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5122 - main_output_accuracy: 0.7805 - main_output_loss: 1.3631 - tof_gate_loss: 0.1923 - val_loss: 1.3509 - val_main_output_accuracy: 0.7247 - val_main_output_loss: 1.2357 - val_tof_gate_loss: 0.0222\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5537 - main_output_accuracy: 0.7694 - main_output_loss: 1.4039 - tof_gate_loss: 0.1967 - val_loss: 1.3574 - val_main_output_accuracy: 0.7203 - val_main_output_loss: 1.2428 - val_tof_gate_loss: 0.0231\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.4172 - main_output_accuracy: 0.8049 - main_output_loss: 1.2781 - tof_gate_loss: 0.1520 - val_loss: 1.3093 - val_main_output_accuracy: 0.7404 - val_main_output_loss: 1.1947 - val_tof_gate_loss: 0.0208\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.5439 - main_output_accuracy: 0.7814 - main_output_loss: 1.3924 - tof_gate_loss: 0.2077 - val_loss: 1.3209 - val_main_output_accuracy: 0.7331 - val_main_output_loss: 1.2059 - val_tof_gate_loss: 0.0234\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.3893 - main_output_accuracy: 0.8261 - main_output_loss: 1.2567 - tof_gate_loss: 0.1548 - val_loss: 1.3253 - val_main_output_accuracy: 0.7448 - val_main_output_loss: 1.2120 - val_tof_gate_loss: 0.0219\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.5097 - main_output_accuracy: 0.7923 - main_output_loss: 1.3658 - tof_gate_loss: 0.1908 - val_loss: 1.3339 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2189 - val_tof_gate_loss: 0.0294\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.5589 - main_output_accuracy: 0.7885 - main_output_loss: 1.4077 - tof_gate_loss: 0.2104 - val_loss: 1.3037 - val_main_output_accuracy: 0.7468 - val_main_output_loss: 1.1899 - val_tof_gate_loss: 0.0256\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5449 - main_output_accuracy: 0.7934 - main_output_loss: 1.3930 - tof_gate_loss: 0.2120 - val_loss: 1.3163 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.2030 - val_tof_gate_loss: 0.0247\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4382 - main_output_accuracy: 0.8154 - main_output_loss: 1.2942 - tof_gate_loss: 0.1828 - val_loss: 1.3031 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.1908 - val_tof_gate_loss: 0.0229\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.3397 - main_output_accuracy: 0.8276 - main_output_loss: 1.2036 - tof_gate_loss: 0.1470 - val_loss: 1.3516 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2396 - val_tof_gate_loss: 0.0222\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.5604 - main_output_accuracy: 0.7731 - main_output_loss: 1.4137 - tof_gate_loss: 0.2079 - val_loss: 1.3095 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.1968 - val_tof_gate_loss: 0.0249\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 225ms/step - loss: 1.5506 - main_output_accuracy: 0.8046 - main_output_loss: 1.4048 - tof_gate_loss: 0.2133 - val_loss: 1.3053 - val_main_output_accuracy: 0.7512 - val_main_output_loss: 1.1934 - val_tof_gate_loss: 0.0240\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.4561 - main_output_accuracy: 0.8132 - main_output_loss: 1.3115 - tof_gate_loss: 0.1895 - val_loss: 1.3322 - val_main_output_accuracy: 0.7399 - val_main_output_loss: 1.2204 - val_tof_gate_loss: 0.0243\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.4002 - main_output_accuracy: 0.8288 - main_output_loss: 1.2620 - tof_gate_loss: 0.1670 - val_loss: 1.3308 - val_main_output_accuracy: 0.7404 - val_main_output_loss: 1.2200 - val_tof_gate_loss: 0.0231\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - loss: 1.3787 - main_output_accuracy: 0.8286 - main_output_loss: 1.2420 - tof_gate_loss: 0.1544 - val_loss: 1.2955 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.1861 - val_tof_gate_loss: 0.0181\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.5687 - main_output_accuracy: 0.7902 - main_output_loss: 1.4174 - tof_gate_loss: 0.2237 - val_loss: 1.3073 - val_main_output_accuracy: 0.7468 - val_main_output_loss: 1.1971 - val_tof_gate_loss: 0.0224\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.4389 - main_output_accuracy: 0.8294 - main_output_loss: 1.2960 - tof_gate_loss: 0.1814 - val_loss: 1.3414 - val_main_output_accuracy: 0.7404 - val_main_output_loss: 1.2308 - val_tof_gate_loss: 0.0282\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.4887 - main_output_accuracy: 0.8006 - main_output_loss: 1.3450 - tof_gate_loss: 0.1895 - val_loss: 1.3563 - val_main_output_accuracy: 0.7296 - val_main_output_loss: 1.2459 - val_tof_gate_loss: 0.0269\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.3862 - main_output_accuracy: 0.8402 - main_output_loss: 1.2513 - tof_gate_loss: 0.1639 - val_loss: 1.3225 - val_main_output_accuracy: 0.7493 - val_main_output_loss: 1.2133 - val_tof_gate_loss: 0.0228\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4134 - main_output_accuracy: 0.8202 - main_output_loss: 1.2720 - tof_gate_loss: 0.1773 - val_loss: 1.3264 - val_main_output_accuracy: 0.7399 - val_main_output_loss: 1.2177 - val_tof_gate_loss: 0.0202\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.5296 - main_output_accuracy: 0.8041 - main_output_loss: 1.3820 - tof_gate_loss: 0.2147 - val_loss: 1.2826 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.1733 - val_tof_gate_loss: 0.0263\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.4645 - main_output_accuracy: 0.8240 - main_output_loss: 1.3206 - tof_gate_loss: 0.1933 - val_loss: 1.2849 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1770 - val_tof_gate_loss: 0.0201\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.3461 - main_output_accuracy: 0.8511 - main_output_loss: 1.2095 - tof_gate_loss: 0.1563 - val_loss: 1.3422 - val_main_output_accuracy: 0.7385 - val_main_output_loss: 1.2350 - val_tof_gate_loss: 0.0185\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.5776 - main_output_accuracy: 0.7941 - main_output_loss: 1.4261 - tof_gate_loss: 0.2353 - val_loss: 1.3149 - val_main_output_accuracy: 0.7473 - val_main_output_loss: 1.2073 - val_tof_gate_loss: 0.0221\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.3478 - main_output_accuracy: 0.8643 - main_output_loss: 1.2106 - tof_gate_loss: 0.1696 - val_loss: 1.3179 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.2106 - val_tof_gate_loss: 0.0219\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.3312 - main_output_accuracy: 0.8630 - main_output_loss: 1.1947 - tof_gate_loss: 0.1683 - val_loss: 1.2901 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.1830 - val_tof_gate_loss: 0.0206\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.3884 - main_output_accuracy: 0.8449 - main_output_loss: 1.2532 - tof_gate_loss: 0.1816 - val_loss: 1.3358 - val_main_output_accuracy: 0.7444 - val_main_output_loss: 1.2285 - val_tof_gate_loss: 0.0233\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 1.4355 - main_output_accuracy: 0.8066 - main_output_loss: 1.3155 - tof_gate_loss: 0.1886 - val_loss: 1.3062 - val_main_output_accuracy: 0.7493 - val_main_output_loss: 1.1996 - val_tof_gate_loss: 0.0212\n",
      "Epoch 101/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.4458 - main_output_accuracy: 0.8220 - main_output_loss: 1.3061 - tof_gate_loss: 0.1901 - val_loss: 1.3070 - val_main_output_accuracy: 0.7576 - val_main_output_loss: 1.2009 - val_tof_gate_loss: 0.0190\n",
      "Epoch 102/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.5018 - main_output_accuracy: 0.8170 - main_output_loss: 1.3591 - tof_gate_loss: 0.2057 - val_loss: 1.3092 - val_main_output_accuracy: 0.7527 - val_main_output_loss: 1.2032 - val_tof_gate_loss: 0.0208\n",
      "Epoch 103/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4259 - main_output_accuracy: 0.8307 - main_output_loss: 1.2868 - tof_gate_loss: 0.1844 - val_loss: 1.3192 - val_main_output_accuracy: 0.7512 - val_main_output_loss: 1.2130 - val_tof_gate_loss: 0.0220\n",
      "Epoch 104/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.4030 - main_output_accuracy: 0.8567 - main_output_loss: 1.2779 - tof_gate_loss: 0.1864 - val_loss: 1.3263 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 1.2203 - val_tof_gate_loss: 0.0211\n",
      "Epoch 105/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.4371 - main_output_accuracy: 0.8253 - main_output_loss: 1.3014 - tof_gate_loss: 0.2022 - val_loss: 1.2979 - val_main_output_accuracy: 0.7547 - val_main_output_loss: 1.1925 - val_tof_gate_loss: 0.0205\n",
      "Epoch 106/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.2740 - main_output_accuracy: 0.8601 - main_output_loss: 1.1390 - tof_gate_loss: 0.1566 - val_loss: 1.3343 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 1.2293 - val_tof_gate_loss: 0.0204\n",
      "Epoch 107/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.5072 - main_output_accuracy: 0.7963 - main_output_loss: 1.3651 - tof_gate_loss: 0.2222 - val_loss: 1.3225 - val_main_output_accuracy: 0.7468 - val_main_output_loss: 1.2175 - val_tof_gate_loss: 0.0220\n",
      "Epoch 108/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.4000 - main_output_accuracy: 0.8299 - main_output_loss: 1.2651 - tof_gate_loss: 0.1853 - val_loss: 1.2999 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.1951 - val_tof_gate_loss: 0.0196\n",
      "Epoch 109/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.3798 - main_output_accuracy: 0.8471 - main_output_loss: 1.2420 - tof_gate_loss: 0.1876 - val_loss: 1.3109 - val_main_output_accuracy: 0.7601 - val_main_output_loss: 1.2059 - val_tof_gate_loss: 0.0224\n",
      "Epoch 110/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.2847 - main_output_accuracy: 0.8514 - main_output_loss: 1.1500 - tof_gate_loss: 0.1529 - val_loss: 1.2852 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1803 - val_tof_gate_loss: 0.0222\n",
      "Epoch 111/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.3785 - main_output_accuracy: 0.8543 - main_output_loss: 1.2401 - tof_gate_loss: 0.1826 - val_loss: 1.3027 - val_main_output_accuracy: 0.7581 - val_main_output_loss: 1.1980 - val_tof_gate_loss: 0.0217\n",
      "Epoch 112/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.3132 - main_output_accuracy: 0.8625 - main_output_loss: 1.1853 - tof_gate_loss: 0.1682 - val_loss: 1.2965 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.1919 - val_tof_gate_loss: 0.0214\n",
      "Epoch 113/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.2919 - main_output_accuracy: 0.8676 - main_output_loss: 1.1591 - tof_gate_loss: 0.1649 - val_loss: 1.3084 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.2039 - val_tof_gate_loss: 0.0229\n",
      "--- Evaluating Fold 2 ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step\n",
      "Fold 2 Accuracy: 0.7507\n",
      "\n",
      "=== Fold 3 ===\n",
      "Loading data for fold 3...\n",
      "Fold data loaded.\n",
      "Fully padded dataset shape: (6113, 128, 38)\n",
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 208ms/step - loss: 3.7130 - main_output_accuracy: 0.1036 - main_output_loss: 3.2299 - tof_gate_loss: 0.5138 - val_loss: 3.0919 - val_main_output_accuracy: 0.2635 - val_main_output_loss: 2.6377 - val_tof_gate_loss: 0.4152\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 3.1098 - main_output_accuracy: 0.2115 - main_output_loss: 2.6819 - tof_gate_loss: 0.3024 - val_loss: 2.6079 - val_main_output_accuracy: 0.3562 - val_main_output_loss: 2.2030 - val_tof_gate_loss: 0.2540\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 2.8945 - main_output_accuracy: 0.2487 - main_output_loss: 2.4975 - tof_gate_loss: 0.2395 - val_loss: 2.3055 - val_main_output_accuracy: 0.4323 - val_main_output_loss: 1.9464 - val_tof_gate_loss: 0.1153\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 2.7843 - main_output_accuracy: 0.2858 - main_output_loss: 2.4004 - tof_gate_loss: 0.2584 - val_loss: 2.1584 - val_main_output_accuracy: 0.4647 - val_main_output_loss: 1.8212 - val_tof_gate_loss: 0.0985\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 2.6429 - main_output_accuracy: 0.3398 - main_output_loss: 2.2779 - tof_gate_loss: 0.2561 - val_loss: 2.0815 - val_main_output_accuracy: 0.4966 - val_main_output_loss: 1.7598 - val_tof_gate_loss: 0.1085\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 2.6151 - main_output_accuracy: 0.3548 - main_output_loss: 2.2648 - tof_gate_loss: 0.2678 - val_loss: 1.9524 - val_main_output_accuracy: 0.5378 - val_main_output_loss: 1.6509 - val_tof_gate_loss: 0.0866\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.5110 - main_output_accuracy: 0.3979 - main_output_loss: 2.1761 - tof_gate_loss: 0.2588 - val_loss: 1.8996 - val_main_output_accuracy: 0.5456 - val_main_output_loss: 1.6175 - val_tof_gate_loss: 0.0583\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 2.4599 - main_output_accuracy: 0.4274 - main_output_loss: 2.1386 - tof_gate_loss: 0.2670 - val_loss: 1.7945 - val_main_output_accuracy: 0.5849 - val_main_output_loss: 1.5281 - val_tof_gate_loss: 0.0430\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 2.3279 - main_output_accuracy: 0.4469 - main_output_loss: 2.0295 - tof_gate_loss: 0.2212 - val_loss: 1.8029 - val_main_output_accuracy: 0.5834 - val_main_output_loss: 1.5469 - val_tof_gate_loss: 0.0519\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 2.3170 - main_output_accuracy: 0.4599 - main_output_loss: 2.0260 - tof_gate_loss: 0.2375 - val_loss: 1.7401 - val_main_output_accuracy: 0.5859 - val_main_output_loss: 1.4929 - val_tof_gate_loss: 0.0609\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 2.3263 - main_output_accuracy: 0.4555 - main_output_loss: 2.0373 - tof_gate_loss: 0.2794 - val_loss: 1.7130 - val_main_output_accuracy: 0.6001 - val_main_output_loss: 1.4726 - val_tof_gate_loss: 0.0736\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 2.1981 - main_output_accuracy: 0.4995 - main_output_loss: 1.9267 - tof_gate_loss: 0.2262 - val_loss: 1.6976 - val_main_output_accuracy: 0.6055 - val_main_output_loss: 1.4684 - val_tof_gate_loss: 0.0603\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 2.1758 - main_output_accuracy: 0.4962 - main_output_loss: 1.9134 - tof_gate_loss: 0.2296 - val_loss: 1.7112 - val_main_output_accuracy: 0.5839 - val_main_output_loss: 1.4920 - val_tof_gate_loss: 0.0498\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - loss: 2.1275 - main_output_accuracy: 0.5161 - main_output_loss: 1.8739 - tof_gate_loss: 0.2128 - val_loss: 1.6329 - val_main_output_accuracy: 0.6104 - val_main_output_loss: 1.4196 - val_tof_gate_loss: 0.0547\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 2.0077 - main_output_accuracy: 0.5530 - main_output_loss: 1.7680 - tof_gate_loss: 0.1852 - val_loss: 1.5707 - val_main_output_accuracy: 0.6443 - val_main_output_loss: 1.3650 - val_tof_gate_loss: 0.0489\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 2.1008 - main_output_accuracy: 0.5328 - main_output_loss: 1.8606 - tof_gate_loss: 0.2265 - val_loss: 1.6014 - val_main_output_accuracy: 0.6295 - val_main_output_loss: 1.4042 - val_tof_gate_loss: 0.0370\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 2.0466 - main_output_accuracy: 0.5673 - main_output_loss: 1.8157 - tof_gate_loss: 0.2081 - val_loss: 1.5247 - val_main_output_accuracy: 0.6663 - val_main_output_loss: 1.3322 - val_tof_gate_loss: 0.0381\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.0347 - main_output_accuracy: 0.5644 - main_output_loss: 1.8093 - tof_gate_loss: 0.2077 - val_loss: 1.5211 - val_main_output_accuracy: 0.6649 - val_main_output_loss: 1.3336 - val_tof_gate_loss: 0.0379\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 1.9683 - main_output_accuracy: 0.5876 - main_output_loss: 1.7500 - tof_gate_loss: 0.1966 - val_loss: 1.5159 - val_main_output_accuracy: 0.6668 - val_main_output_loss: 1.3309 - val_tof_gate_loss: 0.0472\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.9868 - main_output_accuracy: 0.5926 - main_output_loss: 1.7669 - tof_gate_loss: 0.2257 - val_loss: 1.4644 - val_main_output_accuracy: 0.6752 - val_main_output_loss: 1.2853 - val_tof_gate_loss: 0.0368\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.9269 - main_output_accuracy: 0.5878 - main_output_loss: 1.7169 - tof_gate_loss: 0.1951 - val_loss: 1.4791 - val_main_output_accuracy: 0.6737 - val_main_output_loss: 1.3034 - val_tof_gate_loss: 0.0393\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.8578 - main_output_accuracy: 0.6196 - main_output_loss: 1.6528 - tof_gate_loss: 0.1832 - val_loss: 1.5091 - val_main_output_accuracy: 0.6683 - val_main_output_loss: 1.3371 - val_tof_gate_loss: 0.0370\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.8897 - main_output_accuracy: 0.6221 - main_output_loss: 1.6859 - tof_gate_loss: 0.1964 - val_loss: 1.4986 - val_main_output_accuracy: 0.6492 - val_main_output_loss: 1.3280 - val_tof_gate_loss: 0.0464\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 173ms/step - loss: 1.9892 - main_output_accuracy: 0.5987 - main_output_loss: 1.7812 - tof_gate_loss: 0.2349 - val_loss: 1.4606 - val_main_output_accuracy: 0.6712 - val_main_output_loss: 1.2925 - val_tof_gate_loss: 0.0472\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.8775 - main_output_accuracy: 0.6304 - main_output_loss: 1.6755 - tof_gate_loss: 0.2014 - val_loss: 1.4233 - val_main_output_accuracy: 0.6869 - val_main_output_loss: 1.2617 - val_tof_gate_loss: 0.0267\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.9271 - main_output_accuracy: 0.6240 - main_output_loss: 1.7249 - tof_gate_loss: 0.2276 - val_loss: 1.3795 - val_main_output_accuracy: 0.7144 - val_main_output_loss: 1.2199 - val_tof_gate_loss: 0.0318\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.8294 - main_output_accuracy: 0.6374 - main_output_loss: 1.6374 - tof_gate_loss: 0.1895 - val_loss: 1.4005 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.2429 - val_tof_gate_loss: 0.0320\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.7556 - main_output_accuracy: 0.6490 - main_output_loss: 1.5707 - tof_gate_loss: 0.1676 - val_loss: 1.3648 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 1.2098 - val_tof_gate_loss: 0.0297\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.8673 - main_output_accuracy: 0.6316 - main_output_loss: 1.6775 - tof_gate_loss: 0.1989 - val_loss: 1.4694 - val_main_output_accuracy: 0.6747 - val_main_output_loss: 1.3143 - val_tof_gate_loss: 0.0407\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.9703 - main_output_accuracy: 0.6117 - main_output_loss: 1.7734 - tof_gate_loss: 0.2486 - val_loss: 1.3771 - val_main_output_accuracy: 0.7002 - val_main_output_loss: 1.2245 - val_tof_gate_loss: 0.0362\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.7619 - main_output_accuracy: 0.6600 - main_output_loss: 1.5795 - tof_gate_loss: 0.1796 - val_loss: 1.4144 - val_main_output_accuracy: 0.6963 - val_main_output_loss: 1.2639 - val_tof_gate_loss: 0.0365\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.8101 - main_output_accuracy: 0.6490 - main_output_loss: 1.6313 - tof_gate_loss: 0.1931 - val_loss: 1.3616 - val_main_output_accuracy: 0.7144 - val_main_output_loss: 1.2134 - val_tof_gate_loss: 0.0337\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.8095 - main_output_accuracy: 0.6547 - main_output_loss: 1.6262 - tof_gate_loss: 0.2035 - val_loss: 1.3701 - val_main_output_accuracy: 0.7110 - val_main_output_loss: 1.2236 - val_tof_gate_loss: 0.0326\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.7648 - main_output_accuracy: 0.6744 - main_output_loss: 1.5865 - tof_gate_loss: 0.1884 - val_loss: 1.3892 - val_main_output_accuracy: 0.6963 - val_main_output_loss: 1.2430 - val_tof_gate_loss: 0.0398\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.8094 - main_output_accuracy: 0.6600 - main_output_loss: 1.6259 - tof_gate_loss: 0.2203 - val_loss: 1.3800 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 1.2358 - val_tof_gate_loss: 0.0343\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 1.8401 - main_output_accuracy: 0.6476 - main_output_loss: 1.6534 - tof_gate_loss: 0.2207 - val_loss: 1.3435 - val_main_output_accuracy: 0.7184 - val_main_output_loss: 1.2021 - val_tof_gate_loss: 0.0277\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.7440 - main_output_accuracy: 0.6738 - main_output_loss: 1.5735 - tof_gate_loss: 0.1715 - val_loss: 1.3343 - val_main_output_accuracy: 0.7228 - val_main_output_loss: 1.1913 - val_tof_gate_loss: 0.0402\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.6890 - main_output_accuracy: 0.6966 - main_output_loss: 1.5180 - tof_gate_loss: 0.1840 - val_loss: 1.3342 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.1927 - val_tof_gate_loss: 0.0371\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.7908 - main_output_accuracy: 0.6829 - main_output_loss: 1.6125 - tof_gate_loss: 0.2319 - val_loss: 1.3230 - val_main_output_accuracy: 0.7404 - val_main_output_loss: 1.1838 - val_tof_gate_loss: 0.0336\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.7031 - main_output_accuracy: 0.6894 - main_output_loss: 1.5314 - tof_gate_loss: 0.1869 - val_loss: 1.2911 - val_main_output_accuracy: 0.7488 - val_main_output_loss: 1.1541 - val_tof_gate_loss: 0.0296\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.6999 - main_output_accuracy: 0.6971 - main_output_loss: 1.5284 - tof_gate_loss: 0.1982 - val_loss: 1.3096 - val_main_output_accuracy: 0.7360 - val_main_output_loss: 1.1715 - val_tof_gate_loss: 0.0365\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.8044 - main_output_accuracy: 0.6862 - main_output_loss: 1.6282 - tof_gate_loss: 0.2266 - val_loss: 1.3297 - val_main_output_accuracy: 0.7282 - val_main_output_loss: 1.1939 - val_tof_gate_loss: 0.0291\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.6119 - main_output_accuracy: 0.7130 - main_output_loss: 1.4495 - tof_gate_loss: 0.1662 - val_loss: 1.3477 - val_main_output_accuracy: 0.7125 - val_main_output_loss: 1.2114 - val_tof_gate_loss: 0.0360\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.7141 - main_output_accuracy: 0.7054 - main_output_loss: 1.5460 - tof_gate_loss: 0.2028 - val_loss: 1.3153 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.1822 - val_tof_gate_loss: 0.0287\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.6746 - main_output_accuracy: 0.7135 - main_output_loss: 1.5078 - tof_gate_loss: 0.1943 - val_loss: 1.2979 - val_main_output_accuracy: 0.7370 - val_main_output_loss: 1.1644 - val_tof_gate_loss: 0.0335\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.7395 - main_output_accuracy: 0.6798 - main_output_loss: 1.5685 - tof_gate_loss: 0.2193 - val_loss: 1.3027 - val_main_output_accuracy: 0.7321 - val_main_output_loss: 1.1705 - val_tof_gate_loss: 0.0311\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.6642 - main_output_accuracy: 0.7338 - main_output_loss: 1.4970 - tof_gate_loss: 0.2004 - val_loss: 1.2891 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.1590 - val_tof_gate_loss: 0.0252\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6716 - main_output_accuracy: 0.7119 - main_output_loss: 1.5072 - tof_gate_loss: 0.1931 - val_loss: 1.2831 - val_main_output_accuracy: 0.7498 - val_main_output_loss: 1.1531 - val_tof_gate_loss: 0.0266\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.7077 - main_output_accuracy: 0.7070 - main_output_loss: 1.5407 - tof_gate_loss: 0.2167 - val_loss: 1.3031 - val_main_output_accuracy: 0.7399 - val_main_output_loss: 1.1727 - val_tof_gate_loss: 0.0326\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.5826 - main_output_accuracy: 0.7357 - main_output_loss: 1.4236 - tof_gate_loss: 0.1760 - val_loss: 1.3249 - val_main_output_accuracy: 0.7179 - val_main_output_loss: 1.1966 - val_tof_gate_loss: 0.0260\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.7600 - main_output_accuracy: 0.7069 - main_output_loss: 1.5955 - tof_gate_loss: 0.2332 - val_loss: 1.2921 - val_main_output_accuracy: 0.7453 - val_main_output_loss: 1.1654 - val_tof_gate_loss: 0.0248\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - loss: 1.7423 - main_output_accuracy: 0.7161 - main_output_loss: 1.5758 - tof_gate_loss: 0.2241 - val_loss: 1.2903 - val_main_output_accuracy: 0.7380 - val_main_output_loss: 1.1625 - val_tof_gate_loss: 0.0338\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.6379 - main_output_accuracy: 0.7332 - main_output_loss: 1.4799 - tof_gate_loss: 0.1942 - val_loss: 1.3319 - val_main_output_accuracy: 0.7233 - val_main_output_loss: 1.2048 - val_tof_gate_loss: 0.0330\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5329 - main_output_accuracy: 0.7419 - main_output_loss: 1.3791 - tof_gate_loss: 0.1613 - val_loss: 1.3103 - val_main_output_accuracy: 0.7296 - val_main_output_loss: 1.1833 - val_tof_gate_loss: 0.0360\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.5487 - main_output_accuracy: 0.7478 - main_output_loss: 1.3938 - tof_gate_loss: 0.1736 - val_loss: 1.2918 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.1666 - val_tof_gate_loss: 0.0293\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.6228 - main_output_accuracy: 0.7340 - main_output_loss: 1.4650 - tof_gate_loss: 0.2001 - val_loss: 1.2963 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.1724 - val_tof_gate_loss: 0.0265\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - loss: 1.6186 - main_output_accuracy: 0.7323 - main_output_loss: 1.4622 - tof_gate_loss: 0.1888 - val_loss: 1.2782 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.1555 - val_tof_gate_loss: 0.0235\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.6824 - main_output_accuracy: 0.7168 - main_output_loss: 1.5258 - tof_gate_loss: 0.2116 - val_loss: 1.2717 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.1481 - val_tof_gate_loss: 0.0311\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.7626 - main_output_accuracy: 0.7189 - main_output_loss: 1.5958 - tof_gate_loss: 0.2454 - val_loss: 1.2804 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.1568 - val_tof_gate_loss: 0.0328\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.6967 - main_output_accuracy: 0.7273 - main_output_loss: 1.5366 - tof_gate_loss: 0.2281 - val_loss: 1.2697 - val_main_output_accuracy: 0.7488 - val_main_output_loss: 1.1476 - val_tof_gate_loss: 0.0289\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.6399 - main_output_accuracy: 0.7525 - main_output_loss: 1.4764 - tof_gate_loss: 0.2220 - val_loss: 1.3123 - val_main_output_accuracy: 0.7345 - val_main_output_loss: 1.1914 - val_tof_gate_loss: 0.0266\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.5678 - main_output_accuracy: 0.7671 - main_output_loss: 1.4146 - tof_gate_loss: 0.1827 - val_loss: 1.2547 - val_main_output_accuracy: 0.7507 - val_main_output_loss: 1.1330 - val_tof_gate_loss: 0.0318\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.5473 - main_output_accuracy: 0.7619 - main_output_loss: 1.4029 - tof_gate_loss: 0.1896 - val_loss: 1.2528 - val_main_output_accuracy: 0.7542 - val_main_output_loss: 1.1322 - val_tof_gate_loss: 0.0292\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5291 - main_output_accuracy: 0.7749 - main_output_loss: 1.3826 - tof_gate_loss: 0.1787 - val_loss: 1.2270 - val_main_output_accuracy: 0.7743 - val_main_output_loss: 1.1054 - val_tof_gate_loss: 0.0344\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5924 - main_output_accuracy: 0.7584 - main_output_loss: 1.4377 - tof_gate_loss: 0.1972 - val_loss: 1.2305 - val_main_output_accuracy: 0.7650 - val_main_output_loss: 1.1108 - val_tof_gate_loss: 0.0300\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.5155 - main_output_accuracy: 0.7669 - main_output_loss: 1.3655 - tof_gate_loss: 0.1799 - val_loss: 1.2433 - val_main_output_accuracy: 0.7645 - val_main_output_loss: 1.1257 - val_tof_gate_loss: 0.0248\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.5412 - main_output_accuracy: 0.7728 - main_output_loss: 1.3919 - tof_gate_loss: 0.1783 - val_loss: 1.2701 - val_main_output_accuracy: 0.7458 - val_main_output_loss: 1.1524 - val_tof_gate_loss: 0.0243\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5375 - main_output_accuracy: 0.7656 - main_output_loss: 1.3888 - tof_gate_loss: 0.1850 - val_loss: 1.2539 - val_main_output_accuracy: 0.7576 - val_main_output_loss: 1.1368 - val_tof_gate_loss: 0.0237\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.5578 - main_output_accuracy: 0.7708 - main_output_loss: 1.4053 - tof_gate_loss: 0.1917 - val_loss: 1.2355 - val_main_output_accuracy: 0.7709 - val_main_output_loss: 1.1178 - val_tof_gate_loss: 0.0277\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4185 - main_output_accuracy: 0.7942 - main_output_loss: 1.2765 - tof_gate_loss: 0.1464 - val_loss: 1.2251 - val_main_output_accuracy: 0.7669 - val_main_output_loss: 1.1072 - val_tof_gate_loss: 0.0335\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.5999 - main_output_accuracy: 0.7723 - main_output_loss: 1.4407 - tof_gate_loss: 0.2150 - val_loss: 1.2198 - val_main_output_accuracy: 0.7679 - val_main_output_loss: 1.1021 - val_tof_gate_loss: 0.0329\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4969 - main_output_accuracy: 0.7862 - main_output_loss: 1.3482 - tof_gate_loss: 0.1731 - val_loss: 1.2260 - val_main_output_accuracy: 0.7718 - val_main_output_loss: 1.1083 - val_tof_gate_loss: 0.0343\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.5143 - main_output_accuracy: 0.8060 - main_output_loss: 1.3662 - tof_gate_loss: 0.2023 - val_loss: 1.2377 - val_main_output_accuracy: 0.7620 - val_main_output_loss: 1.1208 - val_tof_gate_loss: 0.0342\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.5875 - main_output_accuracy: 0.7640 - main_output_loss: 1.4329 - tof_gate_loss: 0.2084 - val_loss: 1.2518 - val_main_output_accuracy: 0.7630 - val_main_output_loss: 1.1353 - val_tof_gate_loss: 0.0324\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.3679 - main_output_accuracy: 0.8240 - main_output_loss: 1.2283 - tof_gate_loss: 0.1459 - val_loss: 1.2841 - val_main_output_accuracy: 0.7571 - val_main_output_loss: 1.1688 - val_tof_gate_loss: 0.0302\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.6288 - main_output_accuracy: 0.7617 - main_output_loss: 1.4706 - tof_gate_loss: 0.2255 - val_loss: 1.2366 - val_main_output_accuracy: 0.7689 - val_main_output_loss: 1.1226 - val_tof_gate_loss: 0.0262\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4228 - main_output_accuracy: 0.8155 - main_output_loss: 1.2792 - tof_gate_loss: 0.1675 - val_loss: 1.2462 - val_main_output_accuracy: 0.7542 - val_main_output_loss: 1.1327 - val_tof_gate_loss: 0.0242\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 1.5266 - main_output_accuracy: 0.7899 - main_output_loss: 1.3776 - tof_gate_loss: 0.1987 - val_loss: 1.2198 - val_main_output_accuracy: 0.7743 - val_main_output_loss: 1.1064 - val_tof_gate_loss: 0.0267\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.6765 - main_output_accuracy: 0.7507 - main_output_loss: 1.5246 - tof_gate_loss: 0.2622 - val_loss: 1.2467 - val_main_output_accuracy: 0.7542 - val_main_output_loss: 1.1346 - val_tof_gate_loss: 0.0223\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 1.5847 - main_output_accuracy: 0.7944 - main_output_loss: 1.4303 - tof_gate_loss: 0.2224 - val_loss: 1.2516 - val_main_output_accuracy: 0.7674 - val_main_output_loss: 1.1377 - val_tof_gate_loss: 0.0319\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.5684 - main_output_accuracy: 0.7778 - main_output_loss: 1.4183 - tof_gate_loss: 0.2085 - val_loss: 1.2584 - val_main_output_accuracy: 0.7615 - val_main_output_loss: 1.1458 - val_tof_gate_loss: 0.0291\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.4318 - main_output_accuracy: 0.8122 - main_output_loss: 1.2914 - tof_gate_loss: 0.1709 - val_loss: 1.2507 - val_main_output_accuracy: 0.7596 - val_main_output_loss: 1.1379 - val_tof_gate_loss: 0.0300\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.5564 - main_output_accuracy: 0.7831 - main_output_loss: 1.4074 - tof_gate_loss: 0.2303 - val_loss: 1.2437 - val_main_output_accuracy: 0.7669 - val_main_output_loss: 1.1316 - val_tof_gate_loss: 0.0293\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.4284 - main_output_accuracy: 0.7983 - main_output_loss: 1.2883 - tof_gate_loss: 0.1650 - val_loss: 1.2305 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1195 - val_tof_gate_loss: 0.0260\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.3813 - main_output_accuracy: 0.8281 - main_output_loss: 1.2491 - tof_gate_loss: 0.1642 - val_loss: 1.2274 - val_main_output_accuracy: 0.7763 - val_main_output_loss: 1.1163 - val_tof_gate_loss: 0.0270\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.4962 - main_output_accuracy: 0.8052 - main_output_loss: 1.3507 - tof_gate_loss: 0.1960 - val_loss: 1.2213 - val_main_output_accuracy: 0.7767 - val_main_output_loss: 1.1101 - val_tof_gate_loss: 0.0305\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.5291 - main_output_accuracy: 0.7789 - main_output_loss: 1.3823 - tof_gate_loss: 0.1996 - val_loss: 1.2232 - val_main_output_accuracy: 0.7748 - val_main_output_loss: 1.1129 - val_tof_gate_loss: 0.0263\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.4788 - main_output_accuracy: 0.8027 - main_output_loss: 1.3351 - tof_gate_loss: 0.1902 - val_loss: 1.2353 - val_main_output_accuracy: 0.7748 - val_main_output_loss: 1.1249 - val_tof_gate_loss: 0.0278\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.3725 - main_output_accuracy: 0.8339 - main_output_loss: 1.2358 - tof_gate_loss: 0.1662 - val_loss: 1.2291 - val_main_output_accuracy: 0.7728 - val_main_output_loss: 1.1197 - val_tof_gate_loss: 0.0253\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.6193 - main_output_accuracy: 0.7933 - main_output_loss: 1.4644 - tof_gate_loss: 0.2501 - val_loss: 1.2339 - val_main_output_accuracy: 0.7723 - val_main_output_loss: 1.1243 - val_tof_gate_loss: 0.0270\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.4017 - main_output_accuracy: 0.8137 - main_output_loss: 1.2739 - tof_gate_loss: 0.1735 - val_loss: 1.2329 - val_main_output_accuracy: 0.7816 - val_main_output_loss: 1.1246 - val_tof_gate_loss: 0.0227\n",
      "--- Evaluating Fold 3 ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step\n",
      "Fold 3 Accuracy: 0.7679\n",
      "\n",
      "=== Fold 4 ===\n",
      "Loading data for fold 4...\n",
      "Fold data loaded.\n",
      "Fully padded dataset shape: (6114, 128, 38)\n",
      "LR Scheduler: 96 steps per epoch, 14400 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 244ms/step - loss: 3.7919 - main_output_accuracy: 0.1007 - main_output_loss: 3.2945 - tof_gate_loss: 0.5848 - val_loss: 3.1239 - val_main_output_accuracy: 0.2067 - val_main_output_loss: 2.6571 - val_tof_gate_loss: 0.4886\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 186ms/step - loss: 3.1846 - main_output_accuracy: 0.2050 - main_output_loss: 2.7599 - tof_gate_loss: 0.3003 - val_loss: 2.6684 - val_main_output_accuracy: 0.3294 - val_main_output_loss: 2.2759 - val_tof_gate_loss: 0.2137\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 2.8814 - main_output_accuracy: 0.2721 - main_output_loss: 2.4871 - tof_gate_loss: 0.2531 - val_loss: 2.2877 - val_main_output_accuracy: 0.4546 - val_main_output_loss: 1.9272 - val_tof_gate_loss: 0.1528\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 177ms/step - loss: 2.7392 - main_output_accuracy: 0.3168 - main_output_loss: 2.3651 - tof_gate_loss: 0.2575 - val_loss: 2.1523 - val_main_output_accuracy: 0.4624 - val_main_output_loss: 1.8233 - val_tof_gate_loss: 0.0910\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 2.6205 - main_output_accuracy: 0.3375 - main_output_loss: 2.2681 - tof_gate_loss: 0.2358 - val_loss: 2.0146 - val_main_output_accuracy: 0.5272 - val_main_output_loss: 1.7058 - val_tof_gate_loss: 0.0756\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 2.4945 - main_output_accuracy: 0.3774 - main_output_loss: 2.1628 - tof_gate_loss: 0.2139 - val_loss: 1.9609 - val_main_output_accuracy: 0.5425 - val_main_output_loss: 1.6666 - val_tof_gate_loss: 0.0809\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 2.4032 - main_output_accuracy: 0.4128 - main_output_loss: 2.0855 - tof_gate_loss: 0.2325 - val_loss: 1.8593 - val_main_output_accuracy: 0.5695 - val_main_output_loss: 1.5784 - val_tof_gate_loss: 0.0770\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 2.3412 - main_output_accuracy: 0.4501 - main_output_loss: 2.0349 - tof_gate_loss: 0.2370 - val_loss: 1.8628 - val_main_output_accuracy: 0.5538 - val_main_output_loss: 1.5970 - val_tof_gate_loss: 0.0639\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 2.2517 - main_output_accuracy: 0.4576 - main_output_loss: 1.9592 - tof_gate_loss: 0.2183 - val_loss: 1.7793 - val_main_output_accuracy: 0.5778 - val_main_output_loss: 1.5268 - val_tof_gate_loss: 0.0530\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 2.2099 - main_output_accuracy: 0.4782 - main_output_loss: 1.9308 - tof_gate_loss: 0.2031 - val_loss: 1.6921 - val_main_output_accuracy: 0.6136 - val_main_output_loss: 1.4519 - val_tof_gate_loss: 0.0379\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.3003 - main_output_accuracy: 0.4752 - main_output_loss: 2.0210 - tof_gate_loss: 0.2526 - val_loss: 1.7162 - val_main_output_accuracy: 0.6028 - val_main_output_loss: 1.4781 - val_tof_gate_loss: 0.0736\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 2.0507 - main_output_accuracy: 0.5339 - main_output_loss: 1.7963 - tof_gate_loss: 0.1756 - val_loss: 1.6703 - val_main_output_accuracy: 0.6146 - val_main_output_loss: 1.4460 - val_tof_gate_loss: 0.0432\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.1844 - main_output_accuracy: 0.5029 - main_output_loss: 1.9246 - tof_gate_loss: 0.2378 - val_loss: 1.6220 - val_main_output_accuracy: 0.6348 - val_main_output_loss: 1.4027 - val_tof_gate_loss: 0.0541\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 2.0871 - main_output_accuracy: 0.5337 - main_output_loss: 1.8391 - tof_gate_loss: 0.2133 - val_loss: 1.7276 - val_main_output_accuracy: 0.5891 - val_main_output_loss: 1.5150 - val_tof_gate_loss: 0.0562\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.0545 - main_output_accuracy: 0.5417 - main_output_loss: 1.8120 - tof_gate_loss: 0.2116 - val_loss: 1.5903 - val_main_output_accuracy: 0.6343 - val_main_output_loss: 1.3818 - val_tof_gate_loss: 0.0667\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.0082 - main_output_accuracy: 0.5735 - main_output_loss: 1.7753 - tof_gate_loss: 0.2012 - val_loss: 1.6536 - val_main_output_accuracy: 0.6097 - val_main_output_loss: 1.4499 - val_tof_gate_loss: 0.0680\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 2.1082 - main_output_accuracy: 0.5648 - main_output_loss: 1.8710 - tof_gate_loss: 0.2426 - val_loss: 1.5563 - val_main_output_accuracy: 0.6559 - val_main_output_loss: 1.3636 - val_tof_gate_loss: 0.0393\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.9746 - main_output_accuracy: 0.5868 - main_output_loss: 1.7508 - tof_gate_loss: 0.2024 - val_loss: 1.5590 - val_main_output_accuracy: 0.6500 - val_main_output_loss: 1.3689 - val_tof_gate_loss: 0.0478\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.9587 - main_output_accuracy: 0.6002 - main_output_loss: 1.7375 - tof_gate_loss: 0.2108 - val_loss: 1.5380 - val_main_output_accuracy: 0.6608 - val_main_output_loss: 1.3508 - val_tof_gate_loss: 0.0565\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.9359 - main_output_accuracy: 0.5894 - main_output_loss: 1.7242 - tof_gate_loss: 0.2098 - val_loss: 1.4995 - val_main_output_accuracy: 0.6691 - val_main_output_loss: 1.3191 - val_tof_gate_loss: 0.0382\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.8875 - main_output_accuracy: 0.6171 - main_output_loss: 1.6767 - tof_gate_loss: 0.1932 - val_loss: 1.5417 - val_main_output_accuracy: 0.6598 - val_main_output_loss: 1.3633 - val_tof_gate_loss: 0.0448\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.9781 - main_output_accuracy: 0.5972 - main_output_loss: 1.7651 - tof_gate_loss: 0.2272 - val_loss: 1.4677 - val_main_output_accuracy: 0.6819 - val_main_output_loss: 1.2930 - val_tof_gate_loss: 0.0446\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.8518 - main_output_accuracy: 0.6195 - main_output_loss: 1.6525 - tof_gate_loss: 0.1904 - val_loss: 1.4596 - val_main_output_accuracy: 0.6868 - val_main_output_loss: 1.2889 - val_tof_gate_loss: 0.0374\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - loss: 1.9227 - main_output_accuracy: 0.6134 - main_output_loss: 1.7147 - tof_gate_loss: 0.2249 - val_loss: 1.5094 - val_main_output_accuracy: 0.6696 - val_main_output_loss: 1.3411 - val_tof_gate_loss: 0.0395\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.7765 - main_output_accuracy: 0.6574 - main_output_loss: 1.5866 - tof_gate_loss: 0.1654 - val_loss: 1.5172 - val_main_output_accuracy: 0.6529 - val_main_output_loss: 1.3496 - val_tof_gate_loss: 0.0483\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 1.8783 - main_output_accuracy: 0.6364 - main_output_loss: 1.6785 - tof_gate_loss: 0.2082 - val_loss: 1.4460 - val_main_output_accuracy: 0.6971 - val_main_output_loss: 1.2840 - val_tof_gate_loss: 0.0312\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - loss: 1.7976 - main_output_accuracy: 0.6408 - main_output_loss: 1.6065 - tof_gate_loss: 0.1784 - val_loss: 1.4342 - val_main_output_accuracy: 0.6868 - val_main_output_loss: 1.2747 - val_tof_gate_loss: 0.0290\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.8410 - main_output_accuracy: 0.6460 - main_output_loss: 1.6483 - tof_gate_loss: 0.2018 - val_loss: 1.4513 - val_main_output_accuracy: 0.6824 - val_main_output_loss: 1.2919 - val_tof_gate_loss: 0.0387\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 1.9063 - main_output_accuracy: 0.6476 - main_output_loss: 1.7071 - tof_gate_loss: 0.2339 - val_loss: 1.4109 - val_main_output_accuracy: 0.7074 - val_main_output_loss: 1.2515 - val_tof_gate_loss: 0.0465\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 213ms/step - loss: 1.8446 - main_output_accuracy: 0.6382 - main_output_loss: 1.6522 - tof_gate_loss: 0.2134 - val_loss: 1.4327 - val_main_output_accuracy: 0.7015 - val_main_output_loss: 1.2764 - val_tof_gate_loss: 0.0410\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.8313 - main_output_accuracy: 0.6659 - main_output_loss: 1.6424 - tof_gate_loss: 0.2006 - val_loss: 1.3807 - val_main_output_accuracy: 0.7162 - val_main_output_loss: 1.2281 - val_tof_gate_loss: 0.0313\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.7833 - main_output_accuracy: 0.6597 - main_output_loss: 1.6001 - tof_gate_loss: 0.1844 - val_loss: 1.3815 - val_main_output_accuracy: 0.7158 - val_main_output_loss: 1.2299 - val_tof_gate_loss: 0.0338\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 1.8587 - main_output_accuracy: 0.6462 - main_output_loss: 1.6679 - tof_gate_loss: 0.2325 - val_loss: 1.4101 - val_main_output_accuracy: 0.7084 - val_main_output_loss: 1.2607 - val_tof_gate_loss: 0.0275\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.8079 - main_output_accuracy: 0.6810 - main_output_loss: 1.6230 - tof_gate_loss: 0.2101 - val_loss: 1.4096 - val_main_output_accuracy: 0.7045 - val_main_output_loss: 1.2600 - val_tof_gate_loss: 0.0358\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.8498 - main_output_accuracy: 0.6643 - main_output_loss: 1.6609 - tof_gate_loss: 0.2341 - val_loss: 1.4249 - val_main_output_accuracy: 0.6897 - val_main_output_loss: 1.2761 - val_tof_gate_loss: 0.0396\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.7366 - main_output_accuracy: 0.6771 - main_output_loss: 1.5561 - tof_gate_loss: 0.1993 - val_loss: 1.3722 - val_main_output_accuracy: 0.7207 - val_main_output_loss: 1.2256 - val_tof_gate_loss: 0.0356\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.7265 - main_output_accuracy: 0.6874 - main_output_loss: 1.5473 - tof_gate_loss: 0.1927 - val_loss: 1.3495 - val_main_output_accuracy: 0.7339 - val_main_output_loss: 1.2049 - val_tof_gate_loss: 0.0315\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.7213 - main_output_accuracy: 0.6804 - main_output_loss: 1.5452 - tof_gate_loss: 0.1912 - val_loss: 1.3484 - val_main_output_accuracy: 0.7315 - val_main_output_loss: 1.2057 - val_tof_gate_loss: 0.0279\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.6655 - main_output_accuracy: 0.7005 - main_output_loss: 1.4875 - tof_gate_loss: 0.1748 - val_loss: 1.4050 - val_main_output_accuracy: 0.7000 - val_main_output_loss: 1.2644 - val_tof_gate_loss: 0.0235\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.7698 - main_output_accuracy: 0.6842 - main_output_loss: 1.5938 - tof_gate_loss: 0.2213 - val_loss: 1.3751 - val_main_output_accuracy: 0.7079 - val_main_output_loss: 1.2328 - val_tof_gate_loss: 0.0377\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.6424 - main_output_accuracy: 0.7161 - main_output_loss: 1.4730 - tof_gate_loss: 0.1753 - val_loss: 1.3604 - val_main_output_accuracy: 0.7182 - val_main_output_loss: 1.2208 - val_tof_gate_loss: 0.0269\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.6200 - main_output_accuracy: 0.7209 - main_output_loss: 1.4504 - tof_gate_loss: 0.1720 - val_loss: 1.3775 - val_main_output_accuracy: 0.7069 - val_main_output_loss: 1.2380 - val_tof_gate_loss: 0.0342\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.7617 - main_output_accuracy: 0.6927 - main_output_loss: 1.5862 - tof_gate_loss: 0.2247 - val_loss: 1.3429 - val_main_output_accuracy: 0.7246 - val_main_output_loss: 1.2045 - val_tof_gate_loss: 0.0337\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.7437 - main_output_accuracy: 0.6991 - main_output_loss: 1.5685 - tof_gate_loss: 0.2169 - val_loss: 1.3728 - val_main_output_accuracy: 0.7148 - val_main_output_loss: 1.2356 - val_tof_gate_loss: 0.0317\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6138 - main_output_accuracy: 0.7220 - main_output_loss: 1.4512 - tof_gate_loss: 0.1777 - val_loss: 1.3402 - val_main_output_accuracy: 0.7334 - val_main_output_loss: 1.2021 - val_tof_gate_loss: 0.0392\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.6930 - main_output_accuracy: 0.7065 - main_output_loss: 1.5187 - tof_gate_loss: 0.2206 - val_loss: 1.3387 - val_main_output_accuracy: 0.7305 - val_main_output_loss: 1.2021 - val_tof_gate_loss: 0.0350\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5977 - main_output_accuracy: 0.7435 - main_output_loss: 1.4341 - tof_gate_loss: 0.1750 - val_loss: 1.3273 - val_main_output_accuracy: 0.7344 - val_main_output_loss: 1.1935 - val_tof_gate_loss: 0.0253\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - loss: 1.5716 - main_output_accuracy: 0.7384 - main_output_loss: 1.4140 - tof_gate_loss: 0.1656 - val_loss: 1.3114 - val_main_output_accuracy: 0.7334 - val_main_output_loss: 1.1777 - val_tof_gate_loss: 0.0290\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.7270 - main_output_accuracy: 0.7229 - main_output_loss: 1.5528 - tof_gate_loss: 0.2334 - val_loss: 1.3416 - val_main_output_accuracy: 0.7256 - val_main_output_loss: 1.2083 - val_tof_gate_loss: 0.0322\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - loss: 1.6790 - main_output_accuracy: 0.7260 - main_output_loss: 1.5116 - tof_gate_loss: 0.2030 - val_loss: 1.3071 - val_main_output_accuracy: 0.7418 - val_main_output_loss: 1.1746 - val_tof_gate_loss: 0.0310\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.6919 - main_output_accuracy: 0.7144 - main_output_loss: 1.5212 - tof_gate_loss: 0.2230 - val_loss: 1.3211 - val_main_output_accuracy: 0.7315 - val_main_output_loss: 1.1902 - val_tof_gate_loss: 0.0273\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6563 - main_output_accuracy: 0.7244 - main_output_loss: 1.4911 - tof_gate_loss: 0.2039 - val_loss: 1.3046 - val_main_output_accuracy: 0.7467 - val_main_output_loss: 1.1725 - val_tof_gate_loss: 0.0380\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.5690 - main_output_accuracy: 0.7493 - main_output_loss: 1.4066 - tof_gate_loss: 0.1953 - val_loss: 1.3103 - val_main_output_accuracy: 0.7383 - val_main_output_loss: 1.1805 - val_tof_gate_loss: 0.0303\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 188ms/step - loss: 1.7226 - main_output_accuracy: 0.7122 - main_output_loss: 1.5530 - tof_gate_loss: 0.2136 - val_loss: 1.3347 - val_main_output_accuracy: 0.7270 - val_main_output_loss: 1.2036 - val_tof_gate_loss: 0.0371\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.7364 - main_output_accuracy: 0.7160 - main_output_loss: 1.5721 - tof_gate_loss: 0.2293 - val_loss: 1.2937 - val_main_output_accuracy: 0.7447 - val_main_output_loss: 1.1646 - val_tof_gate_loss: 0.0321\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.6781 - main_output_accuracy: 0.7316 - main_output_loss: 1.5151 - tof_gate_loss: 0.2115 - val_loss: 1.2949 - val_main_output_accuracy: 0.7354 - val_main_output_loss: 1.1671 - val_tof_gate_loss: 0.0264\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.6225 - main_output_accuracy: 0.7493 - main_output_loss: 1.4604 - tof_gate_loss: 0.1978 - val_loss: 1.3079 - val_main_output_accuracy: 0.7418 - val_main_output_loss: 1.1814 - val_tof_gate_loss: 0.0263\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - loss: 1.4844 - main_output_accuracy: 0.7665 - main_output_loss: 1.3311 - tof_gate_loss: 0.1514 - val_loss: 1.2957 - val_main_output_accuracy: 0.7526 - val_main_output_loss: 1.1701 - val_tof_gate_loss: 0.0241\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 190ms/step - loss: 1.6264 - main_output_accuracy: 0.7585 - main_output_loss: 1.4664 - tof_gate_loss: 0.2018 - val_loss: 1.3146 - val_main_output_accuracy: 0.7295 - val_main_output_loss: 1.1894 - val_tof_gate_loss: 0.0263\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.5605 - main_output_accuracy: 0.7605 - main_output_loss: 1.4056 - tof_gate_loss: 0.1788 - val_loss: 1.2941 - val_main_output_accuracy: 0.7452 - val_main_output_loss: 1.1677 - val_tof_gate_loss: 0.0312\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.5306 - main_output_accuracy: 0.7716 - main_output_loss: 1.3733 - tof_gate_loss: 0.1941 - val_loss: 1.2893 - val_main_output_accuracy: 0.7467 - val_main_output_loss: 1.1651 - val_tof_gate_loss: 0.0247\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.5996 - main_output_accuracy: 0.7636 - main_output_loss: 1.4384 - tof_gate_loss: 0.2035 - val_loss: 1.2981 - val_main_output_accuracy: 0.7398 - val_main_output_loss: 1.1740 - val_tof_gate_loss: 0.0303\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 189ms/step - loss: 1.5704 - main_output_accuracy: 0.7599 - main_output_loss: 1.4144 - tof_gate_loss: 0.1928 - val_loss: 1.3149 - val_main_output_accuracy: 0.7295 - val_main_output_loss: 1.1912 - val_tof_gate_loss: 0.0257\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.6217 - main_output_accuracy: 0.7668 - main_output_loss: 1.4618 - tof_gate_loss: 0.2106 - val_loss: 1.2869 - val_main_output_accuracy: 0.7521 - val_main_output_loss: 1.1634 - val_tof_gate_loss: 0.0290\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.5596 - main_output_accuracy: 0.7747 - main_output_loss: 1.4007 - tof_gate_loss: 0.1976 - val_loss: 1.3115 - val_main_output_accuracy: 0.7428 - val_main_output_loss: 1.1878 - val_tof_gate_loss: 0.0327\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.4916 - main_output_accuracy: 0.7901 - main_output_loss: 1.3394 - tof_gate_loss: 0.1755 - val_loss: 1.2827 - val_main_output_accuracy: 0.7491 - val_main_output_loss: 1.1603 - val_tof_gate_loss: 0.0266\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 187ms/step - loss: 1.6185 - main_output_accuracy: 0.7717 - main_output_loss: 1.4613 - tof_gate_loss: 0.2179 - val_loss: 1.2881 - val_main_output_accuracy: 0.7447 - val_main_output_loss: 1.1665 - val_tof_gate_loss: 0.0264\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.5474 - main_output_accuracy: 0.7708 - main_output_loss: 1.3912 - tof_gate_loss: 0.1961 - val_loss: 1.2901 - val_main_output_accuracy: 0.7521 - val_main_output_loss: 1.1674 - val_tof_gate_loss: 0.0355\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.5613 - main_output_accuracy: 0.7807 - main_output_loss: 1.4048 - tof_gate_loss: 0.2014 - val_loss: 1.2818 - val_main_output_accuracy: 0.7506 - val_main_output_loss: 1.1606 - val_tof_gate_loss: 0.0281\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.5174 - main_output_accuracy: 0.7950 - main_output_loss: 1.3612 - tof_gate_loss: 0.1819 - val_loss: 1.3059 - val_main_output_accuracy: 0.7359 - val_main_output_loss: 1.1846 - val_tof_gate_loss: 0.0332\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.4925 - main_output_accuracy: 0.8000 - main_output_loss: 1.3409 - tof_gate_loss: 0.1747 - val_loss: 1.2733 - val_main_output_accuracy: 0.7541 - val_main_output_loss: 1.1544 - val_tof_gate_loss: 0.0221\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.5983 - main_output_accuracy: 0.7843 - main_output_loss: 1.4405 - tof_gate_loss: 0.2165 - val_loss: 1.2771 - val_main_output_accuracy: 0.7560 - val_main_output_loss: 1.1573 - val_tof_gate_loss: 0.0284\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.5135 - main_output_accuracy: 0.7849 - main_output_loss: 1.3607 - tof_gate_loss: 0.1961 - val_loss: 1.2960 - val_main_output_accuracy: 0.7418 - val_main_output_loss: 1.1765 - val_tof_gate_loss: 0.0293\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.5558 - main_output_accuracy: 0.7828 - main_output_loss: 1.4042 - tof_gate_loss: 0.2033 - val_loss: 1.2696 - val_main_output_accuracy: 0.7644 - val_main_output_loss: 1.1514 - val_tof_gate_loss: 0.0257\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 1.5664 - main_output_accuracy: 0.7863 - main_output_loss: 1.4215 - tof_gate_loss: 0.2065 - val_loss: 1.2887 - val_main_output_accuracy: 0.7418 - val_main_output_loss: 1.1713 - val_tof_gate_loss: 0.0250\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - loss: 1.5537 - main_output_accuracy: 0.7969 - main_output_loss: 1.4026 - tof_gate_loss: 0.2003 - val_loss: 1.2621 - val_main_output_accuracy: 0.7575 - val_main_output_loss: 1.1456 - val_tof_gate_loss: 0.0199\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - loss: 1.5465 - main_output_accuracy: 0.7913 - main_output_loss: 1.3885 - tof_gate_loss: 0.2141 - val_loss: 1.2884 - val_main_output_accuracy: 0.7531 - val_main_output_loss: 1.1710 - val_tof_gate_loss: 0.0260\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - loss: 1.6312 - main_output_accuracy: 0.7712 - main_output_loss: 1.4708 - tof_gate_loss: 0.2334 - val_loss: 1.2835 - val_main_output_accuracy: 0.7545 - val_main_output_loss: 1.1654 - val_tof_gate_loss: 0.0328\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.4728 - main_output_accuracy: 0.8045 - main_output_loss: 1.3241 - tof_gate_loss: 0.1834 - val_loss: 1.2838 - val_main_output_accuracy: 0.7575 - val_main_output_loss: 1.1680 - val_tof_gate_loss: 0.0238\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.4959 - main_output_accuracy: 0.8014 - main_output_loss: 1.3394 - tof_gate_loss: 0.1995 - val_loss: 1.2905 - val_main_output_accuracy: 0.7536 - val_main_output_loss: 1.1750 - val_tof_gate_loss: 0.0237\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.5277 - main_output_accuracy: 0.7951 - main_output_loss: 1.3770 - tof_gate_loss: 0.1993 - val_loss: 1.2907 - val_main_output_accuracy: 0.7511 - val_main_output_loss: 1.1736 - val_tof_gate_loss: 0.0345\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.5949 - main_output_accuracy: 0.7866 - main_output_loss: 1.4403 - tof_gate_loss: 0.2216 - val_loss: 1.2768 - val_main_output_accuracy: 0.7590 - val_main_output_loss: 1.1610 - val_tof_gate_loss: 0.0281\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - loss: 1.3688 - main_output_accuracy: 0.8277 - main_output_loss: 1.2290 - tof_gate_loss: 0.1516 - val_loss: 1.2898 - val_main_output_accuracy: 0.7541 - val_main_output_loss: 1.1734 - val_tof_gate_loss: 0.0334\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.5033 - main_output_accuracy: 0.7946 - main_output_loss: 1.3559 - tof_gate_loss: 0.2009 - val_loss: 1.2897 - val_main_output_accuracy: 0.7531 - val_main_output_loss: 1.1751 - val_tof_gate_loss: 0.0258\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.3633 - main_output_accuracy: 0.8353 - main_output_loss: 1.2221 - tof_gate_loss: 0.1620 - val_loss: 1.2544 - val_main_output_accuracy: 0.7683 - val_main_output_loss: 1.1412 - val_tof_gate_loss: 0.0225\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step - loss: 1.4601 - main_output_accuracy: 0.8166 - main_output_loss: 1.3145 - tof_gate_loss: 0.1831 - val_loss: 1.3048 - val_main_output_accuracy: 0.7393 - val_main_output_loss: 1.1921 - val_tof_gate_loss: 0.0201\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.4142 - main_output_accuracy: 0.8259 - main_output_loss: 1.2745 - tof_gate_loss: 0.1573 - val_loss: 1.2715 - val_main_output_accuracy: 0.7516 - val_main_output_loss: 1.1591 - val_tof_gate_loss: 0.0226\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.4718 - main_output_accuracy: 0.8115 - main_output_loss: 1.3199 - tof_gate_loss: 0.1948 - val_loss: 1.2726 - val_main_output_accuracy: 0.7570 - val_main_output_loss: 1.1595 - val_tof_gate_loss: 0.0265\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.5295 - main_output_accuracy: 0.8202 - main_output_loss: 1.3781 - tof_gate_loss: 0.2050 - val_loss: 1.2584 - val_main_output_accuracy: 0.7703 - val_main_output_loss: 1.1457 - val_tof_gate_loss: 0.0257\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.4589 - main_output_accuracy: 0.8209 - main_output_loss: 1.3136 - tof_gate_loss: 0.1846 - val_loss: 1.2684 - val_main_output_accuracy: 0.7644 - val_main_output_loss: 1.1564 - val_tof_gate_loss: 0.0229\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4357 - main_output_accuracy: 0.8202 - main_output_loss: 1.2948 - tof_gate_loss: 0.1758 - val_loss: 1.2674 - val_main_output_accuracy: 0.7585 - val_main_output_loss: 1.1547 - val_tof_gate_loss: 0.0282\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - loss: 1.3923 - main_output_accuracy: 0.8290 - main_output_loss: 1.2517 - tof_gate_loss: 0.1574 - val_loss: 1.2488 - val_main_output_accuracy: 0.7717 - val_main_output_loss: 1.1362 - val_tof_gate_loss: 0.0309\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.3814 - main_output_accuracy: 0.8373 - main_output_loss: 1.2469 - tof_gate_loss: 0.1657 - val_loss: 1.2549 - val_main_output_accuracy: 0.7658 - val_main_output_loss: 1.1428 - val_tof_gate_loss: 0.0269\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.4385 - main_output_accuracy: 0.8217 - main_output_loss: 1.2944 - tof_gate_loss: 0.1901 - val_loss: 1.2638 - val_main_output_accuracy: 0.7614 - val_main_output_loss: 1.1532 - val_tof_gate_loss: 0.0229\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - loss: 1.3677 - main_output_accuracy: 0.8415 - main_output_loss: 1.2264 - tof_gate_loss: 0.1747 - val_loss: 1.2852 - val_main_output_accuracy: 0.7604 - val_main_output_loss: 1.1746 - val_tof_gate_loss: 0.0250\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - loss: 1.4162 - main_output_accuracy: 0.8277 - main_output_loss: 1.2709 - tof_gate_loss: 0.1940 - val_loss: 1.2957 - val_main_output_accuracy: 0.7585 - val_main_output_loss: 1.1849 - val_tof_gate_loss: 0.0266\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.4760 - main_output_accuracy: 0.8144 - main_output_loss: 1.3345 - tof_gate_loss: 0.1993 - val_loss: 1.2597 - val_main_output_accuracy: 0.7732 - val_main_output_loss: 1.1495 - val_tof_gate_loss: 0.0226\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - loss: 1.5233 - main_output_accuracy: 0.7921 - main_output_loss: 1.3757 - tof_gate_loss: 0.2135 - val_loss: 1.2715 - val_main_output_accuracy: 0.7629 - val_main_output_loss: 1.1610 - val_tof_gate_loss: 0.0248\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.3668 - main_output_accuracy: 0.8330 - main_output_loss: 1.2262 - tof_gate_loss: 0.1538 - val_loss: 1.2621 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 1.1527 - val_tof_gate_loss: 0.0220\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - loss: 1.5515 - main_output_accuracy: 0.7940 - main_output_loss: 1.3992 - tof_gate_loss: 0.2241 - val_loss: 1.2410 - val_main_output_accuracy: 0.7742 - val_main_output_loss: 1.1315 - val_tof_gate_loss: 0.0235\n",
      "Epoch 101/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 192ms/step - loss: 1.3211 - main_output_accuracy: 0.8580 - main_output_loss: 1.1974 - tof_gate_loss: 0.1537 - val_loss: 1.2676 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.1580 - val_tof_gate_loss: 0.0247\n",
      "Epoch 102/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.4449 - main_output_accuracy: 0.8187 - main_output_loss: 1.3039 - tof_gate_loss: 0.1886 - val_loss: 1.2607 - val_main_output_accuracy: 0.7698 - val_main_output_loss: 1.1517 - val_tof_gate_loss: 0.0216\n",
      "Epoch 103/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - loss: 1.4087 - main_output_accuracy: 0.8449 - main_output_loss: 1.2786 - tof_gate_loss: 0.1887 - val_loss: 1.2646 - val_main_output_accuracy: 0.7639 - val_main_output_loss: 1.1558 - val_tof_gate_loss: 0.0239\n",
      "Epoch 104/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.3880 - main_output_accuracy: 0.8484 - main_output_loss: 1.2490 - tof_gate_loss: 0.1768 - val_loss: 1.2592 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1505 - val_tof_gate_loss: 0.0246\n",
      "Epoch 105/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - loss: 1.4686 - main_output_accuracy: 0.8313 - main_output_loss: 1.3235 - tof_gate_loss: 0.2060 - val_loss: 1.2611 - val_main_output_accuracy: 0.7693 - val_main_output_loss: 1.1522 - val_tof_gate_loss: 0.0263\n",
      "Epoch 106/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.3473 - main_output_accuracy: 0.8591 - main_output_loss: 1.2029 - tof_gate_loss: 0.1782 - val_loss: 1.2714 - val_main_output_accuracy: 0.7722 - val_main_output_loss: 1.1628 - val_tof_gate_loss: 0.0253\n",
      "Epoch 107/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - loss: 1.2899 - main_output_accuracy: 0.8590 - main_output_loss: 1.1556 - tof_gate_loss: 0.1514 - val_loss: 1.2614 - val_main_output_accuracy: 0.7771 - val_main_output_loss: 1.1535 - val_tof_gate_loss: 0.0228\n",
      "Epoch 108/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - loss: 1.4101 - main_output_accuracy: 0.8483 - main_output_loss: 1.2680 - tof_gate_loss: 0.2008 - val_loss: 1.2644 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.1566 - val_tof_gate_loss: 0.0232\n",
      "Epoch 109/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 1.5015 - main_output_accuracy: 0.8153 - main_output_loss: 1.3532 - tof_gate_loss: 0.2215 - val_loss: 1.2712 - val_main_output_accuracy: 0.7722 - val_main_output_loss: 1.1633 - val_tof_gate_loss: 0.0247\n",
      "Epoch 110/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.3705 - main_output_accuracy: 0.8461 - main_output_loss: 1.2334 - tof_gate_loss: 0.1791 - val_loss: 1.2688 - val_main_output_accuracy: 0.7688 - val_main_output_loss: 1.1606 - val_tof_gate_loss: 0.0271\n",
      "Epoch 111/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - loss: 1.4707 - main_output_accuracy: 0.8312 - main_output_loss: 1.3276 - tof_gate_loss: 0.2042 - val_loss: 1.2782 - val_main_output_accuracy: 0.7585 - val_main_output_loss: 1.1708 - val_tof_gate_loss: 0.0237\n",
      "Epoch 112/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - loss: 1.3158 - main_output_accuracy: 0.8647 - main_output_loss: 1.1797 - tof_gate_loss: 0.1668 - val_loss: 1.2774 - val_main_output_accuracy: 0.7683 - val_main_output_loss: 1.1704 - val_tof_gate_loss: 0.0226\n",
      "Epoch 113/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - loss: 1.3211 - main_output_accuracy: 0.8454 - main_output_loss: 1.1861 - tof_gate_loss: 0.1644 - val_loss: 1.2550 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.1479 - val_tof_gate_loss: 0.0233\n",
      "Epoch 114/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - loss: 1.4245 - main_output_accuracy: 0.8375 - main_output_loss: 1.2809 - tof_gate_loss: 0.2031 - val_loss: 1.2556 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.1489 - val_tof_gate_loss: 0.0240\n",
      "Epoch 115/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - loss: 1.3890 - main_output_accuracy: 0.8434 - main_output_loss: 1.2485 - tof_gate_loss: 0.1881 - val_loss: 1.2802 - val_main_output_accuracy: 0.7599 - val_main_output_loss: 1.1734 - val_tof_gate_loss: 0.0245\n",
      "Epoch 116/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - loss: 1.3788 - main_output_accuracy: 0.8507 - main_output_loss: 1.2383 - tof_gate_loss: 0.1911 - val_loss: 1.2730 - val_main_output_accuracy: 0.7658 - val_main_output_loss: 1.1666 - val_tof_gate_loss: 0.0241\n",
      "Epoch 117/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - loss: 1.4703 - main_output_accuracy: 0.8360 - main_output_loss: 1.3271 - tof_gate_loss: 0.2076 - val_loss: 1.2524 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.1460 - val_tof_gate_loss: 0.0242\n",
      "Epoch 118/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - loss: 1.4003 - main_output_accuracy: 0.8407 - main_output_loss: 1.2590 - tof_gate_loss: 0.1924 - val_loss: 1.2573 - val_main_output_accuracy: 0.7820 - val_main_output_loss: 1.1502 - val_tof_gate_loss: 0.0267\n",
      "Epoch 119/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - loss: 1.2829 - main_output_accuracy: 0.8667 - main_output_loss: 1.1539 - tof_gate_loss: 0.1576 - val_loss: 1.2651 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.1596 - val_tof_gate_loss: 0.0223\n",
      "Epoch 120/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - loss: 1.3950 - main_output_accuracy: 0.8591 - main_output_loss: 1.2549 - tof_gate_loss: 0.1926 - val_loss: 1.2594 - val_main_output_accuracy: 0.7732 - val_main_output_loss: 1.1540 - val_tof_gate_loss: 0.0215\n",
      "--- Evaluating Fold 4 ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step\n",
      "Fold 4 Accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import argmax\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# PARQUET_FILE = f'{DATA_PATH}/extended_features_df.parquet'\n",
    "# PARQUET_FILE = 'output/full_features_df.parquet'\n",
    "PARQUET_FILE = 'output/final_processed_train_data.parquet'\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "schema_df = pl.read_parquet(PARQUET_FILE, n_rows=0)\n",
    "all_columns = schema_df.columns\n",
    "meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "feature_cols = [c for c in all_columns if c not in meta_cols]\n",
    "imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "tof_cols  = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "\n",
    "print(\"Scanning Parquet file for sequence IDs...\")\n",
    "all_sequence_ids = (\n",
    "    pl.scan_parquet(PARQUET_FILE)\n",
    "    .select('sequence_id')\n",
    "    .unique()\n",
    "    .collect()\n",
    "    .to_numpy()\n",
    "    .ravel()\n",
    ")\n",
    "print(f\"Found {len(all_sequence_ids)} unique sequences.\")\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "imu_dim = len(imu_cols)\n",
    "\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids)):\n",
    "    print(f\"\\n=== Fold {fold_idx + 1} ===\")\n",
    "    train_ids = all_sequence_ids[train_indices]\n",
    "    val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "    print(f\"Loading data for fold {fold_idx + 1}...\")\n",
    "    train_df = pl.read_parquet(PARQUET_FILE).filter(pl.col('sequence_id').is_in(train_ids))\n",
    "    val_df = pl.read_parquet(PARQUET_FILE).filter(pl.col('sequence_id').is_in(val_ids))\n",
    "    print(\"Fold data loaded.\")\n",
    "\n",
    "    train_gate_df = generate_gate_targets(train_df, tof_cols)\n",
    "    val_gate_df = generate_gate_targets(val_df, tof_cols)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df['gesture']) \n",
    "    train_df = train_df.with_columns(pl.Series(\"gesture_int\", le.transform(train_df['gesture'])))\n",
    "    val_df = val_df.with_columns(pl.Series(\"gesture_int\", le.transform(val_df['gesture'])))\n",
    "\n",
    "    X_train_scaled_features, X_val_scaled_features = pl_standard_scaling(train_df, val_df, imu_cols + tof_cols)\n",
    "\n",
    "    meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "    train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "    val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "    del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "    gc.collect()\n",
    "\n",
    "    X_train, y_train, train_gate_target = create_sequence_dataset(train_df_final, imu_cols + tof_cols, train_gate_df)\n",
    "    X_val, y_val, val_gate_target = create_sequence_dataset(val_df_final, imu_cols + tof_cols, val_gate_df)\n",
    "\n",
    "    del train_df_final, val_df_final\n",
    "    gc.collect()\n",
    "\n",
    "    max_pad_len=128\n",
    "    X_train_padded = perform_padding(X_train, max_pad_len)\n",
    "    X_val_padded = perform_padding(X_val, max_pad_len)\n",
    "    print(f'Fully padded dataset shape: {X_train_padded.shape}')\n",
    "\n",
    "    y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "    y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "    train_dataset = GatedMixupGenerator(\n",
    "        X=X_train_padded,\n",
    "        y=y_train_cat,\n",
    "        gate_targets=train_gate_target,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        imu_dim=imu_dim,\n",
    "        class_weight=None,\n",
    "        alpha=0.2,\n",
    "        masking_prob=0.25\n",
    "    )\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        X_val_padded,\n",
    "        {\n",
    "            'main_output': y_val_cat,\n",
    "            'tof_gate': val_gate_target[:, np.newaxis]\n",
    "        }\n",
    "    )).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    del X_val, y_val, X_train, y_train, X_train_padded, X_val_padded\n",
    "    gc.collect()\n",
    "    \n",
    "    model = create_model_definition(train_dataset, len(imu_cols))\n",
    "    train_model(model, train_dataset, val_dataset, 150, LR_INIT, WD)\n",
    "\n",
    "    print(f\"--- Evaluating Fold {fold_idx + 1} ---\")\n",
    "    val_preds = model.predict(val_dataset)\n",
    "    main_output_preds = val_preds['main_output']\n",
    "\n",
    "    y_pred_fold = np.argmax(main_output_preds, axis=1)\n",
    "    y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "    fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "    fold_accuracies.append(fold_acc)\n",
    "    print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "\n",
    "    all_preds.append(y_pred_fold)\n",
    "    all_labels.append(y_true_fold)\n",
    "\n",
    "    del train_dataset, model, val_dataset\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc058c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-validation Summary ===\n",
      "Per-fold Accuracies: [0.7546614327772326, 0.7507360157016683, 0.767909715407262, 0.7741777123220422]\n",
      "Mean Accuracy: 0.7619 ± 0.0095\n",
      "\n",
      "=== Overall Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8195    0.8041    0.8117       638\n",
      "           1     0.6683    0.6264    0.6467       637\n",
      "           2     0.9808    0.9503    0.9653       161\n",
      "           3     0.5449    0.5611    0.5529       638\n",
      "           4     0.6404    0.5703    0.6033       640\n",
      "           5     0.8735    0.9006    0.8869       161\n",
      "           6     0.8163    0.7844    0.8000       640\n",
      "           7     0.8759    0.9156    0.8953       640\n",
      "           8     0.9808    0.9503    0.9653       161\n",
      "           9     0.5899    0.6922    0.6370       640\n",
      "          10     0.6574    0.6297    0.6433       640\n",
      "          11     0.6854    0.7578    0.7198       161\n",
      "          12     0.9462    0.9581    0.9521       477\n",
      "          13     0.5155    0.3106    0.3876       161\n",
      "          14     0.9222    0.9266    0.9244       640\n",
      "          15     0.9249    0.9017    0.9131       478\n",
      "          16     0.8900    0.9161    0.9029       477\n",
      "          17     0.4608    0.6211    0.5291       161\n",
      "\n",
      "    accuracy                         0.7619      8151\n",
      "   macro avg     0.7663    0.7654    0.7631      8151\n",
      "weighted avg     0.7630    0.7619    0.7610      8151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation Summary\n",
    "print(\"\\n=== Cross-validation Summary ===\")\n",
    "print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "\n",
    "# Global classification report\n",
    "y_all_pred = np.concatenate(all_preds)\n",
    "y_all_true = np.concatenate(all_labels)\n",
    "\n",
    "print(\"\\n=== Overall Classification Report ===\")\n",
    "print(classification_report(y_all_true, y_all_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431da544",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m:\n\u001b[32m      2\u001b[39m     x=e[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m     y=e[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for e in train_dataset:\n",
    "    x=e[0]\n",
    "    y=e[1]\n",
    "    break\n",
    "\n",
    "original = x    \n",
    "inputs = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18f04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 127, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 486,492\n",
      "Non-trainable params: 960\n",
      "Total params: 487,452\n",
      "Estimated model size: 1.86 MB\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# from src.constants import return_data_path\n",
    "# DATA_PATH = return_data_path()\n",
    "# FILE_PATH = f'{DATA_PATH}train.csv'\n",
    "# schema_df = pl.read_csv(FILE_PATH, n_rows=0)\n",
    "# all_columns = schema_df.columns\n",
    "# meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "#                 'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "# feature_cols = [c for c in all_columns if c not in meta_cols]\n",
    "# imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "# tof_cols  = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "# imu_cols  = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "\n",
    "# model = build_gated_two_branch_model(125, 13, 25, 18)\n",
    "trainable_count = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "non_trainable_count = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "total_params = trainable_count + non_trainable_count\n",
    "\n",
    "print(f\"Trainable params: {trainable_count:,}\")\n",
    "print(f\"Non-trainable params: {non_trainable_count:,}\")\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "\n",
    "\n",
    "bytes_per_param = 4  # for float32\n",
    "model_size_bytes = total_params * bytes_per_param\n",
    "model_size_mb = model_size_bytes / (1024**2)\n",
    "\n",
    "print(f\"Estimated model size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274d872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method GatedMixupGenerator.__getitem__ of <src.nn_blocks.GatedMixupGenerator object at 0x7f48cd2829f0>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 348, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = original\n",
    "x = unet_se_cnn(x, base_filters=32, kernel_size=3)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e89f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 348, 528])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, GaussianNoise, Concatenate, Lambda, Activation, Multiply\n",
    "\n",
    "wd=1e-4\n",
    "xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "xc = GaussianNoise(0.09)(x)\n",
    "xc = Dense(16, activation='elu')(xc)\n",
    "x = Concatenate()([xa, xb, xc])\n",
    "# xa.shape, xb.shape, xc.shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab41bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 700])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "def time_sum(x):\n",
    "    return k.sum(x, axis=1)\n",
    "\n",
    "def squeeze_last_axis(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def expand_last_axis(x):\n",
    "    return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "score = Dense(1, activation='tanh')(inputs)\n",
    "score = Lambda(squeeze_last_axis)(score)\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d653c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 700, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = Activation('softmax')(score)\n",
    "weights = Lambda(expand_last_axis)(weights)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b32dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 15])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = Multiply()([inputs, weights])\n",
    "context = Lambda(time_sum)(context)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 348, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "    x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "x.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35369c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0856f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = features_processing(x)\n",
    "x = Dropout(0.3)(x) \n",
    "print(x.shape)\n",
    "x = Dense(x.shape[-1], activation=\"relu\")(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "outputs = Dense(18, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0d2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 350, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.nn_blocks import residual_se_cnn_block,  res_se_cnn_decoder_block, unet_se_cnn_bilstm, unet_se_cnn\n",
    "# x = original\n",
    "# b = residual_se_cnn_block(x, 64, 3, 2)\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef5232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 700, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import UpSampling1D, GRU\n",
    "\n",
    "# UpSampling1D(2)(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60209b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeda984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 700, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filters = 32\n",
    "# x = original\n",
    "# for _ in range(3):\n",
    "#     x = residual_se_cnn_block(x, filters, 3, 1)\n",
    "#     filters *= 2\n",
    "\n",
    "# x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f361500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 700, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c_shape = x.shape[-1]\n",
    "# # x = Bidirectional(GRU(c_shape*2))(x)\n",
    "# x = Dense(c_shape)(x)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24, 348, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x1 = x\n",
    "\n",
    "# b = unet_se_cnn(original)\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40bf291",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"up_sampling1d_8\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (24, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m c = \u001b[43munet_se_cnn_bilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m c.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/src/nn_blocks.py:187\u001b[39m, in \u001b[36munet_se_cnn_bilstm\u001b[39m\u001b[34m(x, base_filters, kernel_size, drop)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# Decoder \u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m skip \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(skips):\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     filters //= \u001b[32m2\u001b[39m\n\u001b[32m    188\u001b[39m     x = res_se_cnn_decoder_block(x, filters, kernel_size, drop=drop, skip_connection=skip)\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/src/nn_blocks.py:128\u001b[39m, in \u001b[36mres_se_cnn_decoder_block\u001b[39m\u001b[34m(x, filters, kernel_size, drop, wd, skip_connection)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mres_se_cnn_decoder_block\u001b[39m(x, filters, kernel_size, drop=\u001b[32m0.3\u001b[39m, wd=\u001b[32m1e-4\u001b[39m, skip_connection=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     x = \u001b[43mUpSampling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     x = Conv1D(filters, kernel_size, padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, use_bias=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    130\u001b[39m                kernel_regularizer=l2(wd))(x)\n\u001b[32m    131\u001b[39m     x = LayerNormalization()(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/layers/input_spec.py:186\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec.allow_last_axis_squeeze:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim != spec.ndim:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    188\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis incompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m         )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.max_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim > spec.max_ndim:\n",
      "\u001b[31mValueError\u001b[39m: Input 0 of layer \"up_sampling1d_8\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (24, 128)"
     ]
    }
   ],
   "source": [
    "# c = unet_se_cnn_bilstm(original)\n",
    "# c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
