{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d456d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building a lean base DataFrame with metadata and raw IMU columns...\n",
      "  Lean base DataFrame created with shape: (574945, 11)\n",
      "  Performing label encoding...\n",
      " Starting merge process...\n",
      "  Loading and joining features from: imu_physics_feats.parquet\n",
      "  Loading and joining features from: imu_cross_modal_features.parquet\n",
      "  Merge complete.\n",
      "  Final merged DataFrame created with shape: (574945, 34)\n",
      "  Training with 29 final IMU features.\n",
      "\n",
      "=== Fold 1/4 ===\n",
      "Fold data loaded.\n",
      "Epoch 1/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 288ms/step - accuracy: 0.0961 - loss: 3.2297 - val_accuracy: 0.1457 - val_loss: 2.8482\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.1698 - loss: 2.7694 - val_accuracy: 0.1987 - val_loss: 2.6170\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.2189 - loss: 2.4791 - val_accuracy: 0.2444 - val_loss: 2.3712\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.2320 - loss: 2.3394 - val_accuracy: 0.2556 - val_loss: 2.2225\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.2582 - loss: 2.2338 - val_accuracy: 0.3204 - val_loss: 2.0389\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.2838 - loss: 2.1213 - val_accuracy: 0.3042 - val_loss: 2.0072\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.3203 - loss: 2.0455 - val_accuracy: 0.3616 - val_loss: 1.9009\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 244ms/step - accuracy: 0.3399 - loss: 1.9907 - val_accuracy: 0.3763 - val_loss: 1.8904\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 245ms/step - accuracy: 0.3689 - loss: 1.8876 - val_accuracy: 0.4156 - val_loss: 1.7432\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 243ms/step - accuracy: 0.3950 - loss: 1.8430 - val_accuracy: 0.4352 - val_loss: 1.7125\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.4282 - loss: 1.7617 - val_accuracy: 0.4284 - val_loss: 1.7795\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 242ms/step - accuracy: 0.4348 - loss: 1.7138 - val_accuracy: 0.4465 - val_loss: 1.7347\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.4508 - loss: 1.6937 - val_accuracy: 0.4858 - val_loss: 1.5846\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - accuracy: 0.4650 - loss: 1.6473 - val_accuracy: 0.4593 - val_loss: 1.6689\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.4738 - loss: 1.6100 - val_accuracy: 0.4676 - val_loss: 1.6121\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.4874 - loss: 1.5657 - val_accuracy: 0.4701 - val_loss: 1.5587\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.4834 - loss: 1.5598 - val_accuracy: 0.4961 - val_loss: 1.5109\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.4923 - loss: 1.5142 - val_accuracy: 0.4887 - val_loss: 1.5049\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.4987 - loss: 1.5140 - val_accuracy: 0.4853 - val_loss: 1.5594\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.4996 - loss: 1.4889 - val_accuracy: 0.4833 - val_loss: 1.5410\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.5185 - loss: 1.4728 - val_accuracy: 0.5191 - val_loss: 1.4515\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.5155 - loss: 1.4405 - val_accuracy: 0.5132 - val_loss: 1.4328\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.5328 - loss: 1.3943 - val_accuracy: 0.5334 - val_loss: 1.4184\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 301ms/step - accuracy: 0.5343 - loss: 1.3943 - val_accuracy: 0.5334 - val_loss: 1.4036\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.5403 - loss: 1.3912 - val_accuracy: 0.5368 - val_loss: 1.3720\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.5379 - loss: 1.3875 - val_accuracy: 0.5275 - val_loss: 1.3989\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.5425 - loss: 1.3633 - val_accuracy: 0.5368 - val_loss: 1.3882\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.5512 - loss: 1.3585 - val_accuracy: 0.5383 - val_loss: 1.3776\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.5463 - loss: 1.3630 - val_accuracy: 0.5304 - val_loss: 1.3767\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.5416 - loss: 1.3394 - val_accuracy: 0.5388 - val_loss: 1.3812\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.5552 - loss: 1.3239 - val_accuracy: 0.5466 - val_loss: 1.3425\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.5677 - loss: 1.3102 - val_accuracy: 0.5618 - val_loss: 1.3376\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.5774 - loss: 1.2780 - val_accuracy: 0.5182 - val_loss: 1.4950\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.5646 - loss: 1.2850 - val_accuracy: 0.5383 - val_loss: 1.3785\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.5786 - loss: 1.2557 - val_accuracy: 0.5574 - val_loss: 1.3106\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.5798 - loss: 1.2488 - val_accuracy: 0.5437 - val_loss: 1.3616\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.5897 - loss: 1.2384 - val_accuracy: 0.5672 - val_loss: 1.3081\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.5776 - loss: 1.2311 - val_accuracy: 0.5711 - val_loss: 1.2854\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.6014 - loss: 1.2032 - val_accuracy: 0.5500 - val_loss: 1.3249\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.5941 - loss: 1.2143 - val_accuracy: 0.5800 - val_loss: 1.2943\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 254ms/step - accuracy: 0.6085 - loss: 1.1889 - val_accuracy: 0.5697 - val_loss: 1.2964\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.6042 - loss: 1.1736 - val_accuracy: 0.5746 - val_loss: 1.2721\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.6221 - loss: 1.1547 - val_accuracy: 0.5775 - val_loss: 1.2850\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.6150 - loss: 1.1482 - val_accuracy: 0.5819 - val_loss: 1.2557\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 401ms/step - accuracy: 0.6200 - loss: 1.1419 - val_accuracy: 0.5829 - val_loss: 1.2813\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 243ms/step - accuracy: 0.6279 - loss: 1.1068 - val_accuracy: 0.5957 - val_loss: 1.2512\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.6304 - loss: 1.1074 - val_accuracy: 0.5810 - val_loss: 1.2931\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.6312 - loss: 1.1035 - val_accuracy: 0.5932 - val_loss: 1.2516\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.6438 - loss: 1.0989 - val_accuracy: 0.5648 - val_loss: 1.3461\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.6261 - loss: 1.1097 - val_accuracy: 0.5628 - val_loss: 1.3525\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.6369 - loss: 1.0941 - val_accuracy: 0.6021 - val_loss: 1.2422\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 268ms/step - accuracy: 0.6481 - loss: 1.0619 - val_accuracy: 0.5883 - val_loss: 1.2933\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.6487 - loss: 1.0684 - val_accuracy: 0.5972 - val_loss: 1.2449\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.6473 - loss: 1.0493 - val_accuracy: 0.6050 - val_loss: 1.2398\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.6524 - loss: 1.0606 - val_accuracy: 0.6109 - val_loss: 1.2250\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.6587 - loss: 1.0345 - val_accuracy: 0.5903 - val_loss: 1.2702\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.6568 - loss: 1.0214 - val_accuracy: 0.5972 - val_loss: 1.2507\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.6701 - loss: 1.0171 - val_accuracy: 0.6040 - val_loss: 1.2478\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.6711 - loss: 1.0004 - val_accuracy: 0.6040 - val_loss: 1.2180\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.6733 - loss: 1.0049 - val_accuracy: 0.5952 - val_loss: 1.2622\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.6846 - loss: 0.9630 - val_accuracy: 0.6026 - val_loss: 1.2655\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.6837 - loss: 0.9648 - val_accuracy: 0.6104 - val_loss: 1.2132\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.6834 - loss: 0.9757 - val_accuracy: 0.5942 - val_loss: 1.2730\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.6793 - loss: 0.9636 - val_accuracy: 0.6079 - val_loss: 1.2419\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.6884 - loss: 0.9519 - val_accuracy: 0.6109 - val_loss: 1.2380\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.6857 - loss: 0.9563 - val_accuracy: 0.5976 - val_loss: 1.2969\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.6908 - loss: 0.9525 - val_accuracy: 0.6251 - val_loss: 1.1774\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7035 - loss: 0.9282 - val_accuracy: 0.6070 - val_loss: 1.2361\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.6887 - loss: 0.9339 - val_accuracy: 0.6026 - val_loss: 1.3144\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.7034 - loss: 0.9166 - val_accuracy: 0.6217 - val_loss: 1.1894\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 266ms/step - accuracy: 0.7090 - loss: 0.9258 - val_accuracy: 0.6050 - val_loss: 1.2610\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.7120 - loss: 0.9056 - val_accuracy: 0.6241 - val_loss: 1.1932\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.7007 - loss: 0.9096 - val_accuracy: 0.6065 - val_loss: 1.2877\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.7122 - loss: 0.9325 - val_accuracy: 0.6050 - val_loss: 1.2877\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.7062 - loss: 0.9190 - val_accuracy: 0.6129 - val_loss: 1.3066\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7154 - loss: 0.8770 - val_accuracy: 0.6119 - val_loss: 1.2584\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.7153 - loss: 0.8802 - val_accuracy: 0.6084 - val_loss: 1.2665\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.7141 - loss: 0.8652 - val_accuracy: 0.6295 - val_loss: 1.2092\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.7189 - loss: 0.8784 - val_accuracy: 0.6178 - val_loss: 1.2474\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7217 - loss: 0.8791 - val_accuracy: 0.6202 - val_loss: 1.2251\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7263 - loss: 0.8669 - val_accuracy: 0.6227 - val_loss: 1.2349\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.7125 - loss: 0.8745 - val_accuracy: 0.6310 - val_loss: 1.2482\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.7174 - loss: 0.8473 - val_accuracy: 0.6305 - val_loss: 1.2315\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7197 - loss: 0.8447 - val_accuracy: 0.6300 - val_loss: 1.2952\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.7366 - loss: 0.8439 - val_accuracy: 0.6286 - val_loss: 1.2535\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.7314 - loss: 0.8174 - val_accuracy: 0.6192 - val_loss: 1.2697\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.7336 - loss: 0.8171 - val_accuracy: 0.6261 - val_loss: 1.2501\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7329 - loss: 0.8289 - val_accuracy: 0.6084 - val_loss: 1.3570\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.7494 - loss: 0.8116 - val_accuracy: 0.6148 - val_loss: 1.2803\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.7346 - loss: 0.8332 - val_accuracy: 0.6300 - val_loss: 1.2414\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 266ms/step - accuracy: 0.7362 - loss: 0.8290 - val_accuracy: 0.6222 - val_loss: 1.2925\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.7503 - loss: 0.7948 - val_accuracy: 0.6192 - val_loss: 1.3344\n",
      "Epoch 93/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.7461 - loss: 0.8015 - val_accuracy: 0.6192 - val_loss: 1.3124\n",
      "Epoch 94/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.7482 - loss: 0.8077 - val_accuracy: 0.6030 - val_loss: 1.3421\n",
      "Epoch 95/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.7511 - loss: 0.7939 - val_accuracy: 0.6060 - val_loss: 1.3914\n",
      "Epoch 96/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.7522 - loss: 0.7736 - val_accuracy: 0.6246 - val_loss: 1.2932\n",
      "Epoch 97/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7494 - loss: 0.7924 - val_accuracy: 0.6148 - val_loss: 1.3312\n",
      "Epoch 98/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 281ms/step - accuracy: 0.7660 - loss: 0.7813 - val_accuracy: 0.6212 - val_loss: 1.2708\n",
      "Epoch 99/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 299ms/step - accuracy: 0.7529 - loss: 0.7911 - val_accuracy: 0.6349 - val_loss: 1.2855\n",
      "Epoch 100/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 295ms/step - accuracy: 0.7678 - loss: 0.7710 - val_accuracy: 0.6138 - val_loss: 1.3305\n",
      "Epoch 101/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.7673 - loss: 0.7508 - val_accuracy: 0.6251 - val_loss: 1.3097\n",
      "Epoch 102/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 266ms/step - accuracy: 0.7540 - loss: 0.7854 - val_accuracy: 0.6256 - val_loss: 1.3256\n",
      "Epoch 103/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.7656 - loss: 0.7511 - val_accuracy: 0.6325 - val_loss: 1.2499\n",
      "Epoch 104/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.7730 - loss: 0.7276 - val_accuracy: 0.6320 - val_loss: 1.3219\n",
      "Epoch 105/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.7749 - loss: 0.7416 - val_accuracy: 0.6079 - val_loss: 1.4012\n",
      "Epoch 106/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.7728 - loss: 0.7305 - val_accuracy: 0.6168 - val_loss: 1.3160\n",
      "Epoch 107/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - accuracy: 0.7812 - loss: 0.7331 - val_accuracy: 0.6320 - val_loss: 1.2709\n",
      "Epoch 108/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7822 - loss: 0.7128 - val_accuracy: 0.6187 - val_loss: 1.3673\n",
      "Epoch 109/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.7736 - loss: 0.7398 - val_accuracy: 0.6271 - val_loss: 1.3617\n",
      "Epoch 110/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.7853 - loss: 0.7212 - val_accuracy: 0.6212 - val_loss: 1.3614\n",
      "Epoch 111/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7848 - loss: 0.7110 - val_accuracy: 0.6290 - val_loss: 1.3472\n",
      "Epoch 112/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.7676 - loss: 0.7512 - val_accuracy: 0.6295 - val_loss: 1.3401\n",
      "Epoch 113/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.7825 - loss: 0.6951 - val_accuracy: 0.6398 - val_loss: 1.3325\n",
      "Epoch 114/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7863 - loss: 0.6937 - val_accuracy: 0.6315 - val_loss: 1.3044\n",
      "Epoch 115/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.7805 - loss: 0.7039 - val_accuracy: 0.6281 - val_loss: 1.3995\n",
      "Epoch 116/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7820 - loss: 0.7057 - val_accuracy: 0.6320 - val_loss: 1.3251\n",
      "Epoch 117/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7904 - loss: 0.6947 - val_accuracy: 0.6217 - val_loss: 1.3338\n",
      "Epoch 118/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7877 - loss: 0.6885 - val_accuracy: 0.6261 - val_loss: 1.3456\n",
      "Epoch 119/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7877 - loss: 0.6907 - val_accuracy: 0.6310 - val_loss: 1.3276\n",
      "Epoch 120/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.8009 - loss: 0.6808 - val_accuracy: 0.6330 - val_loss: 1.3448\n",
      "Epoch 121/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.8034 - loss: 0.6561 - val_accuracy: 0.6192 - val_loss: 1.3704\n",
      "Epoch 122/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.8038 - loss: 0.6786 - val_accuracy: 0.6227 - val_loss: 1.3320\n",
      "Epoch 123/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.8125 - loss: 0.6610 - val_accuracy: 0.6349 - val_loss: 1.3760\n",
      "Epoch 124/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.7980 - loss: 0.6596 - val_accuracy: 0.6153 - val_loss: 1.4065\n",
      "Epoch 125/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7948 - loss: 0.6545 - val_accuracy: 0.6354 - val_loss: 1.3483\n",
      "Epoch 126/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.7805 - loss: 0.7071 - val_accuracy: 0.6261 - val_loss: 1.3553\n",
      "Epoch 127/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.7962 - loss: 0.6533 - val_accuracy: 0.6183 - val_loss: 1.4174\n",
      "Epoch 128/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7990 - loss: 0.6685 - val_accuracy: 0.6286 - val_loss: 1.3479\n",
      "Epoch 129/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.8040 - loss: 0.6477 - val_accuracy: 0.6403 - val_loss: 1.3671\n",
      "Epoch 130/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.7982 - loss: 0.6630 - val_accuracy: 0.6305 - val_loss: 1.3817\n",
      "Epoch 131/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.8029 - loss: 0.6472 - val_accuracy: 0.6251 - val_loss: 1.3859\n",
      "Epoch 132/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 255ms/step - accuracy: 0.8066 - loss: 0.6558 - val_accuracy: 0.6452 - val_loss: 1.3337\n",
      "Epoch 133/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.8043 - loss: 0.6507 - val_accuracy: 0.6443 - val_loss: 1.3788\n",
      "Epoch 134/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.7942 - loss: 0.6558 - val_accuracy: 0.6104 - val_loss: 1.4892\n",
      "Epoch 135/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.8045 - loss: 0.6459 - val_accuracy: 0.6354 - val_loss: 1.3863\n",
      "Epoch 136/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.8134 - loss: 0.6336 - val_accuracy: 0.6305 - val_loss: 1.4646\n",
      "Epoch 137/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.8113 - loss: 0.6205 - val_accuracy: 0.6310 - val_loss: 1.3869\n",
      "Epoch 138/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.8311 - loss: 0.6107 - val_accuracy: 0.6305 - val_loss: 1.4091\n",
      "Epoch 139/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.8138 - loss: 0.6239 - val_accuracy: 0.6428 - val_loss: 1.3544\n",
      "Epoch 140/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.8290 - loss: 0.5987 - val_accuracy: 0.6394 - val_loss: 1.4601\n",
      "Epoch 141/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.8032 - loss: 0.6472 - val_accuracy: 0.6330 - val_loss: 1.4017\n",
      "Epoch 142/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.8280 - loss: 0.6172 - val_accuracy: 0.6477 - val_loss: 1.3657\n",
      "Epoch 143/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.8143 - loss: 0.6197 - val_accuracy: 0.6320 - val_loss: 1.4652\n",
      "Epoch 144/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.8315 - loss: 0.5703 - val_accuracy: 0.6340 - val_loss: 1.4150\n",
      "Epoch 145/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.8349 - loss: 0.5740 - val_accuracy: 0.6232 - val_loss: 1.4101\n",
      "Epoch 146/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.8295 - loss: 0.5866 - val_accuracy: 0.6237 - val_loss: 1.4948\n",
      "Epoch 147/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.8321 - loss: 0.5704 - val_accuracy: 0.6300 - val_loss: 1.4457\n",
      "Epoch 148/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.8302 - loss: 0.5836 - val_accuracy: 0.6310 - val_loss: 1.4203\n",
      "Epoch 149/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.8258 - loss: 0.6282 - val_accuracy: 0.6340 - val_loss: 1.3888\n",
      "Epoch 150/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.8345 - loss: 0.5851 - val_accuracy: 0.6320 - val_loss: 1.4218\n",
      "--- Evaluating Fold ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step\n",
      "Fold 1 Accuracy: 0.6477\n",
      "\n",
      "=== Fold 2/4 ===\n",
      "Fold data loaded.\n",
      "Epoch 1/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 304ms/step - accuracy: 0.0896 - loss: 3.2299 - val_accuracy: 0.1609 - val_loss: 2.8631\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 284ms/step - accuracy: 0.1640 - loss: 2.8242 - val_accuracy: 0.1762 - val_loss: 2.5776\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.2116 - loss: 2.5165 - val_accuracy: 0.2493 - val_loss: 2.3018\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.2449 - loss: 2.3565 - val_accuracy: 0.2763 - val_loss: 2.1635\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.2641 - loss: 2.2209 - val_accuracy: 0.3091 - val_loss: 2.0649\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.2990 - loss: 2.0785 - val_accuracy: 0.3356 - val_loss: 1.9943\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.3190 - loss: 2.0162 - val_accuracy: 0.3386 - val_loss: 1.9910\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.3340 - loss: 1.9703 - val_accuracy: 0.3891 - val_loss: 1.8899\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.3735 - loss: 1.8704 - val_accuracy: 0.4097 - val_loss: 1.7537\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.4008 - loss: 1.8084 - val_accuracy: 0.4342 - val_loss: 1.7049\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.4241 - loss: 1.7294 - val_accuracy: 0.4558 - val_loss: 1.6470\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.4527 - loss: 1.6753 - val_accuracy: 0.4833 - val_loss: 1.5962\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.4683 - loss: 1.6307 - val_accuracy: 0.4411 - val_loss: 1.6502\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.4597 - loss: 1.6222 - val_accuracy: 0.4907 - val_loss: 1.5618\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.4883 - loss: 1.5591 - val_accuracy: 0.4799 - val_loss: 1.5815\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.4879 - loss: 1.5531 - val_accuracy: 0.4789 - val_loss: 1.5965\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.4748 - loss: 1.5636 - val_accuracy: 0.4902 - val_loss: 1.5639\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.5014 - loss: 1.5188 - val_accuracy: 0.4985 - val_loss: 1.5460\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.5152 - loss: 1.4786 - val_accuracy: 0.5088 - val_loss: 1.5151\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.5256 - loss: 1.4426 - val_accuracy: 0.5079 - val_loss: 1.5020\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.5134 - loss: 1.4275 - val_accuracy: 0.5093 - val_loss: 1.5012\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 255ms/step - accuracy: 0.5219 - loss: 1.4470 - val_accuracy: 0.4971 - val_loss: 1.5567\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.5315 - loss: 1.4084 - val_accuracy: 0.5393 - val_loss: 1.4231\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.5319 - loss: 1.3785 - val_accuracy: 0.5343 - val_loss: 1.4385\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.5445 - loss: 1.3766 - val_accuracy: 0.5191 - val_loss: 1.4654\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 255ms/step - accuracy: 0.5598 - loss: 1.3303 - val_accuracy: 0.5397 - val_loss: 1.4499\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.5563 - loss: 1.3485 - val_accuracy: 0.5216 - val_loss: 1.5024\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.5590 - loss: 1.3193 - val_accuracy: 0.5442 - val_loss: 1.4316\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.5683 - loss: 1.2898 - val_accuracy: 0.5466 - val_loss: 1.3847\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.5611 - loss: 1.2976 - val_accuracy: 0.5417 - val_loss: 1.4224\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.5723 - loss: 1.2674 - val_accuracy: 0.5491 - val_loss: 1.3853\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.5720 - loss: 1.2705 - val_accuracy: 0.5481 - val_loss: 1.4063\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.5736 - loss: 1.2496 - val_accuracy: 0.5731 - val_loss: 1.3440\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.5893 - loss: 1.2056 - val_accuracy: 0.5633 - val_loss: 1.3870\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.6046 - loss: 1.2040 - val_accuracy: 0.5545 - val_loss: 1.4109\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.5853 - loss: 1.2294 - val_accuracy: 0.5407 - val_loss: 1.4294\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 268ms/step - accuracy: 0.6000 - loss: 1.2093 - val_accuracy: 0.5574 - val_loss: 1.3765\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.5908 - loss: 1.2109 - val_accuracy: 0.5672 - val_loss: 1.3182\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.6021 - loss: 1.1839 - val_accuracy: 0.5667 - val_loss: 1.3747\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.6190 - loss: 1.1685 - val_accuracy: 0.5437 - val_loss: 1.4232\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.6143 - loss: 1.1499 - val_accuracy: 0.5751 - val_loss: 1.3476\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 256ms/step - accuracy: 0.5986 - loss: 1.1568 - val_accuracy: 0.5677 - val_loss: 1.3963\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.6152 - loss: 1.1390 - val_accuracy: 0.5761 - val_loss: 1.2949\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.6306 - loss: 1.1208 - val_accuracy: 0.5579 - val_loss: 1.3707\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.6155 - loss: 1.1392 - val_accuracy: 0.5682 - val_loss: 1.3120\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 271ms/step - accuracy: 0.6249 - loss: 1.0970 - val_accuracy: 0.5761 - val_loss: 1.3217\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.6220 - loss: 1.1204 - val_accuracy: 0.5716 - val_loss: 1.3951\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.6204 - loss: 1.0965 - val_accuracy: 0.5908 - val_loss: 1.2846\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 240ms/step - accuracy: 0.6331 - loss: 1.0780 - val_accuracy: 0.5550 - val_loss: 1.4102\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 245ms/step - accuracy: 0.6407 - loss: 1.0595 - val_accuracy: 0.5849 - val_loss: 1.2927\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.6354 - loss: 1.0643 - val_accuracy: 0.5810 - val_loss: 1.3115\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.6428 - loss: 1.0549 - val_accuracy: 0.5868 - val_loss: 1.3378\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 242ms/step - accuracy: 0.6467 - loss: 1.0573 - val_accuracy: 0.5873 - val_loss: 1.3070\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 245ms/step - accuracy: 0.6355 - loss: 1.0475 - val_accuracy: 0.5967 - val_loss: 1.2797\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.6447 - loss: 1.0655 - val_accuracy: 0.5898 - val_loss: 1.3107\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.6477 - loss: 1.0486 - val_accuracy: 0.5815 - val_loss: 1.3415\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 255ms/step - accuracy: 0.6515 - loss: 1.0449 - val_accuracy: 0.5962 - val_loss: 1.2887\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 246ms/step - accuracy: 0.6680 - loss: 0.9964 - val_accuracy: 0.5927 - val_loss: 1.3031\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.6628 - loss: 1.0049 - val_accuracy: 0.5972 - val_loss: 1.2425\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 246ms/step - accuracy: 0.6640 - loss: 1.0115 - val_accuracy: 0.5893 - val_loss: 1.2799\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.6765 - loss: 0.9950 - val_accuracy: 0.5932 - val_loss: 1.2739\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.6880 - loss: 0.9753 - val_accuracy: 0.6070 - val_loss: 1.2892\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.6727 - loss: 0.9975 - val_accuracy: 0.5996 - val_loss: 1.3018\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.6747 - loss: 0.9635 - val_accuracy: 0.5800 - val_loss: 1.3317\n",
      "Epoch 65/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.6618 - loss: 0.9969 - val_accuracy: 0.6006 - val_loss: 1.2704\n",
      "Epoch 66/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.6786 - loss: 0.9586 - val_accuracy: 0.6070 - val_loss: 1.3379\n",
      "Epoch 67/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.6865 - loss: 0.9474 - val_accuracy: 0.6045 - val_loss: 1.2628\n",
      "Epoch 68/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.6859 - loss: 0.9567 - val_accuracy: 0.5947 - val_loss: 1.3015\n",
      "Epoch 69/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 239ms/step - accuracy: 0.6865 - loss: 0.9322 - val_accuracy: 0.6178 - val_loss: 1.2572\n",
      "Epoch 70/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 239ms/step - accuracy: 0.6863 - loss: 0.9320 - val_accuracy: 0.6114 - val_loss: 1.2698\n",
      "Epoch 71/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.6828 - loss: 0.9410 - val_accuracy: 0.6143 - val_loss: 1.2669\n",
      "Epoch 72/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 238ms/step - accuracy: 0.6957 - loss: 0.9320 - val_accuracy: 0.6246 - val_loss: 1.2451\n",
      "Epoch 73/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 244ms/step - accuracy: 0.6926 - loss: 0.8919 - val_accuracy: 0.6060 - val_loss: 1.3060\n",
      "Epoch 74/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.7193 - loss: 0.8845 - val_accuracy: 0.6084 - val_loss: 1.2865\n",
      "Epoch 75/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.7127 - loss: 0.8754 - val_accuracy: 0.5839 - val_loss: 1.4296\n",
      "Epoch 76/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 240ms/step - accuracy: 0.6901 - loss: 0.9240 - val_accuracy: 0.6050 - val_loss: 1.2909\n",
      "Epoch 77/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.6957 - loss: 0.9206 - val_accuracy: 0.6173 - val_loss: 1.2696\n",
      "Epoch 78/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7028 - loss: 0.8964 - val_accuracy: 0.6217 - val_loss: 1.2529\n",
      "Epoch 79/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 227ms/step - accuracy: 0.7014 - loss: 0.9216 - val_accuracy: 0.6178 - val_loss: 1.2856\n",
      "Epoch 80/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7110 - loss: 0.8901 - val_accuracy: 0.6168 - val_loss: 1.3271\n",
      "Epoch 81/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 234ms/step - accuracy: 0.7139 - loss: 0.8768 - val_accuracy: 0.6129 - val_loss: 1.3087\n",
      "Epoch 82/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.7139 - loss: 0.8585 - val_accuracy: 0.6187 - val_loss: 1.2507\n",
      "Epoch 83/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 238ms/step - accuracy: 0.7274 - loss: 0.8337 - val_accuracy: 0.6178 - val_loss: 1.3108\n",
      "Epoch 84/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.7121 - loss: 0.8790 - val_accuracy: 0.6178 - val_loss: 1.2747\n",
      "Epoch 85/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 227ms/step - accuracy: 0.7096 - loss: 0.8947 - val_accuracy: 0.6124 - val_loss: 1.3661\n",
      "Epoch 86/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 234ms/step - accuracy: 0.7108 - loss: 0.8537 - val_accuracy: 0.6227 - val_loss: 1.3056\n",
      "Epoch 87/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - accuracy: 0.7150 - loss: 0.8552 - val_accuracy: 0.6202 - val_loss: 1.2672\n",
      "Epoch 88/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.7235 - loss: 0.8366 - val_accuracy: 0.6227 - val_loss: 1.2963\n",
      "Epoch 89/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - accuracy: 0.7270 - loss: 0.8270 - val_accuracy: 0.5957 - val_loss: 1.3953\n",
      "Epoch 90/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 242ms/step - accuracy: 0.7366 - loss: 0.8323 - val_accuracy: 0.6138 - val_loss: 1.3152\n",
      "Epoch 91/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step - accuracy: 0.7274 - loss: 0.8217 - val_accuracy: 0.6153 - val_loss: 1.3613\n",
      "Epoch 92/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.7313 - loss: 0.8108 - val_accuracy: 0.6163 - val_loss: 1.3491\n",
      "--- Evaluating Fold ---\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step\n",
      "Fold 2 Accuracy: 0.6246\n",
      "\n",
      "=== Fold 3/4 ===\n",
      "Fold data loaded.\n",
      "Epoch 1/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 238ms/step - accuracy: 0.0953 - loss: 3.2380 - val_accuracy: 0.1457 - val_loss: 2.8948\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.1766 - loss: 2.7960 - val_accuracy: 0.1997 - val_loss: 2.5068\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.2085 - loss: 2.5178 - val_accuracy: 0.1973 - val_loss: 2.5813\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 216ms/step - accuracy: 0.2356 - loss: 2.3573 - val_accuracy: 0.2586 - val_loss: 2.2881\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - accuracy: 0.2445 - loss: 2.2402 - val_accuracy: 0.2841 - val_loss: 2.1727\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 225ms/step - accuracy: 0.2826 - loss: 2.1366 - val_accuracy: 0.3032 - val_loss: 2.0559\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.2963 - loss: 2.0683 - val_accuracy: 0.3072 - val_loss: 2.0320\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 240ms/step - accuracy: 0.3274 - loss: 1.9835 - val_accuracy: 0.3263 - val_loss: 1.9858\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - accuracy: 0.3418 - loss: 1.9190 - val_accuracy: 0.3798 - val_loss: 1.8564\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.3799 - loss: 1.8342 - val_accuracy: 0.3935 - val_loss: 1.9072\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.4028 - loss: 1.7556 - val_accuracy: 0.4112 - val_loss: 1.7496\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.4380 - loss: 1.6913 - val_accuracy: 0.4220 - val_loss: 1.7011\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 243ms/step - accuracy: 0.4292 - loss: 1.7033 - val_accuracy: 0.4284 - val_loss: 1.7085\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 234ms/step - accuracy: 0.4605 - loss: 1.6124 - val_accuracy: 0.4387 - val_loss: 1.7040\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 213ms/step - accuracy: 0.4491 - loss: 1.6433 - val_accuracy: 0.4416 - val_loss: 1.6660\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.4641 - loss: 1.5912 - val_accuracy: 0.4681 - val_loss: 1.6294\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.4851 - loss: 1.5338 - val_accuracy: 0.4529 - val_loss: 1.6448\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.4778 - loss: 1.5414 - val_accuracy: 0.4941 - val_loss: 1.5586\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.5061 - loss: 1.4831 - val_accuracy: 0.4848 - val_loss: 1.5847\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 234ms/step - accuracy: 0.5093 - loss: 1.4676 - val_accuracy: 0.4769 - val_loss: 1.5871\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.4916 - loss: 1.4753 - val_accuracy: 0.5005 - val_loss: 1.5534\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.5204 - loss: 1.4299 - val_accuracy: 0.4980 - val_loss: 1.5241\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 234ms/step - accuracy: 0.5257 - loss: 1.4033 - val_accuracy: 0.4833 - val_loss: 1.5395\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.5324 - loss: 1.4045 - val_accuracy: 0.4936 - val_loss: 1.5126\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.5275 - loss: 1.3774 - val_accuracy: 0.5162 - val_loss: 1.4485\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.5328 - loss: 1.3816 - val_accuracy: 0.5132 - val_loss: 1.4956\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.5377 - loss: 1.3590 - val_accuracy: 0.5206 - val_loss: 1.4600\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step - accuracy: 0.5515 - loss: 1.3387 - val_accuracy: 0.5324 - val_loss: 1.4273\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 225ms/step - accuracy: 0.5549 - loss: 1.3329 - val_accuracy: 0.5255 - val_loss: 1.4623\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.5485 - loss: 1.3267 - val_accuracy: 0.5451 - val_loss: 1.3967\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.5572 - loss: 1.2986 - val_accuracy: 0.5221 - val_loss: 1.4620\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.5637 - loss: 1.2891 - val_accuracy: 0.5358 - val_loss: 1.4187\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - accuracy: 0.5511 - loss: 1.3052 - val_accuracy: 0.5358 - val_loss: 1.4510\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.5809 - loss: 1.2494 - val_accuracy: 0.5231 - val_loss: 1.4370\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 236ms/step - accuracy: 0.5805 - loss: 1.2457 - val_accuracy: 0.5481 - val_loss: 1.3877\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.5863 - loss: 1.2454 - val_accuracy: 0.5500 - val_loss: 1.3538\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - accuracy: 0.5993 - loss: 1.1921 - val_accuracy: 0.5299 - val_loss: 1.4323\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.5947 - loss: 1.2121 - val_accuracy: 0.5505 - val_loss: 1.3746\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - accuracy: 0.6078 - loss: 1.1988 - val_accuracy: 0.5530 - val_loss: 1.3654\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.6033 - loss: 1.1931 - val_accuracy: 0.5623 - val_loss: 1.3497\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 227ms/step - accuracy: 0.6069 - loss: 1.1439 - val_accuracy: 0.5343 - val_loss: 1.4160\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 239ms/step - accuracy: 0.6129 - loss: 1.1366 - val_accuracy: 0.5608 - val_loss: 1.3851\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.6060 - loss: 1.1729 - val_accuracy: 0.5608 - val_loss: 1.3359\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.6161 - loss: 1.1388 - val_accuracy: 0.5510 - val_loss: 1.3527\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.6257 - loss: 1.1332 - val_accuracy: 0.5378 - val_loss: 1.3777\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.6153 - loss: 1.1365 - val_accuracy: 0.5579 - val_loss: 1.3623\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step - accuracy: 0.6201 - loss: 1.1317 - val_accuracy: 0.5535 - val_loss: 1.3602\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.6249 - loss: 1.0829 - val_accuracy: 0.5662 - val_loss: 1.3613\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 236ms/step - accuracy: 0.6231 - loss: 1.1041 - val_accuracy: 0.5707 - val_loss: 1.3246\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 238ms/step - accuracy: 0.6378 - loss: 1.1017 - val_accuracy: 0.5756 - val_loss: 1.3600\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.6478 - loss: 1.0565 - val_accuracy: 0.5741 - val_loss: 1.3125\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 245ms/step - accuracy: 0.6408 - loss: 1.0681 - val_accuracy: 0.5672 - val_loss: 1.4048\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 227ms/step - accuracy: 0.6465 - loss: 1.0710 - val_accuracy: 0.5682 - val_loss: 1.3411\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.6398 - loss: 1.0919 - val_accuracy: 0.5716 - val_loss: 1.3258\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.6507 - loss: 1.0451 - val_accuracy: 0.5613 - val_loss: 1.3430\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.6615 - loss: 1.0308 - val_accuracy: 0.5677 - val_loss: 1.3754\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 236ms/step - accuracy: 0.6589 - loss: 1.0388 - val_accuracy: 0.5829 - val_loss: 1.3332\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - accuracy: 0.6663 - loss: 1.0102 - val_accuracy: 0.5613 - val_loss: 1.4175\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 275ms/step - accuracy: 0.6516 - loss: 1.0327 - val_accuracy: 0.5756 - val_loss: 1.3299\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 234ms/step - accuracy: 0.6569 - loss: 1.0183 - val_accuracy: 0.5564 - val_loss: 1.3597\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 235ms/step - accuracy: 0.6792 - loss: 0.9786 - val_accuracy: 0.5751 - val_loss: 1.3206\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.6636 - loss: 1.0141 - val_accuracy: 0.5829 - val_loss: 1.2706\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 238ms/step - accuracy: 0.6625 - loss: 1.0126 - val_accuracy: 0.5981 - val_loss: 1.2994\n",
      "Epoch 64/150\n",
      "\u001b[1m68/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.6841 - loss: 0.9888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 213\u001b[39m\n\u001b[32m    211\u001b[39m model.compile(optimizer=optimizer, loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    212\u001b[39m early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m20\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m, mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# --- EVALUATION ---\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Evaluating Fold ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    unet_se_cnn,\n",
    "    features_processing, \n",
    "    GatedMixupGenerator, \n",
    "    tof_block, \n",
    "    match_time_steps, \n",
    "    time_sum, \n",
    "    squeeze_last_axis,\n",
    "    expand_last_axis,\n",
    "    crop_or_pad_output_shape\n",
    ")\n",
    "\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    create_sequence_dataset,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "from src.merge_feats_dynamic import merge_feature_sets\n",
    "\n",
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "def create_sequence_dataset_simple(df: pl.DataFrame, feature_cols: list):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for seq_id, group in df.group_by('sequence_id', maintain_order=True):\n",
    "        sequences.append(group.select(feature_cols).to_numpy())\n",
    "        labels.append(group.select('gesture_int').item(0, 0))\n",
    "    return np.array(sequences, dtype=object), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION (Your existing function)\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    wave_block, residual_se_cnn_block, tof_block_2, attention_layer, wave_block, unet_se_cnn_bilstm\n",
    ")\n",
    "\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "\n",
    "    # x = unet_se_cnn_bilstm(imu, 128, 3)\n",
    "    x = unet_se_cnn_bilstm(imu, 64, 3)\n",
    "    x = unet_se_cnn_bilstm(x, 64, 3)\n",
    "    x = attention_layer(x) \n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "\n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    return tf.keras.models.Model(inputs=inp, outputs=main_out)\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "FEATURE_DIR = Path('output')\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "RANDOM_STATE = 42\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "files_to_merge = [\n",
    "    # \"imu_physics_feats.parquet\",\n",
    "    # \"imu_rolling_stats_features.parquet\",\n",
    "    # \"imu_cross_modal_features.parquet\",\n",
    "    'output/kaggle_0.8_feats.parquet'\n",
    "]\n",
    "feature_paths = [FEATURE_DIR / f for f in files_to_merge]\n",
    "\n",
    "# --- Step 2: Build a LEAN Base DataFrame ---\n",
    "print(\"  Building a lean base DataFrame with metadata and raw IMU columns...\")\n",
    "base_df = pl.read_parquet(FEATURE_DIR / \"cleaned_base_train_data.parquet\")\n",
    "demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "base_df = base_df.join(demographics_df, on='subject', how='left')\n",
    "\n",
    "all_raw_columns = base_df.columns\n",
    "meta_cols = ['sequence_id', 'sequence_counter', 'subject', 'gesture']\n",
    "raw_imu_cols = [c for c in all_raw_columns if c.startswith(('acc_', 'rot_'))]\n",
    "\n",
    "base_df = base_df.select(meta_cols + raw_imu_cols)\n",
    "print(f\"  Lean base DataFrame created with shape: {base_df.shape}\")\n",
    "\n",
    "print(\"  Performing label encoding...\")\n",
    "le = LabelEncoder()\n",
    "gesture_encoded = le.fit_transform(base_df.get_column('gesture'))\n",
    "base_df = base_df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "\n",
    "final_df = merge_feature_sets(base_df, feature_paths)\n",
    "print(f\"  Final merged DataFrame created with shape: {final_df.shape}\")\n",
    "\n",
    "# --- Step 4: Define FINAL Feature Columns for the Model ---\n",
    "all_final_columns = final_df.columns\n",
    "# Define all columns that are NOT features for the model\n",
    "final_meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                    'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "demographic_cols = {'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'}\n",
    "\n",
    "# This is the final list of columns to be scaled and fed to the model\n",
    "imu_cols = [c for c in all_final_columns if c not in final_meta_cols and c not in demographic_cols]\n",
    "imu_dim = len(imu_cols)\n",
    "print(f\"  Training with {imu_dim} final IMU features.\")    \n",
    "\n",
    "# --- Step 5: Prepare for Cross-Validation ---\n",
    "cv_info = final_df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "y_for_split = cv_info.get_column(\"gesture_int\").to_numpy()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "fold_accuracies = []\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids, y_for_split)):\n",
    "    print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} ===\")\n",
    "    train_ids = all_sequence_ids[train_indices]\n",
    "    val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "    # Filter the merged DataFrame for the current fold\n",
    "    train_df = final_df.filter(pl.col('sequence_id').is_in(train_ids))\n",
    "    val_df = final_df.filter(pl.col('sequence_id').is_in(val_ids))\n",
    "    print(\"Fold data loaded.\")\n",
    "\n",
    "    # Label encoding is already done, but we need the encoder for the final report\n",
    "    le = LabelEncoder().fit(train_df['gesture'])\n",
    "    \n",
    "    # --- StandardScaler Logic ---\n",
    "    scaler = StandardScaler()\n",
    "    train_features_scaled = scaler.fit_transform(train_df[imu_cols])\n",
    "    val_features_scaled = scaler.transform(val_df[imu_cols])\n",
    "    X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=imu_cols)\n",
    "    X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=imu_cols)\n",
    "\n",
    "    meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "    train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "    val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "    del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "    gc.collect()\n",
    "\n",
    "    # Create sequences (no gate target needed)\n",
    "    X_train, y_train = create_sequence_dataset_simple(train_df_final, imu_cols)\n",
    "    X_val, y_val = create_sequence_dataset_simple(val_df_final, imu_cols)\n",
    "\n",
    "    del train_df_final, val_df_final\n",
    "    gc.collect()\n",
    "\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "    X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "    \n",
    "    y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "    # Create simple TF Datasets (no generator needed unless you want mixup)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train_cat)).shuffle(len(X_train_padded)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, y_val_cat)).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    del X_train, y_train, X_val, y_val, X_train_padded, X_val_padded\n",
    "    gc.collect()\n",
    "    \n",
    "    # Use the new IMU-only model\n",
    "    model = create_model(train_dataset, imu_dim)\n",
    "    \n",
    "    # Adapt the train_model call for a single output\n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=LR_INIT, weight_decay=WD)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max')\n",
    "    model.fit(train_dataset, validation_data=val_dataset, epochs=150, callbacks=[early_stopping])\n",
    "    \n",
    "    # --- EVALUATION ---\n",
    "    print(\"--- Evaluating Fold ---\")\n",
    "    y_pred_proba = model.predict(val_dataset)\n",
    "    \n",
    "    # Get the class with the highest probability for each sample\n",
    "    y_pred_fold = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "    # Calculate and store the accuracy\n",
    "    fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "    fold_accuracies.append(fold_acc)\n",
    "    print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "\n",
    "    # Store predictions for the final report\n",
    "    all_preds.append(y_pred_fold)\n",
    "    all_labels.append(y_true_fold)\n",
    "\n",
    "    del train_dataset, model, val_dataset\n",
    "    gc.collect()\n",
    "\n",
    "# --- FINAL OOF REPORT ---\n",
    "print(\"\\n=== Cross-validation Summary ===\")\n",
    "print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "y_all_pred = np.concatenate(all_preds)\n",
    "y_all_true = np.concatenate(all_labels)\n",
    "print(\"\\n=== Overall Classification Report ===\")\n",
    "print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25490a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:51:55.346200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755096715.366656 1340056 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755096715.373338 1340056 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755096715.390761 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096715.390797 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096715.390799 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096715.390801 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-13 15:51:55.396405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building a lean base DataFrame with metadata and raw IMU columns...\n",
      "  Lean base DataFrame created with shape: (574945, 11)\n",
      "  Performing label encoding...\n",
      " Starting merge process...\n",
      "  Loading and joining features from: imu_physics_feats.parquet\n",
      "  Loading and joining features from: imu_cross_modal_features.parquet\n",
      "  Merge complete.\n",
      "  Final merged DataFrame created with shape: (574945, 34)\n",
      "  Training with 29 final IMU features.\n",
      "\n",
      "=== Fold 1/4 ===\n",
      "Fold data loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    unet_se_cnn,\n",
    "    features_processing, \n",
    "    GatedMixupGenerator, \n",
    "    tof_block, \n",
    "    match_time_steps, \n",
    "    time_sum, \n",
    "    squeeze_last_axis,\n",
    "    expand_last_axis,\n",
    "    crop_or_pad_output_shape\n",
    ")\n",
    "\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    create_sequence_dataset,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "from src.merge_feats_dynamic import merge_feature_sets\n",
    "\n",
    "# =====================================================================================\n",
    "# MASTER CONTROL FLAG\n",
    "# =====================================================================================\n",
    "TRAIN = False\n",
    "TRAIN = True \n",
    "\n",
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "PARQUET_FILE = 'output/final_model_input_dataset.parquet'\n",
    "# PARQUET_FILE = \"data/extended_features_df.parquet\"\n",
    "# PARQUET_FILE = 'output/kaggle_0.8_feats.parquet'\n",
    "PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "def create_sequence_dataset_simple(df: pl.DataFrame, feature_cols: list):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for seq_id, group in df.group_by('sequence_id', maintain_order=True):\n",
    "        sequences.append(group.select(feature_cols).to_numpy())\n",
    "        labels.append(group.select('gesture_int').item(0, 0))\n",
    "    return np.array(sequences, dtype=object), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION (Your existing function)\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    wave_block, residual_se_cnn_block, tof_block_2, attention_layer, wave_block, unet_se_cnn_bilstm\n",
    ")\n",
    "\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "\n",
    "    # x = unet_se_cnn_bilstm(imu, 128, 3)\n",
    "    x = unet_se_cnn_bilstm(imu, 64, 3)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = attention_layer(x) \n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "\n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    return tf.keras.models.Model(inputs=inp, outputs=main_out)\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "FEATURE_DIR = Path('output')\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "RANDOM_STATE = 42\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if TRAIN:\n",
    "    # --- Step 1: Define the feature sets to merge for this experiment ---\n",
    "    files_to_merge = [\n",
    "        \"imu_physics_feats.parquet\",\n",
    "        # \"imu_rolling_stats_features.parquet\",\n",
    "        \"imu_cross_modal_features.parquet\",\n",
    "    ]\n",
    "    feature_paths = [FEATURE_DIR / f for f in files_to_merge]\n",
    "    \n",
    "    # --- Step 2: Build a LEAN Base DataFrame ---\n",
    "    print(\"  Building a lean base DataFrame with metadata and raw IMU columns...\")\n",
    "    base_df = pl.read_parquet(FEATURE_DIR / \"cleaned_base_train_data.parquet\")\n",
    "    demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "    base_df = base_df.join(demographics_df, on='subject', how='left')\n",
    "\n",
    "    # --- THIS IS THE CRITICAL FIX, FOLLOWING YOUR INSTRUCTIONS ---\n",
    "    # 1. Define the exact columns to keep BEFORE the merge to save memory.\n",
    "    all_raw_columns = base_df.columns\n",
    "    # Metadata columns that are essential for the process\n",
    "    meta_cols = ['sequence_id', 'sequence_counter', 'subject', 'gesture']\n",
    "    # Raw IMU columns needed by the feature engineering functions\n",
    "    raw_imu_cols = [c for c in all_raw_columns if c.startswith(('acc_', 'rot_'))]\n",
    "    \n",
    "    # 2. Immediately narrow the DataFrame. This drops all raw ToF/Thm columns.\n",
    "    base_df = base_df.select(meta_cols + raw_imu_cols)\n",
    "    print(f\"  Lean base DataFrame created with shape: {base_df.shape}\")\n",
    "\n",
    "    # 3. Perform Label Encoding on the lean DataFrame.\n",
    "    print(\"  Performing label encoding...\")\n",
    "    le = LabelEncoder()\n",
    "    gesture_encoded = le.fit_transform(base_df.get_column('gesture'))\n",
    "    base_df = base_df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "\n",
    "    # --- Step 3: Run the merge function ---\n",
    "    final_df = merge_feature_sets(base_df, feature_paths)\n",
    "    print(f\"  Final merged DataFrame created with shape: {final_df.shape}\")\n",
    "\n",
    "    # --- Step 4: Define FINAL Feature Columns for the Model ---\n",
    "    all_final_columns = final_df.columns\n",
    "    # Define all columns that are NOT features for the model\n",
    "    final_meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                       'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "    demographic_cols = {'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'}\n",
    "    \n",
    "    # This is the final list of columns to be scaled and fed to the model\n",
    "    imu_cols = [c for c in all_final_columns if c not in final_meta_cols and c not in demographic_cols]\n",
    "    imu_dim = len(imu_cols)\n",
    "    print(f\"  Training with {imu_dim} final IMU features.\")    \n",
    "\n",
    "    # --- Step 5: Prepare for Cross-Validation ---\n",
    "    cv_info = final_df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "    all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "    y_for_split = cv_info.get_column(\"gesture_int\").to_numpy()\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids, y_for_split)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        # Filter the merged DataFrame for the current fold\n",
    "        train_df = final_df.filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = final_df.filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        print(\"Fold data loaded.\")\n",
    "\n",
    "        # Label encoding is already done, but we need the encoder for the final report\n",
    "        le = LabelEncoder().fit(train_df['gesture'])\n",
    "        \n",
    "        # --- StandardScaler Logic ---\n",
    "        scaler = StandardScaler()\n",
    "        train_features_scaled = scaler.fit_transform(train_df[imu_cols])\n",
    "        val_features_scaled = scaler.transform(val_df[imu_cols])\n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=imu_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=imu_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "        gc.collect()\n",
    "\n",
    "        # Create sequences (no gate target needed)\n",
    "        X_train, y_train = create_sequence_dataset_simple(train_df_final, imu_cols)\n",
    "        X_val, y_val = create_sequence_dataset_simple(val_df_final, imu_cols)\n",
    "\n",
    "        del train_df_final, val_df_final\n",
    "        gc.collect()\n",
    "\n",
    "        X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Create simple TF Datasets (no generator needed unless you want mixup)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train_cat)).shuffle(len(X_train_padded)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, y_val_cat)).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        del X_train, y_train, X_val, y_val, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        # Use the new IMU-only model\n",
    "        model = create_model(train_dataset, imu_dim)\n",
    "        \n",
    "        # Adapt the train_model call for a single output\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=LR_INIT, weight_decay=WD)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max')\n",
    "        model.fit(train_dataset, validation_data=val_dataset, epochs=150, callbacks=[early_stopping])\n",
    "        \n",
    "        # --- EVALUATION ---\n",
    "        print(\"--- Evaluating Fold ---\")\n",
    "        y_pred_proba = model.predict(val_dataset)\n",
    "        \n",
    "        # Get the class with the highest probability for each sample\n",
    "        y_pred_fold = np.argmax(y_pred_proba, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "        # Calculate and store the accuracy\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "\n",
    "        # Store predictions for the final report\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT ---\n",
    "    print(\"\\n=== Cross-validation Summary ===\")\n",
    "    print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:51:55.346200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755096715.366656 1340056 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755096715.373338 1340056 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755096715.390761 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096715.390797 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096715.390799 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096715.390801 1340056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-13 15:51:55.396405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building a lean base DataFrame with metadata and raw IMU columns...\n",
      "  Lean base DataFrame created with shape: (574945, 11)\n",
      "  Performing label encoding...\n",
      " Starting merge process...\n",
      "  Loading and joining features from: imu_physics_feats.parquet\n",
      "  Loading and joining features from: imu_cross_modal_features.parquet\n",
      "  Merge complete.\n",
      "  Final merged DataFrame created with shape: (574945, 34)\n",
      "  Training with 29 final IMU features.\n",
      "\n",
      "=== Fold 1/4 ===\n",
      "Fold data loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    unet_se_cnn,\n",
    "    features_processing, \n",
    "    GatedMixupGenerator, \n",
    "    tof_block, \n",
    "    match_time_steps, \n",
    "    time_sum, \n",
    "    squeeze_last_axis,\n",
    "    expand_last_axis,\n",
    "    crop_or_pad_output_shape\n",
    ")\n",
    "\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    create_sequence_dataset,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "from src.merge_feats_dynamic import merge_feature_sets\n",
    "\n",
    "# =====================================================================================\n",
    "# MASTER CONTROL FLAG\n",
    "# =====================================================================================\n",
    "TRAIN = False\n",
    "TRAIN = True \n",
    "\n",
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "PARQUET_FILE = 'output/final_model_input_dataset.parquet'\n",
    "# PARQUET_FILE = \"data/extended_features_df.parquet\"\n",
    "# PARQUET_FILE = 'output/kaggle_0.8_feats.parquet'\n",
    "PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "def create_sequence_dataset_simple(df: pl.DataFrame, feature_cols: list):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for seq_id, group in df.group_by('sequence_id', maintain_order=True):\n",
    "        sequences.append(group.select(feature_cols).to_numpy())\n",
    "        labels.append(group.select('gesture_int').item(0, 0))\n",
    "    return np.array(sequences, dtype=object), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION (Your existing function)\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    wave_block, residual_se_cnn_block, tof_block_2, attention_layer, wave_block, unet_se_cnn_bilstm\n",
    ")\n",
    "\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "\n",
    "    # x = unet_se_cnn_bilstm(imu, 128, 3)\n",
    "    x = unet_se_cnn_bilstm(imu, 64, 3)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = unet_se_cnn_bilstm(x, 64, 3)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = attention_layer(x) \n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "\n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    return tf.keras.models.Model(inputs=inp, outputs=main_out)\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "FEATURE_DIR = Path('output')\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "RANDOM_STATE = 42\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if TRAIN:\n",
    "    # --- Step 1: Define the feature sets to merge for this experiment ---\n",
    "    files_to_merge = [\n",
    "        \"imu_physics_feats.parquet\",\n",
    "        # \"imu_rolling_stats_features.parquet\",\n",
    "        \"imu_cross_modal_features.parquet\",\n",
    "    ]\n",
    "    feature_paths = [FEATURE_DIR / f for f in files_to_merge]\n",
    "    \n",
    "    # --- Step 2: Build a LEAN Base DataFrame ---\n",
    "    print(\"  Building a lean base DataFrame with metadata and raw IMU columns...\")\n",
    "    base_df = pl.read_parquet(FEATURE_DIR / \"cleaned_base_train_data.parquet\")\n",
    "    demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "    base_df = base_df.join(demographics_df, on='subject', how='left')\n",
    "\n",
    "    # --- THIS IS THE CRITICAL FIX, FOLLOWING YOUR INSTRUCTIONS ---\n",
    "    # 1. Define the exact columns to keep BEFORE the merge to save memory.\n",
    "    all_raw_columns = base_df.columns\n",
    "    # Metadata columns that are essential for the process\n",
    "    meta_cols = ['sequence_id', 'sequence_counter', 'subject', 'gesture']\n",
    "    # Raw IMU columns needed by the feature engineering functions\n",
    "    raw_imu_cols = [c for c in all_raw_columns if c.startswith(('acc_', 'rot_'))]\n",
    "    \n",
    "    # 2. Immediately narrow the DataFrame. This drops all raw ToF/Thm columns.\n",
    "    base_df = base_df.select(meta_cols + raw_imu_cols)\n",
    "    print(f\"  Lean base DataFrame created with shape: {base_df.shape}\")\n",
    "\n",
    "    # 3. Perform Label Encoding on the lean DataFrame.\n",
    "    print(\"  Performing label encoding...\")\n",
    "    le = LabelEncoder()\n",
    "    gesture_encoded = le.fit_transform(base_df.get_column('gesture'))\n",
    "    base_df = base_df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "\n",
    "    # --- Step 3: Run the merge function ---\n",
    "    final_df = merge_feature_sets(base_df, feature_paths)\n",
    "    print(f\"  Final merged DataFrame created with shape: {final_df.shape}\")\n",
    "\n",
    "    # --- Step 4: Define FINAL Feature Columns for the Model ---\n",
    "    all_final_columns = final_df.columns\n",
    "    # Define all columns that are NOT features for the model\n",
    "    final_meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                       'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "    demographic_cols = {'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'}\n",
    "    \n",
    "    # This is the final list of columns to be scaled and fed to the model\n",
    "    imu_cols = [c for c in all_final_columns if c not in final_meta_cols and c not in demographic_cols]\n",
    "    imu_dim = len(imu_cols)\n",
    "    print(f\"  Training with {imu_dim} final IMU features.\")    \n",
    "\n",
    "    # --- Step 5: Prepare for Cross-Validation ---\n",
    "    cv_info = final_df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "    all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "    y_for_split = cv_info.get_column(\"gesture_int\").to_numpy()\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids, y_for_split)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        # Filter the merged DataFrame for the current fold\n",
    "        train_df = final_df.filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = final_df.filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        print(\"Fold data loaded.\")\n",
    "\n",
    "        # Label encoding is already done, but we need the encoder for the final report\n",
    "        le = LabelEncoder().fit(train_df['gesture'])\n",
    "        \n",
    "        # --- StandardScaler Logic ---\n",
    "        scaler = StandardScaler()\n",
    "        train_features_scaled = scaler.fit_transform(train_df[imu_cols])\n",
    "        val_features_scaled = scaler.transform(val_df[imu_cols])\n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=imu_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=imu_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "        gc.collect()\n",
    "\n",
    "        # Create sequences (no gate target needed)\n",
    "        X_train, y_train = create_sequence_dataset_simple(train_df_final, imu_cols)\n",
    "        X_val, y_val = create_sequence_dataset_simple(val_df_final, imu_cols)\n",
    "\n",
    "        del train_df_final, val_df_final\n",
    "        gc.collect()\n",
    "\n",
    "        X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Create simple TF Datasets (no generator needed unless you want mixup)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train_cat)).shuffle(len(X_train_padded)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, y_val_cat)).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        del X_train, y_train, X_val, y_val, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        # Use the new IMU-only model\n",
    "        model = create_model(train_dataset, imu_dim)\n",
    "        \n",
    "        # Adapt the train_model call for a single output\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=LR_INIT, weight_decay=WD)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max')\n",
    "        model.fit(train_dataset, validation_data=val_dataset, epochs=150, callbacks=[early_stopping])\n",
    "        \n",
    "        # --- EVALUATION ---\n",
    "        print(\"--- Evaluating Fold ---\")\n",
    "        y_pred_proba = model.predict(val_dataset)\n",
    "        \n",
    "        # Get the class with the highest probability for each sample\n",
    "        y_pred_fold = np.argmax(y_pred_proba, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "        # Calculate and store the accuracy\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "\n",
    "        # Store predictions for the final report\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT ---\n",
    "    print(\"\\n=== Cross-validation Summary ===\")\n",
    "    print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # =====================================================================================\n",
    "# # --- INFERENCE & LOCAL DEBUGGING SCRIPT ---\n",
    "# # =====================================================================================\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# import traceback\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# import os\n",
    "# import gc\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import polars as pl\n",
    "# import tensorflow as tf\n",
    "# from pathlib import Path\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "# from tensorflow import argmax, minimum, shape\n",
    "\n",
    "# # --- Your existing function imports ---\n",
    "# from src.nn_blocks import (\n",
    "#     unet_se_cnn,\n",
    "#     features_processing, \n",
    "#     GatedMixupGenerator, \n",
    "#     tof_block, \n",
    "#     match_time_steps, \n",
    "#     time_sum, \n",
    "#     squeeze_last_axis,\n",
    "#     expand_last_axis,\n",
    "#     crop_or_pad_output_shape\n",
    "# )\n",
    "\n",
    "# from src.functions import (\n",
    "#     train_model, \n",
    "#     create_sequence_dataset,\n",
    "#     perform_padding,\n",
    "#     generate_gate_targets\n",
    "# )\n",
    "# from src.constants import DATA_PATH\n",
    "# from src.tof_feats import remove_gravity_from_acc, calculate_angular_velocity_from_quat, calculate_angular_distance\n",
    "\n",
    "# def crop_or_pad(inputs):\n",
    "#     x, skip = inputs\n",
    "#     x_len = shape(x)[1]\n",
    "#     skip_len = shape(skip)[1]\n",
    "#     min_len = minimum(x_len, skip_len)\n",
    "#     return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MASTER CONTROL FLAG\n",
    "# # =====================================================================================\n",
    "# TRAIN = True \n",
    "# TRAIN = False\n",
    "\n",
    "# # =====================================================================================\n",
    "# # CONFIGURATION\n",
    "# # =====================================================================================\n",
    "# PARQUET_FILE = 'output/final_processed_train_data.parquet'\n",
    "# PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "# PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "# LR_INIT = 5e-4\n",
    "# WD = 3e-3\n",
    "# NUM_CLASSES = 18\n",
    "# BATCH_SIZE = 64\n",
    "# N_SPLITS = 4 \n",
    "# MAX_PAD_LEN = 128\n",
    "\n",
    "# # --- 2. Define TTA Parameters and Predict Function ---\n",
    "# TTA_STEPS = 10\n",
    "# TTA_NOISE_STDDEV = 0.01\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MODEL DEFINITION (Your existing function)\n",
    "# # =====================================================================================\n",
    "# def create_model(dataset, imu_dim, wd=1e-4):\n",
    "#     sample_batch = next(iter(dataset))\n",
    "#     input_shape = sample_batch[0].shape[1:]\n",
    "#     inp = tf.keras.layers.Input(shape=input_shape)\n",
    "#     imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "#     tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "#     x1 = unet_se_cnn(imu, 3, base_filters=64, kernel_size=3)\n",
    "#     x2 = tof_block(tof, wd)\n",
    "\n",
    "#     x = features_processing(x1, x2)\n",
    "#     x = tf.keras.layers.Dropout(0.3)(x) \n",
    "#     main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "#     gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "#     return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# # --- 1. Load All Inference Artifacts ---\n",
    "# print(\"▶ LOCAL DEBUG MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "# try:\n",
    "#     final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "#     pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "#     scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "#     gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "#     models = []\n",
    "#     print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "#     for fold in range(N_SPLITS):\n",
    "#         model_path = PRETRAINED_DIR / f\"gesture_model_fold_{fold}.h5\"\n",
    "#         model = load_model(model_path, compile=False, custom_objects={\n",
    "#             'unet_se_cnn': unet_se_cnn,\n",
    "#             'tof_block': tof_block,\n",
    "#             'features_processing': features_processing,\n",
    "#             'match_time_steps': match_time_steps,\n",
    "#             'crop_or_pad': crop_or_pad,\n",
    "#             'squeeze_last_axis': squeeze_last_axis,\n",
    "#             'expand_last_axis': expand_last_axis,\n",
    "#             'time_sum': time_sum,\n",
    "#             'crop_or_pad_output_shape': crop_or_pad_output_shape\n",
    "#         })\n",
    "#         models.append(model)\n",
    "#     print(\"  Models, scaler, and metadata loaded.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"ERROR loading artifacts: {e}\")\n",
    "#     # Stop execution if artifacts can't be loaded\n",
    "#     exit()\n",
    "\n",
    "# # --- 2. Define the Predict Function (Using the most robust version) ---\n",
    "# def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#     # ... (All your feature engineering code is correct and can remain the same) ...\n",
    "#     df_seq = sequence.to_pandas()\n",
    "#     # ... (Sanitization, feature creation, scaling, padding) ...\n",
    "#     sensor_cols = [c for c in df_seq.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "#     for col in sensor_cols:\n",
    "#         if df_seq[col].dtype == 'object':\n",
    "#             df_seq[col] = pd.to_numeric(df_seq[col], errors='coerce')\n",
    "#     new_features = {}\n",
    "#     linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "#     new_features['linear_acc_x'] = linear_accel[:, 0]\n",
    "#     new_features['linear_acc_y'] = linear_accel[:, 1]\n",
    "#     new_features['linear_acc_z'] = linear_accel[:, 2]\n",
    "#     linear_acc_mag = np.sqrt(np.square(linear_accel).sum(axis=1))\n",
    "#     new_features['linear_acc_mag'] = linear_acc_mag\n",
    "#     new_features['linear_acc_mag_jerk'] = pd.Series(linear_acc_mag).diff().fillna(0).values\n",
    "#     angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "#     new_features['angular_vel_x'] = angular_vel[:, 0]\n",
    "#     new_features['angular_vel_y'] = angular_vel[:, 1]\n",
    "#     new_features['angular_vel_z'] = angular_vel[:, 2]\n",
    "#     new_features['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "#         tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "#         new_features[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "#         new_features[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "#         new_features[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "#         new_features[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "#     df_seq = df_seq.assign(**new_features)\n",
    "#     mat_unscaled_df = df_seq[final_feature_cols].ffill().bfill().fillna(0)\n",
    "#     mat_scaled = scaler.transform(mat_unscaled_df)\n",
    "#     pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "#     # --- TTA Loop ---\n",
    "#     all_tta_predictions = []\n",
    "#     for i in range(TTA_STEPS):\n",
    "#         noisy_input = pad_input\n",
    "#         if i > 0:\n",
    "#             noise = tf.random.normal(shape=tf.shape(pad_input), mean=0.0, stddev=TTA_NOISE_STDDEV)\n",
    "#             noisy_input = pad_input + noise\n",
    "\n",
    "#         # Ensemble predictions from all fold models\n",
    "#         all_fold_predictions = []\n",
    "#         for model in models:\n",
    "            \n",
    "#             # =========================================================================\n",
    "#             # --- THE FINAL FIX IS HERE ---\n",
    "#             # =========================================================================\n",
    "#             # model.predict returns a dictionary, access the 'main_output' key\n",
    "#             predictions_dict = model.predict(noisy_input, verbose=0)\n",
    "#             main_preds = predictions_dict['main_output']\n",
    "            \n",
    "#             all_fold_predictions.append(main_preds)\n",
    "        \n",
    "#         avg_fold_prediction = np.mean(all_fold_predictions, axis=0)\n",
    "#         all_tta_predictions.append(avg_fold_prediction)\n",
    "\n",
    "#     # --- Final Averaging and Prediction (Unchanged) ---\n",
    "#     final_avg_prediction = np.mean(all_tta_predictions, axis=0)\n",
    "#     idx = int(final_avg_prediction.argmax())\n",
    "    \n",
    "#     return str(gesture_classes[idx])\n",
    "\n",
    "# # =====================================================================================\n",
    "# # --- LOCAL TEST HARNESS ---\n",
    "# # =====================================================================================\n",
    "# print(\"\\n--- Starting Local Test ---\")\n",
    "\n",
    "# # Load the actual test data\n",
    "# TEST_CSV_PATH = 'input/cmi-detect-behavior-with-sensor-data/test.csv'\n",
    "# TEST_DEM_PATH = 'input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n",
    "\n",
    "# try:\n",
    "#     test_df = pl.read_csv(TEST_CSV_PATH)\n",
    "#     test_dem_df = pl.read_csv(TEST_DEM_PATH)\n",
    "    \n",
    "#     # Pick the first sequence from the test set\n",
    "#     target_sequence_id = test_df.get_column(\"sequence_id\").unique()[0]\n",
    "#     print(f\"Testing with sequence_id: {target_sequence_id}\")\n",
    "    \n",
    "#     # Isolate the data for that single sequence\n",
    "#     sample_sequence_pl = test_df.filter(pl.col(\"sequence_id\") == target_sequence_id)\n",
    "    \n",
    "#     # Find the corresponding subject and their demographics\n",
    "#     subject_id = sample_sequence_pl.get_column(\"subject\")[0]\n",
    "#     sample_demographics_pl = test_dem_df.filter(pl.col(\"subject\") == subject_id)\n",
    "    \n",
    "#     # --- Call the predict function directly and catch the REAL error ---\n",
    "#     print(\"\\nCalling predict function directly...\")\n",
    "#     predicted_gesture = predict(sample_sequence_pl, sample_demographics_pl)\n",
    "    \n",
    "#     print(\"\\n✅ SUCCESS! The function ran without errors on a sample.\")\n",
    "#     print(f\"Predicted Gesture: {predicted_gesture}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"\\n❌ ERROR! The function failed. Here is the full Python traceback:\")\n",
    "#     traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
