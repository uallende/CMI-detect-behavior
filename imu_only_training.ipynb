{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea175bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building a lean base DataFrame with metadata and raw IMU columns...\n",
      "  Lean base DataFrame created with shape: (574945, 11)\n",
      "  Performing label encoding...\n",
      " Starting merge process...\n",
      "  Loading and joining features from: imu_physics_feats.parquet\n",
      "  Merge complete.\n",
      "  Final merged DataFrame created with shape: (574945, 32)\n",
      "  Training with 27 final IMU features.\n",
      "\n",
      "=== Fold 1/4 ===\n",
      "Fold data loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755000657.235487  900300 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755000672.761059  900568 service.cc:152] XLA service 0x7e4cd0005270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755000672.761107  900568 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n",
      "2025-08-12 13:11:13.255206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755000675.392422  900568 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-12 13:11:19.758378: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:19.884405: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:20.169437: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:20.399187: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:20.604376: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:20.825561: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 10.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:20.904669: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:20.982664: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 12.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:22.104581: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-12 13:11:23.079437: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/96\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.0556 - loss: 3.3639  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755000696.169763  900568 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 347ms/step - accuracy: 0.1267 - loss: 3.0998 - val_accuracy: 0.2134 - val_loss: 2.7073\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.2389 - loss: 2.4784 - val_accuracy: 0.2969 - val_loss: 2.2885\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.3003 - loss: 2.2262 - val_accuracy: 0.3430 - val_loss: 2.0497\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.3497 - loss: 2.0368 - val_accuracy: 0.3832 - val_loss: 1.9248\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.3911 - loss: 1.8910 - val_accuracy: 0.4338 - val_loss: 1.7291\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.4244 - loss: 1.7565 - val_accuracy: 0.4490 - val_loss: 1.6352\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.4593 - loss: 1.6704 - val_accuracy: 0.4907 - val_loss: 1.5647\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.4769 - loss: 1.6254 - val_accuracy: 0.4799 - val_loss: 1.5713\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.4828 - loss: 1.5469 - val_accuracy: 0.5059 - val_loss: 1.5112\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.5051 - loss: 1.5067 - val_accuracy: 0.5186 - val_loss: 1.4636\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.5297 - loss: 1.4377 - val_accuracy: 0.5348 - val_loss: 1.4132\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5392 - loss: 1.4222 - val_accuracy: 0.5388 - val_loss: 1.3809\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.5396 - loss: 1.3907 - val_accuracy: 0.5299 - val_loss: 1.4201\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.5537 - loss: 1.3360 - val_accuracy: 0.5564 - val_loss: 1.3738\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.5723 - loss: 1.3324 - val_accuracy: 0.5476 - val_loss: 1.3473\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.5742 - loss: 1.2976 - val_accuracy: 0.5432 - val_loss: 1.3476\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5835 - loss: 1.2702 - val_accuracy: 0.5584 - val_loss: 1.3336\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5840 - loss: 1.2476 - val_accuracy: 0.5554 - val_loss: 1.3178\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6029 - loss: 1.2216 - val_accuracy: 0.5824 - val_loss: 1.2808\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6047 - loss: 1.2070 - val_accuracy: 0.5599 - val_loss: 1.3546\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6103 - loss: 1.1892 - val_accuracy: 0.5927 - val_loss: 1.2244\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6131 - loss: 1.1457 - val_accuracy: 0.5800 - val_loss: 1.2819\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.6239 - loss: 1.1441 - val_accuracy: 0.5859 - val_loss: 1.2599\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6491 - loss: 1.0931 - val_accuracy: 0.5888 - val_loss: 1.2326\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.6293 - loss: 1.0895 - val_accuracy: 0.5864 - val_loss: 1.2488\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6439 - loss: 1.0721 - val_accuracy: 0.6011 - val_loss: 1.2280\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6534 - loss: 1.0343 - val_accuracy: 0.6104 - val_loss: 1.2302\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6627 - loss: 1.0235 - val_accuracy: 0.6026 - val_loss: 1.2117\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6709 - loss: 1.0029 - val_accuracy: 0.5986 - val_loss: 1.2072\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6670 - loss: 1.0133 - val_accuracy: 0.6104 - val_loss: 1.1771\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6849 - loss: 0.9749 - val_accuracy: 0.5898 - val_loss: 1.2470\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6734 - loss: 0.9955 - val_accuracy: 0.6001 - val_loss: 1.1953\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6947 - loss: 0.9558 - val_accuracy: 0.6040 - val_loss: 1.1901\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6928 - loss: 0.9311 - val_accuracy: 0.6251 - val_loss: 1.1671\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7063 - loss: 0.9214 - val_accuracy: 0.6207 - val_loss: 1.1685\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.6918 - loss: 0.9327 - val_accuracy: 0.6079 - val_loss: 1.2139\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6957 - loss: 0.9324 - val_accuracy: 0.6178 - val_loss: 1.2117\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7148 - loss: 0.8696 - val_accuracy: 0.6202 - val_loss: 1.1668\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7186 - loss: 0.8687 - val_accuracy: 0.6452 - val_loss: 1.1689\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7225 - loss: 0.8727 - val_accuracy: 0.5922 - val_loss: 1.4701\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7339 - loss: 0.8396 - val_accuracy: 0.6266 - val_loss: 1.1727\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7248 - loss: 0.8609 - val_accuracy: 0.6158 - val_loss: 1.2234\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7334 - loss: 0.8318 - val_accuracy: 0.6261 - val_loss: 1.2431\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7352 - loss: 0.8241 - val_accuracy: 0.6305 - val_loss: 1.2357\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7560 - loss: 0.7912 - val_accuracy: 0.6354 - val_loss: 1.1810\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7579 - loss: 0.7601 - val_accuracy: 0.6281 - val_loss: 1.2463\n",
      "Epoch 47/150\n",
      "\u001b[1m 1/96\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7656 - loss: 0.7242"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    unet_se_cnn,\n",
    "    features_processing, \n",
    "    GatedMixupGenerator, \n",
    "    tof_block, \n",
    "    match_time_steps, \n",
    "    time_sum, \n",
    "    squeeze_last_axis,\n",
    "    expand_last_axis,\n",
    "    crop_or_pad_output_shape\n",
    ")\n",
    "\n",
    "from src.functions import (\n",
    "    train_model, \n",
    "    create_sequence_dataset,\n",
    "    perform_padding,\n",
    "    generate_gate_targets\n",
    ")\n",
    "\n",
    "from src.merge_feats_dynamic import merge_feature_sets\n",
    "\n",
    "# =====================================================================================\n",
    "# MASTER CONTROL FLAG\n",
    "# =====================================================================================\n",
    "TRAIN = False\n",
    "TRAIN = True \n",
    "\n",
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "PARQUET_FILE = 'output/final_model_input_dataset.parquet'\n",
    "# PARQUET_FILE = \"data/extended_features_df.parquet\"\n",
    "# PARQUET_FILE = 'output/kaggle_0.8_feats.parquet'\n",
    "PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 4 \n",
    "MAX_PAD_LEN = 128\n",
    "\n",
    "def create_sequence_dataset_simple(df: pl.DataFrame, feature_cols: list):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for seq_id, group in df.group_by('sequence_id', maintain_order=True):\n",
    "        sequences.append(group.select(feature_cols).to_numpy())\n",
    "        labels.append(group.select('gesture_int').item(0, 0))\n",
    "    return np.array(sequences, dtype=object), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# MODEL DEFINITION (Your existing function)\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import (\n",
    "    wave_block, residual_se_cnn_block, tof_block_2, attention_layer\n",
    ")\n",
    "\n",
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "\n",
    "    x = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3)\n",
    "    x = attention_layer(x) # Assuming attention_layer is defined \n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "\n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    return tf.keras.models.Model(inputs=inp, outputs=main_out)\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "FEATURE_DIR = Path('output')\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "RANDOM_STATE = 42\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if TRAIN:\n",
    "    # --- Step 1: Define the feature sets to merge for this experiment ---\n",
    "    files_to_merge = [\n",
    "        \"imu_physics_feats.parquet\",\n",
    "        # \"imu_rolling_stats_features.parquet\",\n",
    "        # \"imu_cross_modal_features.parquet\",\n",
    "    ]\n",
    "    feature_paths = [FEATURE_DIR / f for f in files_to_merge]\n",
    "    \n",
    "    # --- Step 2: Build a LEAN Base DataFrame ---\n",
    "    print(\"  Building a lean base DataFrame with metadata and raw IMU columns...\")\n",
    "    base_df = pl.read_parquet(FEATURE_DIR / \"cleaned_base_train_data.parquet\")\n",
    "    demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "    base_df = base_df.join(demographics_df, on='subject', how='left')\n",
    "\n",
    "    # --- THIS IS THE CRITICAL FIX, FOLLOWING YOUR INSTRUCTIONS ---\n",
    "    # 1. Define the exact columns to keep BEFORE the merge to save memory.\n",
    "    all_raw_columns = base_df.columns\n",
    "    # Metadata columns that are essential for the process\n",
    "    meta_cols = ['sequence_id', 'sequence_counter', 'subject', 'gesture']\n",
    "    # Raw IMU columns needed by the feature engineering functions\n",
    "    raw_imu_cols = [c for c in all_raw_columns if c.startswith(('acc_', 'rot_'))]\n",
    "    \n",
    "    # 2. Immediately narrow the DataFrame. This drops all raw ToF/Thm columns.\n",
    "    base_df = base_df.select(meta_cols + raw_imu_cols)\n",
    "    print(f\"  Lean base DataFrame created with shape: {base_df.shape}\")\n",
    "\n",
    "    # 3. Perform Label Encoding on the lean DataFrame.\n",
    "    print(\"  Performing label encoding...\")\n",
    "    le = LabelEncoder()\n",
    "    gesture_encoded = le.fit_transform(base_df.get_column('gesture'))\n",
    "    base_df = base_df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "\n",
    "    # --- Step 3: Run the merge function ---\n",
    "    final_df = merge_feature_sets(base_df, feature_paths)\n",
    "    print(f\"  Final merged DataFrame created with shape: {final_df.shape}\")\n",
    "\n",
    "    # --- Step 4: Define FINAL Feature Columns for the Model ---\n",
    "    all_final_columns = final_df.columns\n",
    "    # Define all columns that are NOT features for the model\n",
    "    final_meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                       'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "    demographic_cols = {'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'}\n",
    "    \n",
    "    # This is the final list of columns to be scaled and fed to the model\n",
    "    imu_cols = [c for c in all_final_columns if c not in final_meta_cols and c not in demographic_cols]\n",
    "    imu_dim = len(imu_cols)\n",
    "    print(f\"  Training with {imu_dim} final IMU features.\")    \n",
    "\n",
    "    # --- Step 5: Prepare for Cross-Validation ---\n",
    "    cv_info = final_df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "    all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "    y_for_split = cv_info.get_column(\"gesture_int\").to_numpy()\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids, y_for_split)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        # Filter the merged DataFrame for the current fold\n",
    "        train_df = final_df.filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = final_df.filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        print(\"Fold data loaded.\")\n",
    "\n",
    "        # Label encoding is already done, but we need the encoder for the final report\n",
    "        le = LabelEncoder().fit(train_df['gesture'])\n",
    "        \n",
    "        # --- StandardScaler Logic ---\n",
    "        scaler = StandardScaler()\n",
    "        train_features_scaled = scaler.fit_transform(train_df[imu_cols])\n",
    "        val_features_scaled = scaler.transform(val_df[imu_cols])\n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=imu_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=imu_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        del train_df, val_df, X_train_scaled_features, X_val_scaled_features\n",
    "        gc.collect()\n",
    "\n",
    "        # Create sequences (no gate target needed)\n",
    "        X_train, y_train = create_sequence_dataset_simple(train_df_final, imu_cols)\n",
    "        X_val, y_val = create_sequence_dataset_simple(val_df_final, imu_cols)\n",
    "\n",
    "        del train_df_final, val_df_final\n",
    "        gc.collect()\n",
    "\n",
    "        X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Create simple TF Datasets (no generator needed unless you want mixup)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train_cat)).shuffle(len(X_train_padded)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, y_val_cat)).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        del X_train, y_train, X_val, y_val, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        # Use the new IMU-only model\n",
    "        model = create_model(train_dataset, imu_dim)\n",
    "        \n",
    "        # Adapt the train_model call for a single output\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=LR_INIT, weight_decay=WD)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max')\n",
    "        model.fit(train_dataset, validation_data=val_dataset, epochs=150, callbacks=[early_stopping])\n",
    "        \n",
    "        # --- EVALUATION ---\n",
    "        # The model now returns a single array, not a dictionary\n",
    "        y_pred_proba = model.predict(val_dataset)\n",
    "        y_pred_fold = np.argmax(y_pred_proba, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "        # --- EVALUATION ---\n",
    "        val_preds = model.predict(val_dataset)\n",
    "        main_output_preds = val_preds['main_output']\n",
    "        y_pred_fold = np.argmax(main_output_preds, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT ---\n",
    "    print(\"\\n=== Cross-validation Summary ===\")\n",
    "    print(f\"Per-fold Accuracies: {fold_accuracies}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30587df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m:\n\u001b[32m      2\u001b[39m     x = e[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m     y = e[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for e in train_dataset:\n",
    "    x = e[0]\n",
    "    y = e[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630baad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imu_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3ad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gesture</th><th>gesture_int</th><th>sequence_type</th><th>behavior</th><th>orientation</th><th>row_id</th><th>subject</th><th>phase</th><th>sequence_id</th><th>sequence_counter</th><th>acc_x</th><th>acc_y</th><th>acc_z</th><th>rot_w</th><th>rot_x</th><th>rot_y</th><th>rot_z</th><th>adult_child</th><th>age</th><th>sex</th><th>handedness</th><th>height_cm</th><th>shoulder_to_wrist_cm</th><th>elbow_to_wrist_cm</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Cheek - pinch skin&quot;</td><td>1</td><td>&quot;Target&quot;</td><td>&quot;Relaxes and moves hand to targ…</td><td>&quot;Seated Lean Non Dom - FACE DOW…</td><td>&quot;SEQ_000007_000000&quot;</td><td>&quot;SUBJ_059520&quot;</td><td>&quot;Transition&quot;</td><td>&quot;SEQ_000007&quot;</td><td>0</td><td>6.683594</td><td>6.214844</td><td>3.355469</td><td>0.134399</td><td>-0.355164</td><td>-0.447327</td><td>-0.809753</td><td>0</td><td>12</td><td>1</td><td>1</td><td>163.0</td><td>52</td><td>24.0</td></tr><tr><td>&quot;Cheek - pinch skin&quot;</td><td>1</td><td>&quot;Target&quot;</td><td>&quot;Relaxes and moves hand to targ…</td><td>&quot;Seated Lean Non Dom - FACE DOW…</td><td>&quot;SEQ_000007_000001&quot;</td><td>&quot;SUBJ_059520&quot;</td><td>&quot;Transition&quot;</td><td>&quot;SEQ_000007&quot;</td><td>1</td><td>6.949219</td><td>6.214844</td><td>3.125</td><td>0.143494</td><td>-0.340271</td><td>-0.42865</td><td>-0.824524</td><td>0</td><td>12</td><td>1</td><td>1</td><td>163.0</td><td>52</td><td>24.0</td></tr><tr><td>&quot;Cheek - pinch skin&quot;</td><td>1</td><td>&quot;Target&quot;</td><td>&quot;Relaxes and moves hand to targ…</td><td>&quot;Seated Lean Non Dom - FACE DOW…</td><td>&quot;SEQ_000007_000002&quot;</td><td>&quot;SUBJ_059520&quot;</td><td>&quot;Transition&quot;</td><td>&quot;SEQ_000007&quot;</td><td>2</td><td>5.722656</td><td>5.410156</td><td>5.421875</td><td>0.219055</td><td>-0.274231</td><td>-0.356934</td><td>-0.865662</td><td>0</td><td>12</td><td>1</td><td>1</td><td>163.0</td><td>52</td><td>24.0</td></tr><tr><td>&quot;Cheek - pinch skin&quot;</td><td>1</td><td>&quot;Target&quot;</td><td>&quot;Relaxes and moves hand to targ…</td><td>&quot;Seated Lean Non Dom - FACE DOW…</td><td>&quot;SEQ_000007_000003&quot;</td><td>&quot;SUBJ_059520&quot;</td><td>&quot;Transition&quot;</td><td>&quot;SEQ_000007&quot;</td><td>3</td><td>6.6015625</td><td>3.53125</td><td>6.457031</td><td>0.297546</td><td>-0.26416</td><td>-0.238159</td><td>-0.885986</td><td>0</td><td>12</td><td>1</td><td>1</td><td>163.0</td><td>52</td><td>24.0</td></tr><tr><td>&quot;Cheek - pinch skin&quot;</td><td>1</td><td>&quot;Target&quot;</td><td>&quot;Relaxes and moves hand to targ…</td><td>&quot;Seated Lean Non Dom - FACE DOW…</td><td>&quot;SEQ_000007_000004&quot;</td><td>&quot;SUBJ_059520&quot;</td><td>&quot;Transition&quot;</td><td>&quot;SEQ_000007&quot;</td><td>4</td><td>5.566406</td><td>0.277344</td><td>9.6328125</td><td>0.333557</td><td>-0.218628</td><td>-0.063538</td><td>-0.914856</td><td>0</td><td>12</td><td>1</td><td>1</td><td>163.0</td><td>52</td><td>24.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 24)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ gesture   ┆ gesture_i ┆ sequence_ ┆ behavior  ┆ … ┆ handednes ┆ height_cm ┆ shoulder_ ┆ elbow_to │\n",
       "│ ---       ┆ nt        ┆ type      ┆ ---       ┆   ┆ s         ┆ ---       ┆ to_wrist_ ┆ _wrist_c │\n",
       "│ str       ┆ ---       ┆ ---       ┆ str       ┆   ┆ ---       ┆ f64       ┆ cm        ┆ m        │\n",
       "│           ┆ i64       ┆ str       ┆           ┆   ┆ i64       ┆           ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ i64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Cheek -   ┆ 1         ┆ Target    ┆ Relaxes   ┆ … ┆ 1         ┆ 163.0     ┆ 52        ┆ 24.0     │\n",
       "│ pinch     ┆           ┆           ┆ and moves ┆   ┆           ┆           ┆           ┆          │\n",
       "│ skin      ┆           ┆           ┆ hand to   ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ targ…     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Cheek -   ┆ 1         ┆ Target    ┆ Relaxes   ┆ … ┆ 1         ┆ 163.0     ┆ 52        ┆ 24.0     │\n",
       "│ pinch     ┆           ┆           ┆ and moves ┆   ┆           ┆           ┆           ┆          │\n",
       "│ skin      ┆           ┆           ┆ hand to   ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ targ…     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Cheek -   ┆ 1         ┆ Target    ┆ Relaxes   ┆ … ┆ 1         ┆ 163.0     ┆ 52        ┆ 24.0     │\n",
       "│ pinch     ┆           ┆           ┆ and moves ┆   ┆           ┆           ┆           ┆          │\n",
       "│ skin      ┆           ┆           ┆ hand to   ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ targ…     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Cheek -   ┆ 1         ┆ Target    ┆ Relaxes   ┆ … ┆ 1         ┆ 163.0     ┆ 52        ┆ 24.0     │\n",
       "│ pinch     ┆           ┆           ┆ and moves ┆   ┆           ┆           ┆           ┆          │\n",
       "│ skin      ┆           ┆           ┆ hand to   ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ targ…     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Cheek -   ┆ 1         ┆ Target    ┆ Relaxes   ┆ … ┆ 1         ┆ 163.0     ┆ 52        ┆ 24.0     │\n",
       "│ pinch     ┆           ┆           ┆ and moves ┆   ┆           ┆           ┆           ┆          │\n",
       "│ skin      ┆           ┆           ┆ hand to   ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ targ…     ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 38)\n"
     ]
    }
   ],
   "source": [
    "input_shape = x[0].shape\n",
    "inp = tf.keras.layers.Input(shape=input_shape)\n",
    "imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a87a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 32, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = 0\n",
    "# TOF/Thermal lighter branch\n",
    "x2 = tf.keras.layers.Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(wd))(tof)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "x2 = tf.keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(wd))(x2)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33df75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dataset, imu_dim, wd=1e-4):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    input_shape = sample_batch[0].shape[1:]\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU deep branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n",
    "\n",
    "    # TOF/Thermal lighter branch\n",
    "    x2 = tf.keras.layers.Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.layers.l2(wd))(tof)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=tf.keras.layers.l2(wd))(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2); x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(2)(x2); x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "\n",
    "    merged = tf.keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "    xa = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, kernel_regularizer=tf.keras.layers.l2(wd)))(merged)\n",
    "    xb = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=tf.keras.layers.l2(wd)))(merged)\n",
    "    xc = tf.keras.layers.GaussianNoise(0.09)(merged)\n",
    "    xc = tf.keras.layers.Dense(16, activation='elu')(xc)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([xa, xb, xc])\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = tf.keras.layers.Dense(units, use_bias=False, kernel_regularizer=tf.keras.layers.l2(wd))(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x); x = tf.keras.layers.Activation('relu')(x)\n",
    "        x = tf.keras.layers.Dropout(drop)(x)\n",
    "\n",
    "    main_out = tf.keras.layers.tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # =====================================================================================\n",
    "# # --- INFERENCE & LOCAL DEBUGGING SCRIPT ---\n",
    "# # =====================================================================================\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# import traceback\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# import os\n",
    "# import gc\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import polars as pl\n",
    "# import tensorflow as tf\n",
    "# from pathlib import Path\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "# from tensorflow import argmax, minimum, shape\n",
    "\n",
    "# # --- Your existing function imports ---\n",
    "# from src.nn_blocks import (\n",
    "#     unet_se_cnn,\n",
    "#     features_processing, \n",
    "#     GatedMixupGenerator, \n",
    "#     tof_block, \n",
    "#     match_time_steps, \n",
    "#     time_sum, \n",
    "#     squeeze_last_axis,\n",
    "#     expand_last_axis,\n",
    "#     crop_or_pad_output_shape\n",
    "# )\n",
    "\n",
    "# from src.functions import (\n",
    "#     train_model, \n",
    "#     create_sequence_dataset,\n",
    "#     perform_padding,\n",
    "#     generate_gate_targets\n",
    "# )\n",
    "# from src.constants import DATA_PATH\n",
    "# from src.tof_feats import remove_gravity_from_acc, calculate_angular_velocity_from_quat, calculate_angular_distance\n",
    "\n",
    "# def crop_or_pad(inputs):\n",
    "#     x, skip = inputs\n",
    "#     x_len = shape(x)[1]\n",
    "#     skip_len = shape(skip)[1]\n",
    "#     min_len = minimum(x_len, skip_len)\n",
    "#     return x[:, :min_len, :], skip[:, :min_len, :]\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MASTER CONTROL FLAG\n",
    "# # =====================================================================================\n",
    "# TRAIN = True \n",
    "# TRAIN = False\n",
    "\n",
    "# # =====================================================================================\n",
    "# # CONFIGURATION\n",
    "# # =====================================================================================\n",
    "# PARQUET_FILE = 'output/final_processed_train_data.parquet'\n",
    "# PRETRAINED_DIR = Path(\"output/artifacts\")\n",
    "# PRETRAINED_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "# LR_INIT = 5e-4\n",
    "# WD = 3e-3\n",
    "# NUM_CLASSES = 18\n",
    "# BATCH_SIZE = 64\n",
    "# N_SPLITS = 4 \n",
    "# MAX_PAD_LEN = 128\n",
    "\n",
    "# # --- 2. Define TTA Parameters and Predict Function ---\n",
    "# TTA_STEPS = 10\n",
    "# TTA_NOISE_STDDEV = 0.01\n",
    "\n",
    "# # =====================================================================================\n",
    "# # MODEL DEFINITION (Your existing function)\n",
    "# # =====================================================================================\n",
    "# def create_model(dataset, imu_dim, wd=1e-4):\n",
    "#     sample_batch = next(iter(dataset))\n",
    "#     input_shape = sample_batch[0].shape[1:]\n",
    "#     inp = tf.keras.layers.Input(shape=input_shape)\n",
    "#     imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "#     tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "#     x1 = unet_se_cnn(imu, 3, base_filters=64, kernel_size=3)\n",
    "#     x2 = tof_block(tof, wd)\n",
    "\n",
    "#     x = features_processing(x1, x2)\n",
    "#     x = tf.keras.layers.Dropout(0.3)(x) \n",
    "#     main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "#     gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x) # Renamed layer\n",
    "    \n",
    "#     return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# # --- 1. Load All Inference Artifacts ---\n",
    "# print(\"▶ LOCAL DEBUG MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "# try:\n",
    "#     final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "#     pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "#     scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "#     gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "#     models = []\n",
    "#     print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "#     for fold in range(N_SPLITS):\n",
    "#         model_path = PRETRAINED_DIR / f\"gesture_model_fold_{fold}.h5\"\n",
    "#         model = load_model(model_path, compile=False, custom_objects={\n",
    "#             'unet_se_cnn': unet_se_cnn,\n",
    "#             'tof_block': tof_block,\n",
    "#             'features_processing': features_processing,\n",
    "#             'match_time_steps': match_time_steps,\n",
    "#             'crop_or_pad': crop_or_pad,\n",
    "#             'squeeze_last_axis': squeeze_last_axis,\n",
    "#             'expand_last_axis': expand_last_axis,\n",
    "#             'time_sum': time_sum,\n",
    "#             'crop_or_pad_output_shape': crop_or_pad_output_shape\n",
    "#         })\n",
    "#         models.append(model)\n",
    "#     print(\"  Models, scaler, and metadata loaded.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"ERROR loading artifacts: {e}\")\n",
    "#     # Stop execution if artifacts can't be loaded\n",
    "#     exit()\n",
    "\n",
    "# # --- 2. Define the Predict Function (Using the most robust version) ---\n",
    "# def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#     # ... (All your feature engineering code is correct and can remain the same) ...\n",
    "#     df_seq = sequence.to_pandas()\n",
    "#     # ... (Sanitization, feature creation, scaling, padding) ...\n",
    "#     sensor_cols = [c for c in df_seq.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "#     for col in sensor_cols:\n",
    "#         if df_seq[col].dtype == 'object':\n",
    "#             df_seq[col] = pd.to_numeric(df_seq[col], errors='coerce')\n",
    "#     new_features = {}\n",
    "#     linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "#     new_features['linear_acc_x'] = linear_accel[:, 0]\n",
    "#     new_features['linear_acc_y'] = linear_accel[:, 1]\n",
    "#     new_features['linear_acc_z'] = linear_accel[:, 2]\n",
    "#     linear_acc_mag = np.sqrt(np.square(linear_accel).sum(axis=1))\n",
    "#     new_features['linear_acc_mag'] = linear_acc_mag\n",
    "#     new_features['linear_acc_mag_jerk'] = pd.Series(linear_acc_mag).diff().fillna(0).values\n",
    "#     angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "#     new_features['angular_vel_x'] = angular_vel[:, 0]\n",
    "#     new_features['angular_vel_y'] = angular_vel[:, 1]\n",
    "#     new_features['angular_vel_z'] = angular_vel[:, 2]\n",
    "#     new_features['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "#         tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "#         new_features[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "#         new_features[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "#         new_features[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "#         new_features[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "#     df_seq = df_seq.assign(**new_features)\n",
    "#     mat_unscaled_df = df_seq[final_feature_cols].ffill().bfill().fillna(0)\n",
    "#     mat_scaled = scaler.transform(mat_unscaled_df)\n",
    "#     pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "#     # --- TTA Loop ---\n",
    "#     all_tta_predictions = []\n",
    "#     for i in range(TTA_STEPS):\n",
    "#         noisy_input = pad_input\n",
    "#         if i > 0:\n",
    "#             noise = tf.random.normal(shape=tf.shape(pad_input), mean=0.0, stddev=TTA_NOISE_STDDEV)\n",
    "#             noisy_input = pad_input + noise\n",
    "\n",
    "#         # Ensemble predictions from all fold models\n",
    "#         all_fold_predictions = []\n",
    "#         for model in models:\n",
    "            \n",
    "#             # =========================================================================\n",
    "#             # --- THE FINAL FIX IS HERE ---\n",
    "#             # =========================================================================\n",
    "#             # model.predict returns a dictionary, access the 'main_output' key\n",
    "#             predictions_dict = model.predict(noisy_input, verbose=0)\n",
    "#             main_preds = predictions_dict['main_output']\n",
    "            \n",
    "#             all_fold_predictions.append(main_preds)\n",
    "        \n",
    "#         avg_fold_prediction = np.mean(all_fold_predictions, axis=0)\n",
    "#         all_tta_predictions.append(avg_fold_prediction)\n",
    "\n",
    "#     # --- Final Averaging and Prediction (Unchanged) ---\n",
    "#     final_avg_prediction = np.mean(all_tta_predictions, axis=0)\n",
    "#     idx = int(final_avg_prediction.argmax())\n",
    "    \n",
    "#     return str(gesture_classes[idx])\n",
    "\n",
    "# # =====================================================================================\n",
    "# # --- LOCAL TEST HARNESS ---\n",
    "# # =====================================================================================\n",
    "# print(\"\\n--- Starting Local Test ---\")\n",
    "\n",
    "# # Load the actual test data\n",
    "# TEST_CSV_PATH = 'input/cmi-detect-behavior-with-sensor-data/test.csv'\n",
    "# TEST_DEM_PATH = 'input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n",
    "\n",
    "# try:\n",
    "#     test_df = pl.read_csv(TEST_CSV_PATH)\n",
    "#     test_dem_df = pl.read_csv(TEST_DEM_PATH)\n",
    "    \n",
    "#     # Pick the first sequence from the test set\n",
    "#     target_sequence_id = test_df.get_column(\"sequence_id\").unique()[0]\n",
    "#     print(f\"Testing with sequence_id: {target_sequence_id}\")\n",
    "    \n",
    "#     # Isolate the data for that single sequence\n",
    "#     sample_sequence_pl = test_df.filter(pl.col(\"sequence_id\") == target_sequence_id)\n",
    "    \n",
    "#     # Find the corresponding subject and their demographics\n",
    "#     subject_id = sample_sequence_pl.get_column(\"subject\")[0]\n",
    "#     sample_demographics_pl = test_dem_df.filter(pl.col(\"subject\") == subject_id)\n",
    "    \n",
    "#     # --- Call the predict function directly and catch the REAL error ---\n",
    "#     print(\"\\nCalling predict function directly...\")\n",
    "#     predicted_gesture = predict(sample_sequence_pl, sample_demographics_pl)\n",
    "    \n",
    "#     print(\"\\n✅ SUCCESS! The function ran without errors on a sample.\")\n",
    "#     print(f\"Predicted Gesture: {predicted_gesture}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"\\n❌ ERROR! The function failed. Here is the full Python traceback:\")\n",
    "#     traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
