{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5a8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:45:42.812359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755981942.831419 4113464 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755981942.837283 4113464 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755981942.853367 4113464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755981942.853399 4113464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755981942.853401 4113464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755981942.853403 4113464 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-23 21:45:42.858623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow import shape, minimum\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import pad_sequences, Sequence, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate,\n",
    "    BatchNormalization, GRU, Dropout, add, Activation, Multiply, Reshape,\n",
    "    LayerNormalization, Add, Bidirectional, LSTM, UpSampling1D, Lambda, GaussianNoise, MultiHeadAttention\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from src.nn_blocks import tof_block, residual_se_cnn_block, TransformerBlock, tof_block_2, features_processing, unet_se_cnn\n",
    "\n",
    "NUM_CLASSES = 18\n",
    "\n",
    "\n",
    "# --- Gated Model 1: Based on CNN-RNN Hybrid ---\n",
    "def create_gated_cnn_rnn(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd) # Output: (None, 64, 64)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output: (None, 32, 128)\n",
    "    x1 = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(x1) # Output: (None, 32, 256)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "\n",
    "    # --- FIX: Project x2 to match x1's feature dimension before processing ---\n",
    "    x2_projected = Dense(256, activation='relu')(x2)\n",
    "\n",
    "    # Now both inputs to features_processing have shape (None, 32, 256)\n",
    "    x = features_processing(x1, x2_projected)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Gated Model 2: Based on UNet_Style ---\n",
    "def create_gated_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU branch\n",
    "    x1 = unet_se_cnn(imu, unet_depth=4, base_filters=64, kernel_size=5, drop=0.3) # Output: (None, 128, 64)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "\n",
    "    # We will use a simpler approach for this model.\n",
    "    x1_pooled = GlobalAveragePooling1D()(x1)\n",
    "    x2_pooled = GlobalAveragePooling1D()(x2)\n",
    "    x = Concatenate()([x1_pooled, x2_pooled])\n",
    "    \n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Gated Model 3: Based on CNN_Transformer ---\n",
    "def create_gated_cnn_transformer(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd) # Output: (None, 64, 64)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output: (None, 32, 128)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=128, rate=0.3)(x1) # Output: (None, 32, 128)\n",
    "    x1 = residual_se_cnn_block(x1, 64, 3, drop=0.2, wd=wd) # Output: (None, 16, 64)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output: (None, 8, 128)    \n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=128, rate=0.3)(x1) # Output: (None, 8, 128)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "    x2 = tf.keras.layers.MaxPooling1D(4)(x2)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def best_unet_1(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def best_unet_2(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = unet_se_cnn(imu, 3, base_filters=128, kernel_size=3)\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x) \n",
    "    main_out = tf.keras.layers.Dense(18, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b248ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# 5 NEW ADVANCED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "\n",
    "from src.nn_blocks import match_time_steps, wave_block, res_se_cnn_decoder_block\n",
    "\n",
    "# --- Advanced Model 2: Stacked Transformer Tower ---\n",
    "def create_advanced_model_2_transformer_tower(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Strong CNN backbone to create rich features for the Transformer\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd) # Output shape: (None, 32, 128)\n",
    "    \n",
    "    # Stacked Transformer Tower\n",
    "    # Each block attends to the output of the previous one, building deeper context.\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    x1 = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256, rate=0.3)(x1)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd) # Output shape: (None, 32, 128)\n",
    "\n",
    "    # Merge and classify\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model 3: Hybrid UNet + WaveNet ---\n",
    "def create_advanced_model_3_unet_wave(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1_unet = unet_se_cnn(imu, unet_depth=3, base_filters=64, kernel_size=5)\n",
    "    x1_wave = wave_block(imu, 64, 3, n=5, dropout_rate=0.3) # n=5 -> dilations up to 16\n",
    "    \n",
    "    x1_unet_matched, x1_wave_matched = match_time_steps(x1_unet, x1_wave)\n",
    "    x1 = Concatenate()([x1_unet_matched, x1_wave_matched])\n",
    "    \n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_wave_net(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = wave_block(imu, 128, 3, n=4, dropout_rate=0.3) \n",
    "    x2 = tof_block(tof, wd)\n",
    "\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model 4: Triple Stacked Block Design ---\n",
    "def cnn_gru_block(x, filters, kernel_size, wd=1e-4):\n",
    "    # A self-contained block combining CNN and GRU\n",
    "    x_cnn = residual_se_cnn_block(x, filters, kernel_size, wd=wd)\n",
    "    x_gru = Bidirectional(GRU(filters // 2, return_sequences=True))(x_cnn)\n",
    "    return x_gru\n",
    "\n",
    "def cnn_gru_block(x, filters, kernel_size, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A simplified and robust block that first applies a CNN, then a GRU.\n",
    "    \"\"\"\n",
    "    # 1. CNN part for feature extraction and downsampling\n",
    "    x = residual_se_cnn_block(x, filters, kernel_size, wd=wd)\n",
    "    \n",
    "    # 2. GRU part for sequence processing\n",
    "    x = Bidirectional(GRU(filters, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_advanced_model_4_stacked_blocks(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Apply the hybrid block three times\n",
    "    x1 = cnn_gru_block(imu, 64, 3)  # Output: (None, 64, 128)\n",
    "    x1 = cnn_gru_block(x1, 128, 5) # Output: (None, 32, 256)\n",
    "    \n",
    "    # The final block will not return sequences to simplify the final merge\n",
    "    x1 = Bidirectional(GRU(128, return_sequences=False))(x1) # Output: (None, 256)\n",
    "    \n",
    "    # Standard ToF branch, but we need to aggregate it to match x1\n",
    "    x2 = tof_block_2(tof, wd) # Output: (None, 32, 128)\n",
    "    x2 = GlobalAveragePooling1D()(x2) # Output: (None, 128)\n",
    "\n",
    "    # Merge the two aggregated feature vectors\n",
    "    x = Concatenate()([x1, x2]) # Output: (None, 256 + 128) = (None, 384)\n",
    "    \n",
    "    # Final classifier MLP\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model 5: UNet with BiLSTM Bottleneck ---\n",
    "def unet_se_cnn_bilstm(x, unet_depth=3, base_filters=64, kernel_size=3, drop=0.3):\n",
    "    filters = base_filters\n",
    "    skips = []\n",
    "    for _ in range(unet_depth):\n",
    "        x = residual_se_cnn_block(x, filters, kernel_size, drop=drop)\n",
    "        skips.append(x)\n",
    "        filters *= 2\n",
    "    \n",
    "    # --- BiLSTM Bottleneck ---\n",
    "    # Process the most compressed representation sequentially\n",
    "    x = Bidirectional(LSTM(filters // 2, return_sequences=True))(x)\n",
    "    \n",
    "    for skip in reversed(skips):\n",
    "        filters //= 2\n",
    "        x = res_se_cnn_decoder_block(x, filters, kernel_size, drop=drop, skip_connection=skip)\n",
    "    return x\n",
    "\n",
    "def create_advanced_model_1_deep_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branches ---\n",
    "    x1_unet = unet_se_cnn(imu, unet_depth=4, base_filters=128, kernel_size=5, drop=0.3)\n",
    "    x1_conv_k3 = residual_se_cnn_block(imu, 64, 3)\n",
    "    x1_conv_k7 = residual_se_cnn_block(imu, 64, 7)\n",
    "    \n",
    "    # --- FIX: Aggregate each branch BEFORE merging ---\n",
    "    # This creates a fixed-size vector from each branch, avoiding shape conflicts.\n",
    "    p1 = GlobalAveragePooling1D()(x1_unet)\n",
    "    p2 = GlobalAveragePooling1D()(x1_conv_k3)\n",
    "    p3 = GlobalAveragePooling1D()(x1_conv_k7)\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "    p4 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "    # Concatenate the aggregated feature vectors\n",
    "    x = Concatenate()([p1, p2, p3, p4])\n",
    "    \n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def create_advanced_model_5_unet_bilstm(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Use the UNet with the BiLSTM bottleneck\n",
    "    x1 = unet_se_cnn_bilstm(imu, unet_depth=3, base_filters=128, kernel_size=3)\n",
    "    \n",
    "    # Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # --- FIX: Use the robust aggregation strategy instead of features_processing ---\n",
    "    x1_pooled = GlobalAveragePooling1D()(x1)\n",
    "    x2_pooled = GlobalAveragePooling1D()(x2)\n",
    "    x = Concatenate()([x1_pooled, x2_pooled])\n",
    "\n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699bc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# 3 NEW ADVANCED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "from src.nn_blocks import attention_layer\n",
    "\n",
    "def create_advanced_model_A_dual_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Branch 1: A deep U-Net for the IMU data\n",
    "    x1_raw = unet_se_cnn(imu, unet_depth=4, base_filters=128, kernel_size=5, drop=0.3)\n",
    "    \n",
    "    # Branch 2: A parallel, slightly lighter U-Net for the ToF/Thermal data\n",
    "    x2_raw = unet_se_cnn(tof, unet_depth=3, base_filters=64, kernel_size=5, drop=0.3)\n",
    "\n",
    "    # --- FIX: Project both branches to a common feature dimension (e.g., 128) ---\n",
    "    # This ensures the input to features_processing is consistent.\n",
    "    x1 = Conv1D(128, 1, padding='same', activation='relu', name='imu_projection')(x1_raw)\n",
    "    x2 = Conv1D(128, 1, padding='same', activation='relu', name='tof_projection')(x2_raw)\n",
    "    \n",
    "    # Now both x1 and x2 have shape (None, 128, 128)\n",
    "    # They can be safely passed to the features_processing block.\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model B: Cross-Attention Fusion ---\n",
    "# Hypothesis: Instead of just concatenating the IMU and ToF branches, we can create\n",
    "# richer features by allowing them to \"talk to each other.\" The IMU branch will learn\n",
    "# what to pay attention to in the ToF data, and vice-versa.\n",
    "def create_advanced_model_B_cross_attention(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # 1. Create strong, downsampled feature representations for both branches\n",
    "    # Output Shape for both: (None, 32, 128)\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd)\n",
    "    \n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # 2. Cross-Attention Fusion\n",
    "    # The IMU branch queries the ToF branch for relevant context\n",
    "    imu_attends_tof = tf.keras.layers.Attention()([x1, x2])\n",
    "    # The ToF branch queries the IMU branch for relevant context\n",
    "    tof_attends_imu = tf.keras.layers.Attention()([x2, x1])\n",
    "    \n",
    "    # 3. Create an enriched representation by concatenating all perspectives\n",
    "    # The final tensor contains the original features plus the context-aware features.\n",
    "    # Shape: (None, 32, 128 + 128 + 128 + 128) = (None, 32, 512)\n",
    "    x = Concatenate()([x1, imu_attends_tof, x2, tof_attends_imu])\n",
    "    \n",
    "    # 4. Final Processing\n",
    "    # We use a powerful sequence processor on this ultra-rich tensor\n",
    "    x = Bidirectional(GRU(256, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    x = attention_layer(x)\n",
    "    \n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model C: Stacked Hybrid Blocks ---\n",
    "# Hypothesis: A single block of (CNN -> RNN) is good. Repeatedly stacking this\n",
    "# hybrid block will allow the model to learn progressively more abstract and\n",
    "\n",
    "# powerful spatio-temporal features.\n",
    "def cnn_lstm_block(x, filters, kernel_size, drop=0.2, wd=1e-4):\n",
    "    # A self-contained, reusable block\n",
    "    x = residual_se_cnn_block(x, filters, kernel_size, drop=drop, wd=wd)\n",
    "    x = Bidirectional(LSTM(filters, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    return x\n",
    "\n",
    "def create_advanced_model_C_stacked_hybrid(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Stacked Hybrid Blocks ---\n",
    "    # Each block refines the output of the previous one\n",
    "    # Input: (128, D) -> Block1: (64, 128) -> Block2: (32, 256)\n",
    "    x1 = cnn_lstm_block(imu, 64, 3)\n",
    "    x1 = cnn_lstm_block(x1, 128, 5)\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    # Output: (32, 128)\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "    # Project ToF features to match the final IMU feature dimension (256)\n",
    "    x2_projected = Dense(256, activation='relu')(x2)\n",
    "\n",
    "    # Now both inputs have shape (None, 32, 256) and can be processed\n",
    "    x = features_processing(x1, x2_projected)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66767de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# 3 NEW ADVANCED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "\n",
    "# --- Advanced Model A: BERT-Fusion (Keras Implementation) ---\n",
    "# Hypothesis: Using a Transformer (BERT) as a late-stage fusion layer for features\n",
    "# from three separate, specialized branches will create the most powerful representation.\n",
    "# This is a direct translation of the PyTorch model's core idea.\n",
    "def create_advanced_model_A_bert_fusion(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof_and_thm = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "    \n",
    "    # We need to split ToF and Thermal for separate processing\n",
    "    # Assuming thm_cols are the first 5 in the tof_and_thm tensor\n",
    "    thm = tf.keras.layers.Lambda(lambda t: t[:, :, :5])(tof_and_thm)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, 5:])(tof_and_thm)\n",
    "\n",
    "    # 1. Create three separate feature extraction branches\n",
    "    # IMU Branch\n",
    "    x_imu = residual_se_cnn_block(imu, 128, 3)\n",
    "    x_imu = residual_se_cnn_block(x_imu, 256, 5) # Shape: (None, 32, 256)\n",
    "    \n",
    "    # Thermal Branch\n",
    "    x_thm = residual_se_cnn_block(thm, 64, 3)\n",
    "    x_thm = residual_se_cnn_block(x_thm, 128, 5)\n",
    "    x_thm = Conv1D(256, 1, padding='same', activation='relu')(x_thm) # Project to 256 features\n",
    "    \n",
    "    # ToF Branch\n",
    "    x_tof = residual_se_cnn_block(tof, 128, 3)\n",
    "    x_tof = residual_se_cnn_block(x_tof, 256, 5) # Shape: (None, 32, 256)\n",
    "    \n",
    "    # 2. Concatenate along the feature axis and feed into a Transformer\n",
    "    # Shape: (None, 32, 256+256+256) -> (None, 32, 768)\n",
    "    x = Concatenate()([x_imu, x_thm, x_tof])\n",
    "    \n",
    "    # Transformer (BERT-like) layers for deep fusion\n",
    "    x = TransformerBlock(embed_dim=768, num_heads=8, ff_dim=1024, rate=0.2)(x)\n",
    "    x = TransformerBlock(embed_dim=768, num_heads=8, ff_dim=1024, rate=0.2)(x)\n",
    "    \n",
    "    # 3. Use Global Pooling to aggregate the time dimension\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # 4. Final Classifier MLP\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model B: Hyper-UNet ---\n",
    "# Hypothesis: Since U-Nets are the top performers, an even deeper and wider U-Net\n",
    "# with more filters and a deeper encoder/decoder structure will capture more complex features.\n",
    "def create_advanced_model_B_hyper_unet(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # Branch 1: A very deep and wide U-Net for IMU data\n",
    "    # unet_depth=5 creates a very deep model, base_filters=128 makes it wide.\n",
    "    x1 = unet_se_cnn(imu, unet_depth=5, base_filters=128, kernel_size=5, drop=0.3)\n",
    "    \n",
    "    # Branch 2: A standard ToF block\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # Project both branches to a common, large feature dimension before merging\n",
    "    x1_proj = Conv1D(128, 1, padding='same', activation='relu')(x1)\n",
    "    x2_proj = Conv1D(128, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    # Use the standard features_processing block to merge and classify\n",
    "    x = features_processing(x1_proj, x2_proj)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# --- Advanced Model C: Parallel UNet-Transformer Hybrid ---\n",
    "# Hypothesis: The IMU signal contains both local patterns (best for U-Net) and global\n",
    "# context (best for Transformer). Processing the IMU with both backbones in parallel\n",
    "# and fusing their outputs will create the ultimate feature representation.\n",
    "def create_advanced_model_C_parallel_hybrid(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch is now two parallel streams ---\n",
    "    \n",
    "    # Stream 1: U-Net for multi-resolution analysis\n",
    "    imu_unet = unet_se_cnn(imu, unet_depth=4, base_filters=128, kernel_size=5)\n",
    "    \n",
    "    # Stream 2: CNN -> Transformer Tower for global context\n",
    "    imu_cnn = residual_se_cnn_block(imu, 64, 3)\n",
    "    imu_cnn = residual_se_cnn_block(imu_cnn, 128, 5) # Shape: (None, 32, 128)\n",
    "    imu_transformer = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256)(imu_cnn)\n",
    "    \n",
    "    # --- Fusion of IMU streams ---\n",
    "    imu_unet_matched, imu_transformer_matched = match_time_steps(imu_unet, imu_transformer)\n",
    "    x1 = Concatenate()([imu_unet_matched, imu_transformer_matched]) # Shape: (None, 32, 256)\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    x2 = tof_block_2(tof, wd) # Shape: (None, 32, 128)\n",
    "\n",
    "    # --- FIX: Project both branches to a common, predictable feature dimension ---\n",
    "    # Let's project both to 256 features, so the merged result is 512.\n",
    "    x1_proj = Conv1D(256, 1, padding='same', activation='relu', name='imu_projection')(x1)\n",
    "    x2_proj = Conv1D(256, 1, padding='same', activation='relu', name='tof_projection')(x2)\n",
    "    \n",
    "    # Now both x1_proj and x2_proj have shape (None, 32, 256)\n",
    "    # They can be safely passed to the features_processing block.\n",
    "    x = features_processing(x1_proj, x2_proj)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5307904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polars as pl\n",
    "# df = pl.read_parquet('output/imu_physics_feats.parquet')\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60244006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Layer, Sequential\n",
    "\n",
    "def ImuFeatureExtractorLayer(imu_input):\n",
    "    \"\"\"A Keras layer to perform on-the-fly feature engineering.\"\"\"\n",
    "    acc = imu_input[:, :, :3]  # Assuming raw acc_x, y, z are the first 3 features\n",
    "    gyro = imu_input[:, :, 3:6] # Assuming raw rot_w,x,y,z -> angular velocity are next\n",
    "    \n",
    "    acc_mag = tf.norm(acc, axis=-1, keepdims=True)\n",
    "    gyro_mag = tf.norm(gyro, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Jerk (diff) requires padding to maintain time dimension\n",
    "    jerk = tf.pad(acc[:, 1:, :] - acc[:, :-1, :], [[0, 0], [1, 0], [0, 0]])\n",
    "    \n",
    "    # Squared values\n",
    "    acc_pow = tf.square(acc)\n",
    "    \n",
    "    # Concatenate all derived features\n",
    "    return Concatenate()([acc, gyro, acc_mag, gyro_mag, jerk, acc_pow])\n",
    "\n",
    "def create_new_model_1_in_model_fe(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    # IMPORTANT: This model expects the RAW acc/rot features, not the engineered ones.\n",
    "    # You will need to adjust your data pipeline to feed the raw features.\n",
    "    imu_raw = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # 1. On-the-fly feature engineering branch\n",
    "    x1 = ImuFeatureExtractorLayer(imu_raw)\n",
    "    \n",
    "    # 2. Standard CNN backbone to process these rich features\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5)\n",
    "    x1 = residual_se_cnn_block(x1, 256, 7)\n",
    "    \n",
    "    # 3. Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # 4. Merge and classify\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# =====================================================================================\n",
    "# 3 NEW ADVANCED PANNs-BASED MODEL ARCHITECTURES\n",
    "# =====================================================================================\n",
    "\n",
    "def create_panns_model_A_rnn_head(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Parallel CNNs (PANNs Backbone) ---\n",
    "    # Each branch downsamples time to 32 and outputs 128 features\n",
    "    k3 = residual_se_cnn_block(imu, 128, 3)\n",
    "    k5 = residual_se_cnn_block(imu, 128, 5)\n",
    "    k7 = residual_se_cnn_block(imu, 128, 7)\n",
    "    \n",
    "    # Concatenate the multi-scale features\n",
    "    # Shape: (None, 32, 128 + 128 + 128) = (None, 32, 384)\n",
    "    x1 = Concatenate()([k3, k5, k7])\n",
    "    \n",
    "    # --- ToF Branch ---\n",
    "    x2 = tof_block(tof, wd) # Shape: (None, 32, 128)\n",
    "\n",
    "    # --- Merge and Process with RNN Head ---\n",
    "    # Project ToF features to match the IMU feature dimension for a cleaner merge\n",
    "    x2_proj = Conv1D(384, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    # Concatenate the full feature set\n",
    "    x = Concatenate()([x1, x2_proj]) # Shape: (None, 32, 384 + 384) = (None, 32, 768)\n",
    "    \n",
    "    # Add a powerful RNN head to learn sequential patterns from the rich features\n",
    "    x = Bidirectional(GRU(384, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    x = attention_layer(x) # Use attention to summarize the sequence\n",
    "    \n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "def pann_rnn_head_feat_processing(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Parallel CNNs (PANNs Backbone) ---\n",
    "    # Each branch downsamples time to 32 and outputs 128 features\n",
    "    k3 = residual_se_cnn_block(imu, 128, 3)\n",
    "    k5 = residual_se_cnn_block(imu, 128, 5)\n",
    "    k7 = residual_se_cnn_block(imu, 128, 7)\n",
    "    \n",
    "    # Shape: (None, 32, 128 + 128 + 128) = (None, 32, 384)\n",
    "    x1 = Concatenate()([k3, k5, k7])\n",
    "    x2 = tof_block(tof, wd) # Shape: (None, 32, 128)\n",
    "    x2_proj = Conv1D(384, 1, padding='same', activation='relu')(x2)\n",
    "    \n",
    "    x = features_processing(x1, x2_proj)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5dd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImuFeatureExtractorLayer(imu_input):\n",
    "    \"\"\"A Keras layer to perform on-the-fly feature engineering.\"\"\"\n",
    "    acc = tf.keras.layers.Lambda(lambda t: t[:, :, :3])(imu_input)\n",
    "    gyro = tf.keras.layers.Lambda(lambda t: t[:, :, 3:6])(imu_input)\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # Wrap each raw TensorFlow function in a Keras Lambda layer.\n",
    "    \n",
    "    acc_mag = tf.keras.layers.Lambda(lambda t: tf.norm(t, axis=-1, keepdims=True))(acc)\n",
    "    gyro_mag = tf.keras.layers.Lambda(lambda t: tf.norm(t, axis=-1, keepdims=True))(gyro)\n",
    "    \n",
    "    # The tf.pad function also needs to be wrapped.\n",
    "    jerk = tf.keras.layers.Lambda(\n",
    "        lambda t: tf.pad(t[:, 1:, :] - t[:, :-1, :], [[0, 0], [1, 0], [0, 0]])\n",
    "    )(acc)\n",
    "    \n",
    "    # tf.square is a simple operation, but for consistency, we can wrap it too.\n",
    "    acc_pow = tf.keras.layers.Lambda(tf.square)(acc)\n",
    "    \n",
    "    # Concatenate all the resulting KerasTensors\n",
    "    return Concatenate()([acc, gyro, acc_mag, gyro_mag, jerk, acc_pow])\n",
    "\n",
    "def create_new_model_1_in_model_fe(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu_raw = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # 1. On-the-fly feature engineering branch\n",
    "    x1 = ImuFeatureExtractorLayer(imu_raw)\n",
    "    \n",
    "    # 2. Standard CNN backbone to process these rich features\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5)\n",
    "    x1 = residual_se_cnn_block(x1, 256, 7)\n",
    "    \n",
    "    # 3. Standard ToF branch\n",
    "    x2 = tof_block_2(tof, wd)\n",
    "\n",
    "    # --- FIX: Aggregate each branch BEFORE merging ---\n",
    "    # This creates fixed-size vectors and avoids all shape conflicts.\n",
    "    x1_pooled = GlobalAveragePooling1D()(x1)\n",
    "    x2_pooled = GlobalAveragePooling1D()(x2)\n",
    "    \n",
    "    # Concatenate the aggregated feature vectors\n",
    "    x = Concatenate()([x1_pooled, x2_pooled])\n",
    "    \n",
    "    # --- Final Classifier MLP ---\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807119b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def generate_tof_features_for_inference(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    decay_weights = np.power(0.9, np.arange(64))\n",
    "    x_coords, y_coords = np.meshgrid(np.arange(8), np.arange(8))\n",
    "    feature_expressions = []\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "        if not all(col in df.columns for col in pixel_cols): continue\n",
    "        list_expr = pl.concat_list([pl.when(pl.col(c) == -1).then(None).otherwise(pl.col(c)) for c in pixel_cols]).alias(f\"tof_{i}_list\")\n",
    "        feature_expressions.extend([list_expr.list.mean().alias(f'tof_{i}_mean'), list_expr.list.std().alias(f'tof_{i}_std'),\n",
    "                                    list_expr.list.min().alias(f'tof_{i}_min'), list_expr.list.max().alias(f'tof_{i}_max'),\n",
    "                                    list_expr.list.median().alias(f'tof_{i}_median'), list_expr.list.diff().list.mean().alias(f'tof_{i}_diff_mean'),\n",
    "                                    list_expr.list.drop_nulls().list.len().alias(f'tof_{i}_active_pixels'),\n",
    "                                    # list_expr.list.drop_nulls().map_elements(pl_skew, return_dtype=pl.Float64).alias(f'tof_{i}_skew'),\n",
    "                                    # list_expr.list.drop_nulls().map_elements(pl_kurtosis, return_dtype=pl.Float64).alias(f'tof_{i}_kurtosis')\n",
    "                                    ])\n",
    "        tof_data_exprs = [pl.when(pl.col(c) == -1).then(None).otherwise(pl.col(c)) for c in pixel_cols]\n",
    "        feature_expressions.append(pl.sum_horizontal([(expr * weight).fill_null(0) for expr, weight in zip(tof_data_exprs, decay_weights)]).alias(f'tof_{i}_mean_decay'))\n",
    "        weights_exprs = [(1 / (expr + 1e-6)).fill_null(0) for expr in tof_data_exprs]\n",
    "        total_weight_expr = pl.sum_horizontal(weights_exprs)\n",
    "        centroid_x_expr = pl.when(total_weight_expr > 1e-9).then(pl.sum_horizontal([(w * c) for w, c in zip(weights_exprs, x_coords.ravel())]) / total_weight_expr).otherwise(None)\n",
    "        centroid_y_expr = pl.when(total_weight_expr > 1e-9).then(pl.sum_horizontal([(w * c) for w, c in zip(weights_exprs, y_coords.ravel())]) / total_weight_expr).otherwise(None)\n",
    "        feature_expressions.extend([centroid_x_expr.alias(f'tof_{i}_centroid_x'), centroid_y_expr.alias(f'tof_{i}_centroid_y')])\n",
    "    if feature_expressions:\n",
    "        df = df.with_columns(feature_expressions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267eb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading and cleaning raw data from train.csv...\n",
      "  Final DataFrame created with shape: (574945, 349)\n",
      "  Training with 332 total raw features (7 IMU).\n",
      "  DataFrame columns have been reordered for the model.\n",
      "\n",
      "============================================================\n",
      "▶ Training and Evaluating Model: End_To_End_CNN\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 for End_To_End_CNN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755982007.169106 4113464 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-08-23 21:46:47.185972: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 277243904 exceeds 10% of free system memory.\n",
      "2025-08-23 21:46:48.677978: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 277243904 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Scheduler: 102 steps per epoch, 15300 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1755982033.014432 4113620 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-23 21:47:14.138921: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 34/102\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - loss: 4.1007 - main_output_accuracy: 0.0589 - main_output_loss: 3.4868 - tof_gate_loss: 1.0795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:47:24.504699: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 3.8539 - main_output_accuracy: 0.0900 - main_output_loss: 3.2815 - tof_gate_loss: 0.8719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:47:36.792014: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 277243904 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 205ms/step - loss: 3.8513 - main_output_accuracy: 0.0904 - main_output_loss: 3.2794 - tof_gate_loss: 0.8695 - val_loss: 3.0205 - val_main_output_accuracy: 0.2551 - val_main_output_loss: 2.5546 - val_tof_gate_loss: 0.3690\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - loss: 3.1322 - main_output_accuracy: 0.2071 - main_output_loss: 2.6931 - tof_gate_loss: 0.2318 - val_loss: 2.6234 - val_main_output_accuracy: 0.3096 - val_main_output_loss: 2.2088 - val_tof_gate_loss: 0.1430\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 150ms/step - loss: 2.8625 - main_output_accuracy: 0.2739 - main_output_loss: 2.4557 - tof_gate_loss: 0.1091 - val_loss: 2.3845 - val_main_output_accuracy: 0.3691 - val_main_output_loss: 1.9894 - val_tof_gate_loss: 0.0836\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - loss: 2.6621 - main_output_accuracy: 0.3293 - main_output_loss: 2.2719 - tof_gate_loss: 0.0662 - val_loss: 2.2758 - val_main_output_accuracy: 0.4237 - val_main_output_loss: 1.8985 - val_tof_gate_loss: 0.0399\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - loss: 2.5837 - main_output_accuracy: 0.3711 - main_output_loss: 2.2062 - tof_gate_loss: 0.0455 - val_loss: 2.1905 - val_main_output_accuracy: 0.4261 - val_main_output_loss: 1.8250 - val_tof_gate_loss: 0.0271\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - loss: 2.5395 - main_output_accuracy: 0.3917 - main_output_loss: 2.1727 - tof_gate_loss: 0.0342 - val_loss: 2.0910 - val_main_output_accuracy: 0.4905 - val_main_output_loss: 1.7354 - val_tof_gate_loss: 0.0226\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 2.3990 - main_output_accuracy: 0.4266 - main_output_loss: 2.0421 - tof_gate_loss: 0.0268 - val_loss: 2.0526 - val_main_output_accuracy: 0.4948 - val_main_output_loss: 1.7056 - val_tof_gate_loss: 0.0165\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 169ms/step - loss: 2.4055 - main_output_accuracy: 0.4329 - main_output_loss: 2.0584 - tof_gate_loss: 0.0225 - val_loss: 2.0080 - val_main_output_accuracy: 0.5156 - val_main_output_loss: 1.6680 - val_tof_gate_loss: 0.0158\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - loss: 2.2916 - main_output_accuracy: 0.4758 - main_output_loss: 1.9532 - tof_gate_loss: 0.0178 - val_loss: 1.9801 - val_main_output_accuracy: 0.5101 - val_main_output_loss: 1.6495 - val_tof_gate_loss: 0.0117\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 166ms/step - loss: 2.2905 - main_output_accuracy: 0.4940 - main_output_loss: 1.9602 - tof_gate_loss: 0.0150 - val_loss: 1.9870 - val_main_output_accuracy: 0.5040 - val_main_output_loss: 1.6670 - val_tof_gate_loss: 0.0107\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 2.1220 - main_output_accuracy: 0.5451 - main_output_loss: 1.7994 - tof_gate_loss: 0.0128 - val_loss: 1.9369 - val_main_output_accuracy: 0.5248 - val_main_output_loss: 1.6209 - val_tof_gate_loss: 0.0096\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - loss: 2.1646 - main_output_accuracy: 0.5436 - main_output_loss: 1.8494 - tof_gate_loss: 0.0117 - val_loss: 1.8893 - val_main_output_accuracy: 0.5414 - val_main_output_loss: 1.5839 - val_tof_gate_loss: 0.0093\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 2.0088 - main_output_accuracy: 0.5812 - main_output_loss: 1.7000 - tof_gate_loss: 0.0099 - val_loss: 1.9326 - val_main_output_accuracy: 0.5236 - val_main_output_loss: 1.6317 - val_tof_gate_loss: 0.0072\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step - loss: 2.0096 - main_output_accuracy: 0.5949 - main_output_loss: 1.7079 - tof_gate_loss: 0.0089 - val_loss: 1.8508 - val_main_output_accuracy: 0.5573 - val_main_output_loss: 1.5597 - val_tof_gate_loss: 0.0064\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 169ms/step - loss: 1.9917 - main_output_accuracy: 0.6080 - main_output_loss: 1.6963 - tof_gate_loss: 0.0075 - val_loss: 1.8660 - val_main_output_accuracy: 0.5506 - val_main_output_loss: 1.5772 - val_tof_gate_loss: 0.0058\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - loss: 1.9665 - main_output_accuracy: 0.6282 - main_output_loss: 1.6774 - tof_gate_loss: 0.0064 - val_loss: 1.8365 - val_main_output_accuracy: 0.5481 - val_main_output_loss: 1.5532 - val_tof_gate_loss: 0.0058\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - loss: 1.9132 - main_output_accuracy: 0.6540 - main_output_loss: 1.6296 - tof_gate_loss: 0.0059 - val_loss: 1.8453 - val_main_output_accuracy: 0.5647 - val_main_output_loss: 1.5700 - val_tof_gate_loss: 0.0045\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - loss: 1.9245 - main_output_accuracy: 0.6382 - main_output_loss: 1.6464 - tof_gate_loss: 0.0052 - val_loss: 1.8168 - val_main_output_accuracy: 0.5720 - val_main_output_loss: 1.5467 - val_tof_gate_loss: 0.0047\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 160ms/step - loss: 1.9255 - main_output_accuracy: 0.6475 - main_output_loss: 1.6530 - tof_gate_loss: 0.0049 - val_loss: 1.8887 - val_main_output_accuracy: 0.5297 - val_main_output_loss: 1.6250 - val_tof_gate_loss: 0.0043\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 166ms/step - loss: 1.8120 - main_output_accuracy: 0.6816 - main_output_loss: 1.5446 - tof_gate_loss: 0.0041 - val_loss: 1.8457 - val_main_output_accuracy: 0.5524 - val_main_output_loss: 1.5858 - val_tof_gate_loss: 0.0033\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - loss: 1.7578 - main_output_accuracy: 0.7018 - main_output_loss: 1.4948 - tof_gate_loss: 0.0040 - val_loss: 1.8462 - val_main_output_accuracy: 0.5543 - val_main_output_loss: 1.5889 - val_tof_gate_loss: 0.0031\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 158ms/step - loss: 1.8255 - main_output_accuracy: 0.6949 - main_output_loss: 1.5670 - tof_gate_loss: 0.0032 - val_loss: 1.8417 - val_main_output_accuracy: 0.5543 - val_main_output_loss: 1.5908 - val_tof_gate_loss: 0.0032\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - loss: 1.7956 - main_output_accuracy: 0.7065 - main_output_loss: 1.5438 - tof_gate_loss: 0.0033 - val_loss: 1.8503 - val_main_output_accuracy: 0.5451 - val_main_output_loss: 1.6011 - val_tof_gate_loss: 0.0023\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 1.7213 - main_output_accuracy: 0.7254 - main_output_loss: 1.4712 - tof_gate_loss: 0.0028 - val_loss: 1.8276 - val_main_output_accuracy: 0.5684 - val_main_output_loss: 1.5851 - val_tof_gate_loss: 0.0023\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 179ms/step - loss: 1.7438 - main_output_accuracy: 0.7398 - main_output_loss: 1.4972 - tof_gate_loss: 0.0027 - val_loss: 1.8003 - val_main_output_accuracy: 0.5665 - val_main_output_loss: 1.5589 - val_tof_gate_loss: 0.0020\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 187ms/step - loss: 1.7571 - main_output_accuracy: 0.7410 - main_output_loss: 1.5149 - tof_gate_loss: 0.0024 - val_loss: 1.8016 - val_main_output_accuracy: 0.5776 - val_main_output_loss: 1.5669 - val_tof_gate_loss: 0.0019\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 1.6727 - main_output_accuracy: 0.7592 - main_output_loss: 1.4342 - tof_gate_loss: 0.0023 - val_loss: 1.8161 - val_main_output_accuracy: 0.5751 - val_main_output_loss: 1.5837 - val_tof_gate_loss: 0.0018\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 1.5997 - main_output_accuracy: 0.7608 - main_output_loss: 1.3646 - tof_gate_loss: 0.0020 - val_loss: 1.8092 - val_main_output_accuracy: 0.5671 - val_main_output_loss: 1.5800 - val_tof_gate_loss: 0.0014\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - loss: 1.7164 - main_output_accuracy: 0.7527 - main_output_loss: 1.4860 - tof_gate_loss: 0.0019 - val_loss: 1.8231 - val_main_output_accuracy: 0.5598 - val_main_output_loss: 1.5992 - val_tof_gate_loss: 0.0018\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - loss: 1.5806 - main_output_accuracy: 0.7985 - main_output_loss: 1.3524 - tof_gate_loss: 0.0017 - val_loss: 1.8368 - val_main_output_accuracy: 0.5622 - val_main_output_loss: 1.6120 - val_tof_gate_loss: 0.0014\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step - loss: 1.6032 - main_output_accuracy: 0.7765 - main_output_loss: 1.3768 - tof_gate_loss: 0.0017 - val_loss: 1.7961 - val_main_output_accuracy: 0.5843 - val_main_output_loss: 1.5819 - val_tof_gate_loss: 0.0011\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 1.6076 - main_output_accuracy: 0.7897 - main_output_loss: 1.3840 - tof_gate_loss: 0.0015 - val_loss: 1.8555 - val_main_output_accuracy: 0.5494 - val_main_output_loss: 1.6422 - val_tof_gate_loss: 0.0012\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 186ms/step - loss: 1.5177 - main_output_accuracy: 0.8159 - main_output_loss: 1.2974 - tof_gate_loss: 0.0014 - val_loss: 1.8081 - val_main_output_accuracy: 0.5739 - val_main_output_loss: 1.5931 - val_tof_gate_loss: 0.0011\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 1.5644 - main_output_accuracy: 0.7927 - main_output_loss: 1.3462 - tof_gate_loss: 0.0014 - val_loss: 1.8660 - val_main_output_accuracy: 0.5586 - val_main_output_loss: 1.6575 - val_tof_gate_loss: 9.4660e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 1.5647 - main_output_accuracy: 0.8086 - main_output_loss: 1.3497 - tof_gate_loss: 0.0012 - val_loss: 1.8227 - val_main_output_accuracy: 0.5819 - val_main_output_loss: 1.6125 - val_tof_gate_loss: 9.8753e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step - loss: 1.6539 - main_output_accuracy: 0.7865 - main_output_loss: 1.4400 - tof_gate_loss: 0.0012 - val_loss: 1.8501 - val_main_output_accuracy: 0.5677 - val_main_output_loss: 1.6450 - val_tof_gate_loss: 8.3801e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step - loss: 1.5101 - main_output_accuracy: 0.8201 - main_output_loss: 1.2999 - tof_gate_loss: 0.0012 - val_loss: 1.8340 - val_main_output_accuracy: 0.5708 - val_main_output_loss: 1.6290 - val_tof_gate_loss: 9.5587e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - loss: 1.4128 - main_output_accuracy: 0.8347 - main_output_loss: 1.2047 - tof_gate_loss: 0.0010 - val_loss: 1.8366 - val_main_output_accuracy: 0.5782 - val_main_output_loss: 1.6375 - val_tof_gate_loss: 8.0216e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 178ms/step - loss: 1.5767 - main_output_accuracy: 0.8125 - main_output_loss: 1.3711 - tof_gate_loss: 9.8501e-04 - val_loss: 1.8525 - val_main_output_accuracy: 0.5733 - val_main_output_loss: 1.6523 - val_tof_gate_loss: 7.5971e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 181ms/step - loss: 1.5766 - main_output_accuracy: 0.8077 - main_output_loss: 1.3731 - tof_gate_loss: 9.4472e-04 - val_loss: 1.8246 - val_main_output_accuracy: 0.5745 - val_main_output_loss: 1.6182 - val_tof_gate_loss: 7.6374e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - loss: 1.3812 - main_output_accuracy: 0.8516 - main_output_loss: 1.1798 - tof_gate_loss: 8.2463e-04 - val_loss: 1.8501 - val_main_output_accuracy: 0.5708 - val_main_output_loss: 1.6601 - val_tof_gate_loss: 6.5799e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 177ms/step - loss: 1.4943 - main_output_accuracy: 0.8226 - main_output_loss: 1.2947 - tof_gate_loss: 8.7892e-04 - val_loss: 1.8192 - val_main_output_accuracy: 0.5769 - val_main_output_loss: 1.6264 - val_tof_gate_loss: 5.8407e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - loss: 1.4171 - main_output_accuracy: 0.8536 - main_output_loss: 1.2192 - tof_gate_loss: 8.4322e-04 - val_loss: 1.9087 - val_main_output_accuracy: 0.5616 - val_main_output_loss: 1.7140 - val_tof_gate_loss: 5.6094e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 181ms/step - loss: 1.4469 - main_output_accuracy: 0.8309 - main_output_loss: 1.2508 - tof_gate_loss: 7.4832e-04 - val_loss: 1.8766 - val_main_output_accuracy: 0.5702 - val_main_output_loss: 1.6907 - val_tof_gate_loss: 5.9786e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 176ms/step - loss: 1.3598 - main_output_accuracy: 0.8765 - main_output_loss: 1.1653 - tof_gate_loss: 7.2725e-04 - val_loss: 1.8621 - val_main_output_accuracy: 0.5788 - val_main_output_loss: 1.6699 - val_tof_gate_loss: 5.6215e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 177ms/step - loss: 1.3982 - main_output_accuracy: 0.8580 - main_output_loss: 1.2057 - tof_gate_loss: 7.6201e-04 - val_loss: 1.8733 - val_main_output_accuracy: 0.5653 - val_main_output_loss: 1.6860 - val_tof_gate_loss: 4.8745e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 182ms/step - loss: 1.4313 - main_output_accuracy: 0.8580 - main_output_loss: 1.2409 - tof_gate_loss: 6.8708e-04 - val_loss: 1.9231 - val_main_output_accuracy: 0.5647 - val_main_output_loss: 1.7381 - val_tof_gate_loss: 4.1503e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 1.4043 - main_output_accuracy: 0.8572 - main_output_loss: 1.2150 - tof_gate_loss: 6.4084e-04 - val_loss: 1.8657 - val_main_output_accuracy: 0.5659 - val_main_output_loss: 1.6772 - val_tof_gate_loss: 4.4837e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - loss: 1.5751 - main_output_accuracy: 0.8279 - main_output_loss: 1.3888 - tof_gate_loss: 6.8387e-04 - val_loss: 1.8407 - val_main_output_accuracy: 0.5782 - val_main_output_loss: 1.6555 - val_tof_gate_loss: 4.8557e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 179ms/step - loss: 1.4458 - main_output_accuracy: 0.8523 - main_output_loss: 1.2592 - tof_gate_loss: 6.9129e-04 - val_loss: 1.9182 - val_main_output_accuracy: 0.5512 - val_main_output_loss: 1.7369 - val_tof_gate_loss: 4.4188e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - loss: 1.3335 - main_output_accuracy: 0.8691 - main_output_loss: 1.1488 - tof_gate_loss: 5.8980e-04 - val_loss: 1.8684 - val_main_output_accuracy: 0.5684 - val_main_output_loss: 1.6883 - val_tof_gate_loss: 3.1782e-04\n",
      "--- Fold 1 Best Epoch: 31 ---\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n",
      "Fold 1 Accuracy: 0.5843\n",
      "\n",
      "=== Fold 2/5 for End_To_End_CNN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 22:03:10.731939: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 277073920 exceeds 10% of free system memory.\n",
      "2025-08-23 22:03:12.539651: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 277073920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Scheduler: 102 steps per epoch, 15300 total decay steps.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uallende/projects/kaggle/CMI/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 12/102\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - loss: 4.0874 - main_output_accuracy: 0.0686 - main_output_loss: 3.4652 - tof_gate_loss: 1.1210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 22:03:39.447708: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.89GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 225ms/step - loss: 3.8109 - main_output_accuracy: 0.1027 - main_output_loss: 3.2438 - tof_gate_loss: 0.8491 - val_loss: 3.0040 - val_main_output_accuracy: 0.2479 - val_main_output_loss: 2.5380 - val_tof_gate_loss: 0.3553\n",
      "Epoch 2/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - loss: 3.1416 - main_output_accuracy: 0.2034 - main_output_loss: 2.7032 - tof_gate_loss: 0.2289 - val_loss: 2.5581 - val_main_output_accuracy: 0.3294 - val_main_output_loss: 2.1456 - val_tof_gate_loss: 0.1236\n",
      "Epoch 3/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 2.8722 - main_output_accuracy: 0.2601 - main_output_loss: 2.4651 - tof_gate_loss: 0.1116 - val_loss: 2.3364 - val_main_output_accuracy: 0.3840 - val_main_output_loss: 1.9419 - val_tof_gate_loss: 0.0642\n",
      "Epoch 4/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - loss: 2.7173 - main_output_accuracy: 0.3138 - main_output_loss: 2.3279 - tof_gate_loss: 0.0644 - val_loss: 2.2353 - val_main_output_accuracy: 0.4110 - val_main_output_loss: 1.8549 - val_tof_gate_loss: 0.0401\n",
      "Epoch 5/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 163ms/step - loss: 2.5908 - main_output_accuracy: 0.3586 - main_output_loss: 2.2130 - tof_gate_loss: 0.0468 - val_loss: 2.1796 - val_main_output_accuracy: 0.4472 - val_main_output_loss: 1.8103 - val_tof_gate_loss: 0.0298\n",
      "Epoch 6/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 160ms/step - loss: 2.5321 - main_output_accuracy: 0.3846 - main_output_loss: 2.1641 - tof_gate_loss: 0.0368 - val_loss: 2.1022 - val_main_output_accuracy: 0.4847 - val_main_output_loss: 1.7427 - val_tof_gate_loss: 0.0243\n",
      "Epoch 7/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - loss: 2.3992 - main_output_accuracy: 0.4235 - main_output_loss: 2.0416 - tof_gate_loss: 0.0278 - val_loss: 2.1157 - val_main_output_accuracy: 0.4791 - val_main_output_loss: 1.7657 - val_tof_gate_loss: 0.0210\n",
      "Epoch 8/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - loss: 2.3597 - main_output_accuracy: 0.4477 - main_output_loss: 2.0106 - tof_gate_loss: 0.0230 - val_loss: 2.0230 - val_main_output_accuracy: 0.5153 - val_main_output_loss: 1.6803 - val_tof_gate_loss: 0.0154\n",
      "Epoch 9/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 166ms/step - loss: 2.2803 - main_output_accuracy: 0.4730 - main_output_loss: 1.9397 - tof_gate_loss: 0.0183 - val_loss: 1.9848 - val_main_output_accuracy: 0.5282 - val_main_output_loss: 1.6523 - val_tof_gate_loss: 0.0132\n",
      "Epoch 10/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 2.2452 - main_output_accuracy: 0.4849 - main_output_loss: 1.9125 - tof_gate_loss: 0.0156 - val_loss: 1.9412 - val_main_output_accuracy: 0.5313 - val_main_output_loss: 1.6155 - val_tof_gate_loss: 0.0129\n",
      "Epoch 11/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 179ms/step - loss: 2.1877 - main_output_accuracy: 0.5160 - main_output_loss: 1.8625 - tof_gate_loss: 0.0133 - val_loss: 1.9412 - val_main_output_accuracy: 0.5393 - val_main_output_loss: 1.6207 - val_tof_gate_loss: 0.0092\n",
      "Epoch 12/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 176ms/step - loss: 2.1460 - main_output_accuracy: 0.5418 - main_output_loss: 1.8283 - tof_gate_loss: 0.0116 - val_loss: 1.9106 - val_main_output_accuracy: 0.5491 - val_main_output_loss: 1.5982 - val_tof_gate_loss: 0.0089\n",
      "Epoch 13/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 170ms/step - loss: 2.0264 - main_output_accuracy: 0.5732 - main_output_loss: 1.7154 - tof_gate_loss: 0.0097 - val_loss: 1.8914 - val_main_output_accuracy: 0.5503 - val_main_output_loss: 1.5875 - val_tof_gate_loss: 0.0087\n",
      "Epoch 14/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - loss: 2.1267 - main_output_accuracy: 0.5787 - main_output_loss: 1.8221 - tof_gate_loss: 0.0090 - val_loss: 1.8482 - val_main_output_accuracy: 0.5736 - val_main_output_loss: 1.5468 - val_tof_gate_loss: 0.0070\n",
      "Epoch 15/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - loss: 2.1210 - main_output_accuracy: 0.5902 - main_output_loss: 1.8221 - tof_gate_loss: 0.0079 - val_loss: 1.8686 - val_main_output_accuracy: 0.5669 - val_main_output_loss: 1.5755 - val_tof_gate_loss: 0.0058\n",
      "Epoch 16/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 2.0795 - main_output_accuracy: 0.5927 - main_output_loss: 1.7873 - tof_gate_loss: 0.0070 - val_loss: 1.8422 - val_main_output_accuracy: 0.5699 - val_main_output_loss: 1.5526 - val_tof_gate_loss: 0.0060\n",
      "Epoch 17/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - loss: 1.9883 - main_output_accuracy: 0.6229 - main_output_loss: 1.7013 - tof_gate_loss: 0.0060 - val_loss: 1.8554 - val_main_output_accuracy: 0.5699 - val_main_output_loss: 1.5753 - val_tof_gate_loss: 0.0051\n",
      "Epoch 18/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 170ms/step - loss: 1.8784 - main_output_accuracy: 0.6591 - main_output_loss: 1.5967 - tof_gate_loss: 0.0055 - val_loss: 1.8508 - val_main_output_accuracy: 0.5650 - val_main_output_loss: 1.5716 - val_tof_gate_loss: 0.0042\n",
      "Epoch 19/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 1.9798 - main_output_accuracy: 0.6377 - main_output_loss: 1.7033 - tof_gate_loss: 0.0050 - val_loss: 1.9020 - val_main_output_accuracy: 0.5429 - val_main_output_loss: 1.6295 - val_tof_gate_loss: 0.0046\n",
      "Epoch 20/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 166ms/step - loss: 1.9367 - main_output_accuracy: 0.6522 - main_output_loss: 1.6649 - tof_gate_loss: 0.0041 - val_loss: 1.8542 - val_main_output_accuracy: 0.5706 - val_main_output_loss: 1.5853 - val_tof_gate_loss: 0.0036\n",
      "Epoch 21/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 1.7574 - main_output_accuracy: 0.6948 - main_output_loss: 1.4904 - tof_gate_loss: 0.0040 - val_loss: 1.8293 - val_main_output_accuracy: 0.5663 - val_main_output_loss: 1.5679 - val_tof_gate_loss: 0.0031\n",
      "Epoch 22/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 1.8054 - main_output_accuracy: 0.6763 - main_output_loss: 1.5451 - tof_gate_loss: 0.0036 - val_loss: 1.8413 - val_main_output_accuracy: 0.5736 - val_main_output_loss: 1.5830 - val_tof_gate_loss: 0.0029\n",
      "Epoch 23/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - loss: 1.7408 - main_output_accuracy: 0.7245 - main_output_loss: 1.4825 - tof_gate_loss: 0.0033 - val_loss: 1.8109 - val_main_output_accuracy: 0.5736 - val_main_output_loss: 1.5566 - val_tof_gate_loss: 0.0022\n",
      "Epoch 24/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 163ms/step - loss: 1.7332 - main_output_accuracy: 0.7219 - main_output_loss: 1.4813 - tof_gate_loss: 0.0030 - val_loss: 1.8108 - val_main_output_accuracy: 0.5859 - val_main_output_loss: 1.5606 - val_tof_gate_loss: 0.0025\n",
      "Epoch 25/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - loss: 1.7042 - main_output_accuracy: 0.7283 - main_output_loss: 1.4541 - tof_gate_loss: 0.0024 - val_loss: 1.7940 - val_main_output_accuracy: 0.5742 - val_main_output_loss: 1.5449 - val_tof_gate_loss: 0.0019\n",
      "Epoch 26/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 177ms/step - loss: 1.6654 - main_output_accuracy: 0.7359 - main_output_loss: 1.4189 - tof_gate_loss: 0.0025 - val_loss: 1.8165 - val_main_output_accuracy: 0.5865 - val_main_output_loss: 1.5736 - val_tof_gate_loss: 0.0018\n",
      "Epoch 27/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 1.8003 - main_output_accuracy: 0.7245 - main_output_loss: 1.5571 - tof_gate_loss: 0.0022 - val_loss: 1.7636 - val_main_output_accuracy: 0.5969 - val_main_output_loss: 1.5242 - val_tof_gate_loss: 0.0017\n",
      "Epoch 28/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - loss: 1.7063 - main_output_accuracy: 0.7332 - main_output_loss: 1.4668 - tof_gate_loss: 0.0021 - val_loss: 1.8222 - val_main_output_accuracy: 0.5736 - val_main_output_loss: 1.5851 - val_tof_gate_loss: 0.0017\n",
      "Epoch 29/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - loss: 1.6684 - main_output_accuracy: 0.7563 - main_output_loss: 1.4316 - tof_gate_loss: 0.0019 - val_loss: 1.8676 - val_main_output_accuracy: 0.5601 - val_main_output_loss: 1.6358 - val_tof_gate_loss: 0.0015\n",
      "Epoch 30/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 161ms/step - loss: 1.7234 - main_output_accuracy: 0.7366 - main_output_loss: 1.4896 - tof_gate_loss: 0.0017 - val_loss: 1.7791 - val_main_output_accuracy: 0.5767 - val_main_output_loss: 1.5500 - val_tof_gate_loss: 0.0014\n",
      "Epoch 31/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 160ms/step - loss: 1.6554 - main_output_accuracy: 0.7651 - main_output_loss: 1.4248 - tof_gate_loss: 0.0016 - val_loss: 1.7669 - val_main_output_accuracy: 0.5865 - val_main_output_loss: 1.5395 - val_tof_gate_loss: 0.0015\n",
      "Epoch 32/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - loss: 1.6043 - main_output_accuracy: 0.7787 - main_output_loss: 1.3772 - tof_gate_loss: 0.0016 - val_loss: 1.8035 - val_main_output_accuracy: 0.5791 - val_main_output_loss: 1.5806 - val_tof_gate_loss: 0.0013\n",
      "Epoch 33/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - loss: 1.6180 - main_output_accuracy: 0.7764 - main_output_loss: 1.3941 - tof_gate_loss: 0.0016 - val_loss: 1.8064 - val_main_output_accuracy: 0.5742 - val_main_output_loss: 1.5870 - val_tof_gate_loss: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 161ms/step - loss: 1.5574 - main_output_accuracy: 0.8087 - main_output_loss: 1.3354 - tof_gate_loss: 0.0013 - val_loss: 1.8279 - val_main_output_accuracy: 0.5736 - val_main_output_loss: 1.6104 - val_tof_gate_loss: 0.0011\n",
      "Epoch 35/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 161ms/step - loss: 1.5709 - main_output_accuracy: 0.7880 - main_output_loss: 1.3511 - tof_gate_loss: 0.0014 - val_loss: 1.8057 - val_main_output_accuracy: 0.5816 - val_main_output_loss: 1.5908 - val_tof_gate_loss: 9.8562e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - loss: 1.5091 - main_output_accuracy: 0.7966 - main_output_loss: 1.2923 - tof_gate_loss: 0.0012 - val_loss: 1.8355 - val_main_output_accuracy: 0.5810 - val_main_output_loss: 1.6214 - val_tof_gate_loss: 7.7262e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 160ms/step - loss: 1.3693 - main_output_accuracy: 0.8413 - main_output_loss: 1.1553 - tof_gate_loss: 0.0010 - val_loss: 1.8308 - val_main_output_accuracy: 0.5779 - val_main_output_loss: 1.6210 - val_tof_gate_loss: 7.6783e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 158ms/step - loss: 1.5116 - main_output_accuracy: 0.8120 - main_output_loss: 1.2999 - tof_gate_loss: 0.0010 - val_loss: 1.8600 - val_main_output_accuracy: 0.5804 - val_main_output_loss: 1.6531 - val_tof_gate_loss: 6.9086e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 1.6078 - main_output_accuracy: 0.7894 - main_output_loss: 1.3983 - tof_gate_loss: 9.5806e-04 - val_loss: 1.8136 - val_main_output_accuracy: 0.5761 - val_main_output_loss: 1.6097 - val_tof_gate_loss: 8.5376e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 160ms/step - loss: 1.3416 - main_output_accuracy: 0.8477 - main_output_loss: 1.1336 - tof_gate_loss: 9.5540e-04 - val_loss: 1.8049 - val_main_output_accuracy: 0.5890 - val_main_output_loss: 1.5980 - val_tof_gate_loss: 6.4125e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 163ms/step - loss: 1.5210 - main_output_accuracy: 0.8130 - main_output_loss: 1.3148 - tof_gate_loss: 9.1042e-04 - val_loss: 1.8288 - val_main_output_accuracy: 0.5724 - val_main_output_loss: 1.6239 - val_tof_gate_loss: 6.4703e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - loss: 1.5063 - main_output_accuracy: 0.8356 - main_output_loss: 1.3036 - tof_gate_loss: 8.4404e-04 - val_loss: 1.8227 - val_main_output_accuracy: 0.5779 - val_main_output_loss: 1.6213 - val_tof_gate_loss: 7.0122e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 1.4426 - main_output_accuracy: 0.8498 - main_output_loss: 1.2413 - tof_gate_loss: 8.7142e-04 - val_loss: 1.8406 - val_main_output_accuracy: 0.5779 - val_main_output_loss: 1.6416 - val_tof_gate_loss: 5.6521e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - loss: 1.4771 - main_output_accuracy: 0.8483 - main_output_loss: 1.2777 - tof_gate_loss: 7.4107e-04 - val_loss: 1.8273 - val_main_output_accuracy: 0.5822 - val_main_output_loss: 1.6314 - val_tof_gate_loss: 6.3553e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - loss: 1.5070 - main_output_accuracy: 0.8283 - main_output_loss: 1.3090 - tof_gate_loss: 7.8619e-04 - val_loss: 1.8617 - val_main_output_accuracy: 0.5718 - val_main_output_loss: 1.6684 - val_tof_gate_loss: 5.2630e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - loss: 1.3886 - main_output_accuracy: 0.8665 - main_output_loss: 1.1922 - tof_gate_loss: 7.1382e-04 - val_loss: 1.8275 - val_main_output_accuracy: 0.5755 - val_main_output_loss: 1.6365 - val_tof_gate_loss: 5.1622e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 163ms/step - loss: 1.3755 - main_output_accuracy: 0.8731 - main_output_loss: 1.1811 - tof_gate_loss: 7.0552e-04 - val_loss: 1.8130 - val_main_output_accuracy: 0.5834 - val_main_output_loss: 1.6206 - val_tof_gate_loss: 4.1629e-04\n",
      "--- Fold 2 Best Epoch: 27 ---\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step\n",
      "Fold 2 Accuracy: 0.5969\n",
      "\n",
      "=== Fold 3/5 for End_To_End_CNN ===\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================================\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "NUM_CLASSES = 18\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 5 \n",
    "MAX_PAD_LEN = 128\n",
    "FEATURE_DIR = Path('output')\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "RANDOM_STATE = 42\n",
    "SAMPLING_RATE_HZ = 200 # Use the correct sampling rate\n",
    "\n",
    "from src.merge_feats_dynamic import merge_feature_sets\n",
    "from src.functions import create_sequence_dataset, generate_gate_targets, train_model\n",
    "from src.imu_physics_feats import calculate_angular_velocity\n",
    "from src.nn_blocks import GatedMixupGenerator\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "def create_end_to_end_model(input_shape, imu_dim, wd=1e-4):\n",
    "    inp = tf.keras.layers.Input(shape=input_shape)\n",
    "    imu = tf.keras.layers.Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof_thm = tf.keras.layers.Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # --- IMU Branch: Learns from raw acc and rot ---\n",
    "    # A deep CNN tower to extract hierarchical features from the raw IMU signals.\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.2, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.2, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 256, 7, drop=0.2, wd=wd) # Shape: (None, 16, 256)\n",
    "    \n",
    "    # --- ToF/Thm Branch: Learns from raw pixels and temperatures ---\n",
    "    # A lighter CNN tower to handle the high dimensionality of the raw ToF/Thm data.\n",
    "    x2 = residual_se_cnn_block(tof_thm, 64, 3, drop=0.2, wd=wd)\n",
    "    x2 = residual_se_cnn_block(x2, 128, 5, drop=0.2, wd=wd) # Shape: (None, 32, 128)\n",
    "    # Project to match the IMU branch's feature dimension\n",
    "    x2 = Conv1D(256, 1, padding='same', activation='relu')(x2) # Shape: (None, 32, 256)\n",
    "\n",
    "    # --- Merge and Classify ---\n",
    "    # Use the standard features_processing block to merge and learn context\n",
    "    x = features_processing(x1, x2)\n",
    "    x = Dropout(0.3)(x) \n",
    "    main_out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"main_output\")(x)\n",
    "    gate_out = Dense(1, activation=\"sigmoid\", name=\"tof_gate\")(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs={\"main_output\": main_out, \"tof_gate\": gate_out})\n",
    "\n",
    "# =====================================================================================\n",
    "# TRAINING LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "# --- Step 1: Load and Clean RAW Data ---\n",
    "print(\"  Loading and cleaning raw data from train.csv...\")\n",
    "RAW_DIR = Path('input/cmi-detect-behavior-with-sensor-data')\n",
    "df = pl.read_csv(RAW_DIR / \"train.csv\")\n",
    "demographics_df = pl.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "df = df.join(demographics_df, on='subject', how='left')\n",
    "\n",
    "# Define all columns that contain sensor readings\n",
    "sensor_cols = [c for c in df.columns if c.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]\n",
    "\n",
    "# Clean the raw data by replacing -1 and imputing nulls.\n",
    "df = df.with_columns(\n",
    "    [pl.when(pl.col(c) == -1).then(None).otherwise(pl.col(c)).alias(c) for c in sensor_cols]\n",
    ").with_columns(\n",
    "    pl.col(sensor_cols).forward_fill().backward_fill().fill_null(0).over(\"sequence_id\")\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "gesture_encoded = le.fit_transform(df.get_column('gesture'))\n",
    "final_df = df.with_columns(pl.Series(\"gesture_int\", gesture_encoded))  \n",
    "print(f\"  Final DataFrame created with shape: {final_df.shape}\")\n",
    "\n",
    "# --- Step 2: Define Feature Columns from RAW Data ---\n",
    "raw_imu_cols = [c for c in final_df.columns if c.startswith(('acc_', 'rot_'))]\n",
    "raw_tof_thm_cols = [c for c in final_df.columns if c.startswith(('thm_', 'tof_'))]\n",
    "all_feature_cols = raw_imu_cols + raw_tof_thm_cols\n",
    "imu_dim = len(raw_imu_cols)\n",
    "print(f\"  Training with {len(all_feature_cols)} total raw features ({imu_dim} IMU).\")    \n",
    "\n",
    "# Reorder the DataFrame to match the required structure for the model.\n",
    "metadata_to_keep = ['sequence_id', 'sequence_counter', 'gesture', 'gesture_int', 'subject']\n",
    "final_df = final_df.select(metadata_to_keep + all_feature_cols)\n",
    "print(\"  DataFrame columns have been reordered for the model.\")\n",
    "\n",
    "# --- Step 3: Prepare for Cross-Validation ---\n",
    "cv_info = final_df.group_by(\"sequence_id\").agg(pl.first(\"gesture_int\")).sort(\"sequence_id\")\n",
    "all_sequence_ids = cv_info.get_column(\"sequence_id\").to_numpy()\n",
    "y_for_split = cv_info.get_column(\"gesture_int\").to_numpy()\n",
    "\n",
    "input_shape = (MAX_PAD_LEN, len(all_feature_cols)) \n",
    "model_results = {}\n",
    "model_builders = [(\"End_To_End_CNN\", lambda: create_end_to_end_model(input_shape, imu_dim))]\n",
    "\n",
    "for model_name, model_builder in model_builders:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training and Evaluating Model: {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    best_epochs = []\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_sequence_ids, y_for_split)):\n",
    "        print(f\"\\n=== Fold {fold_idx + 1}/{N_SPLITS} for {model_name} ===\")\n",
    "        train_ids = all_sequence_ids[train_indices]\n",
    "        val_ids = all_sequence_ids[val_indices]\n",
    "\n",
    "        train_df = final_df.filter(pl.col('sequence_id').is_in(train_ids))\n",
    "        val_df = final_df.filter(pl.col('sequence_id').is_in(val_ids))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        train_features_scaled = scaler.fit_transform(train_df.select(all_feature_cols))\n",
    "        val_features_scaled = scaler.transform(val_df.select(all_feature_cols))\n",
    "        \n",
    "        X_train_scaled_features = pl.DataFrame(train_features_scaled, schema=all_feature_cols)\n",
    "        X_val_scaled_features = pl.DataFrame(val_features_scaled, schema=all_feature_cols)\n",
    "\n",
    "        meta_cols_to_keep = ['sequence_id', 'sequence_counter', 'gesture_int']\n",
    "        train_df_final = train_df.select(meta_cols_to_keep).with_columns(X_train_scaled_features)\n",
    "        val_df_final = val_df.select(meta_cols_to_keep).with_columns(X_val_scaled_features)\n",
    "\n",
    "        # Gate target is based on raw ToF columns\n",
    "        tof_v_cols = [c for c in train_df.columns if c.startswith('tof_v')]\n",
    "        train_gate_target_df = generate_gate_targets(train_df, tof_v_cols)\n",
    "        val_gate_target_df = generate_gate_targets(val_df, tof_v_cols)\n",
    "\n",
    "        X_train, y_train, train_gate_target = create_sequence_dataset(train_df_final, all_feature_cols, train_gate_target_df)\n",
    "        X_val, y_val, val_gate_target = create_sequence_dataset(val_df_final, all_feature_cols, val_gate_target_df)\n",
    "\n",
    "        X_train_padded = pad_sequences(X_train, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        X_val_padded = pad_sequences(X_val, maxlen=MAX_PAD_LEN, padding='post', truncating='post', dtype='float32')\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "        \n",
    "        train_dataset = GatedMixupGenerator(\n",
    "            X=X_train_padded, y=y_train_cat, gate_targets=train_gate_target,\n",
    "            batch_size=BATCH_SIZE, imu_dim=imu_dim, alpha=0.2, masking_prob=0.25\n",
    "        )\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            X_val_padded, {'main_output': y_val_cat, 'tof_gate': val_gate_target[:, np.newaxis]}\n",
    "        )).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        del X_train, y_train, X_val, y_val, X_train_padded, X_val_padded\n",
    "        gc.collect()\n",
    "        \n",
    "        model = model_builder()\n",
    "        history = train_model(model, train_dataset, val_dataset, 150, LR_INIT, WD)\n",
    "        \n",
    "        monitor_metric = 'val_main_output_accuracy'\n",
    "        best_epoch = np.argmax(history.history[monitor_metric]) + 1\n",
    "        best_epochs.append(best_epoch)\n",
    "        print(f\"--- Fold {fold_idx + 1} Best Epoch: {best_epoch} ---\")\n",
    "\n",
    "        val_preds = model.predict(val_dataset)\n",
    "        main_output_preds = val_preds['main_output']\n",
    "        \n",
    "        y_pred_fold = np.argmax(main_output_preds, axis=1)\n",
    "        y_true_fold = np.argmax(y_val_cat, axis=1)\n",
    "        fold_acc = accuracy_score(y_true_fold, y_pred_fold)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {fold_acc:.4f}\")\n",
    "        all_preds.append(y_pred_fold)\n",
    "        all_labels.append(y_true_fold)\n",
    "\n",
    "        del train_dataset, model, val_dataset\n",
    "        gc.collect()\n",
    "\n",
    "    # --- FINAL OOF REPORT for this model architecture ---\n",
    "    print(f\"\\n=== OOF Summary for {model_name} ===\")\n",
    "    print(f\"Per-fold Accuracies: {[round(a, 4) for a in fold_accuracies]}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    \n",
    "    # --- NEW: Report on the best epochs found ---\n",
    "    avg_best_epoch = int(np.mean(best_epochs))\n",
    "    print(f\"Best epochs per fold: {best_epochs}\")\n",
    "    print(f\"Average best epoch: {avg_best_epoch}\")\n",
    "    \n",
    "    # Store the results for this model\n",
    "    model_results[model_name] = {\n",
    "        'mean_accuracy': np.mean(fold_accuracies),\n",
    "        'avg_best_epoch': avg_best_epoch\n",
    "    }\n",
    "\n",
    "    y_all_pred = np.concatenate(all_preds)\n",
    "    y_all_true = np.concatenate(all_labels)\n",
    "    print(\"\\n=== Overall Classification Report ===\")\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# --- FINAL SUMMARY ACROSS ALL MODELS ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"▶ FINAL MODEL EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for model_name, results in model_results.items():\n",
    "    print(f\"  - {model_name}: Mean Accuracy = {results['mean_accuracy']:.4f}, Avg Best Epoch = {results['avg_best_epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddba87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "class ImuFeatureExtractorPT(nn.Module):\n",
    "    def __init__(self,fs=100.,**kwargs):\n",
    "        super().__init__()\n",
    "        self.fs=fs\n",
    "        k=15\n",
    "        self.lpf=nn.Conv1d(6,6,k,padding=k//2,groups=6,bias=False)\n",
    "        nn.init.kaiming_uniform_(self.lpf.weight,a=math.sqrt(5))\n",
    "        self.lpf_acc=nn.Conv1d(3,3,k,padding=k//2,groups=3,bias=False)\n",
    "        self.lpf_gyro=nn.Conv1d(3,3,k,padding=k//2,groups=3,bias=False)\n",
    "\n",
    "        def forward(self,imu):\n",
    "            acc,gyro=imu[:,:3,:],imu[:,3:6,:]\n",
    "            acc_mag,gyro_mag=torch.norm(acc,dim=1,keepdim=True),torch.norm(gyro,dim=1,keepdim=True)\n",
    "            jerk,gyro_delta=F.pad(acc[:,:,1:]-acc[:,:,:-1],(1,0)),F.pad(gyro[:,:,1:]-gyro[:,:,:-1],(1,0))\n",
    "            acc_pow,gyro_pow=acc**2,gyro**2\n",
    "            acc_lpf,acc_hpf=self.lpf_acc(acc),acc-self.lpf_acc(acc)\n",
    "            gyro_lpf,gyro_hpf=self.lpf_gyro(gyro),gyro-self.lpf_gyro(gyro)\n",
    "            return torch.cat([acc,gyro,acc_mag,gyro_mag,jerk,gyro_delta,acc_pow,gyro_pow,acc_lpf,acc_hpf,gyro_lpf,gyro_hpf],dim=1)\n",
    "        \n",
    "class SEBlockPT(nn.Module):\n",
    "    def __init__(self,c,r=8):\n",
    "        super().__init__()\n",
    "        self.squeeze=nn.AdaptiveAvgPool1d(1)\n",
    "        self.excitation=nn.Sequential(nn.Linear(c,c//r,bias=False),nn.ReLU(inplace=True),nn.Linear(c//r,c,bias=False),nn.Sigmoid())\n",
    "        def forward(self,x):b,c,_=x.size()\n",
    "        y=self.squeeze(x).view(b,c)\n",
    "        y=self.excitation(y).view(b,c,1)\n",
    "        return x*y.expand_as(x)\n",
    "        \n",
    "class ResidualSECNNBlockPT(nn.Module):\n",
    "    def __init__(self,i,o,k,p=2,d=0.3):\n",
    "        super().__init__()\n",
    "        self.c1,self.b1=nn.Conv1d(i,o,k,padding=k//2,bias=False),nn.BatchNorm1d(o)\n",
    "        self.c2,self.b2=nn.Conv1d(o,o,k,padding=k//2,bias=False),nn.BatchNorm1d(o)\n",
    "        self.se=SEBlockPT(o)\n",
    "        self.s=nn.Sequential(nn.Conv1d(i,o,1,bias=False),nn.BatchNorm1d(o))if i!=o else nn.Identity()\n",
    "        self.p,self.d=nn.MaxPool1d(p),nn.Dropout(d)\n",
    "        def forward(self,x):o=F.relu(self.b1(self.c1(x)))\n",
    "        o=self.b2(self.c2(o))\n",
    "        o=self.se(o)+self.s(x)\n",
    "        return self.d(self.p(F.relu(o)))\n",
    "    \n",
    "class PublicTwoBranchModel(nn.Module):\n",
    "    def __init__(self,p,i,t,n,d=[0.3]*4+[0.4,0.5,0.3],f=True,**kwargs):\n",
    "        super().__init__()\n",
    "        imu_dim=32 if f else i\n",
    "        self.imu_fe=ImuFeatureExtractorPT(**kwargs)if f else nn.Identity()\n",
    "        self.fn=7\n",
    "        fk=torch.tensor(firwin(33,1.0,fs=10.0,pass_zero=False),dtype=torch.float32).view(1,1,-1).repeat(self.fn,1,1)\n",
    "        self.register_buffer(\"fk\",fk)\n",
    "        self.ib1,self.ib2=ResidualSECNNBlockPT(imu_dim,64,3,d=d[0]),ResidualSECNNBlockPT(64,128,5,d=d[1])\n",
    "        self.tc1,self.tb1,self.tp1,self.td1=nn.Conv1d(t,64,3,padding=1,bias=False),nn.BatchNorm1d(64),nn.MaxPool1d(2),nn.Dropout(d[2])\n",
    "        self.tc2,self.tb2,self.tp2,self.td2=nn.Conv1d(64,128,3,padding=1,bias=False),nn.BatchNorm1d(128),nn.MaxPool1d(2),nn.Dropout(d[3])\n",
    "        self.bilstm,self.ld=nn.LSTM(256,128,bidirectional=True,batch_first=True),nn.Dropout(d[4])\n",
    "        self.att=type('A',(nn.Module,),{'__init__':lambda s,h:super(type(s),s).__init__()or setattr(s,'a',nn.Linear(h,1)),'forward':lambda s,x:torch.sum(x*F.softmax(torch.tanh(s.a(x)).squeeze(-1),dim=1).unsqueeze(-1),dim=1)})(256)\n",
    "        self.d1,self.bnd1,self.dr1=nn.Linear(256,256,bias=False),nn.BatchNorm1d(256),nn.Dropout(d[5])\n",
    "        self.d2,self.bnd2,self.dr2=nn.Linear(256,128,bias=False),nn.BatchNorm1d(128),nn.Dropout(d[6])\n",
    "        self.clf=nn.Linear(128,n)\n",
    "        self.m=torch.tensor([0,0,0,0,0,0,9e-3,1.08, -2.6e-3,3.7e-3,-5.3e-3,-2.8e-3,1.3e-3,-1.5e-4,0.63,0.62,0.60,0.62,0.63,0.65,7.4e-3,-3.4e-3,-7.5e-3,-2.6e-2,2.9e-2,-3.1e-2,-2e-3,-4.7e-3,-4.7e-3,-2.6e-2,1.5e-2,1e-2],dtype=torch.float32).view(1,-1,1).to(device)\n",
    "        self.s=torch.tensor([1,1,1,1,1,1,0.2,0.85,0.31,0.26,0.29,0.23,0.3,0.32,1.02,0.88,0.86,1.09,1.02,0.9,0.46,0.2,0.2,1.22,0.95,0.66,0.29,0.34,0.81,0.65,1.1,1.55],dtype=torch.float32).view(1,-1,1).to(device)+1e-8\n",
    "\n",
    "    def forward(self,x):\n",
    "        ir,t=x[:,:,:self.fn].transpose(1,2),x[:,:,self.fn:].transpose(1,2)\n",
    "        ife=self.imu_fe(ir)\n",
    "        fl=F.conv1d(ife[:,:self.fn,:],self.fk,padding=self.fk.shape[-1]//2,groups=self.fn)\n",
    "        imu=(torch.cat([fl,ife[:,self.fn:,:]],dim=1)-self.m)/self.s\n",
    "        x1=self.ib2(self.ib1(imu))\n",
    "        x2=self.td2(self.tp2(F.relu(self.tb2(self.tc2(self.td1(self.tp1(F.relu(self.tb1(self.tc1(t))))))))))\n",
    "        lo,_=self.bilstm(torch.cat([x1,x2],dim=1).transpose(1,2))\n",
    "        a=self.att(self.ld(lo))\n",
    "        x=self.dr1(F.relu(self.bnd1(self.d1(a))))\n",
    "        x=self.dr2(F.relu(self.bnd2(self.d2(x))))\n",
    "        return self.clf(x)\n",
    "        \n",
    "    def pad_sequences_torch(s,m,p='post',v=0.0):\n",
    "        r=[]\n",
    "        [r.append(i[:m]if len(i)>=m else np.concatenate([i,np.full((m-len(i),i.shape[1]),v,dtype=np.float32)]if p=='post'else[np.full((m-len(i),i.shape[1]),v,dtype=np.float32),i]))for i in s]\n",
    "        return np.array(r,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3053055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlockKeras(tf.keras.layers.Layer):\n",
    "    def __init__(self,r=8,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r=r\n",
    "\n",
    "    def build(self,s):\n",
    "        c=s[-1]\n",
    "        self.gap=GlobalAveragePooling1D()\n",
    "        self.d1=Dense(c//self.r,activation='relu')\n",
    "        self.d2=Dense(c,activation='sigmoid')\n",
    "        self.rs=Reshape((1,c))\n",
    "        super().build(s)\n",
    "    \n",
    "    def call(self,i):return Multiply()([i,self.rs(self.d2(self.d1(self.gap(i))))])\n",
    "\n",
    "    def get_config(self):\n",
    "        c=super().get_config()\n",
    "        c.update({'r':self.r})\n",
    "        return c\n",
    "\n",
    "class ResidualSECNNBlockKeras(tf.keras.layers.Layer):\n",
    "    def __init__(self,f,k,p=2,d=0.3,wd=1e-4,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.f,self.k,self.p,self.d,self.wd=f,k,p,d,wd\n",
    "        self.c1=Conv1D(f,k,padding='same',use_bias=False,kernel_regularizer=l2(wd))\n",
    "        self.b1=BatchNormalization()\n",
    "        self.c2=Conv1D(f,k,padding='same',use_bias=False,kernel_regularizer=l2(wd))\n",
    "        self.b2=BatchNormalization()\n",
    "        self.se=SEBlockKeras()\n",
    "        self.pool=MaxPooling1D(p)\n",
    "        self.drop=Dropout(d)\n",
    "\n",
    "    def build(self,s):\n",
    "        self.s_conv=Conv1D(self.f,1,padding='same',use_bias=False,kernel_regularizer=l2(self.wd))if s[-1]!=self.f else None\n",
    "        super().build(s)\n",
    "\n",
    "    def call(self,i):\n",
    "        x=Activation('relu')(self.b1(self.c1(i)))\n",
    "        x=self.b2(self.c2(x))\n",
    "        s=self.s_conv(i)if self.s_conv else i\n",
    "        x=self.se(x)\n",
    "        x=add([x,s])\n",
    "        return self.drop(self.pool(Activation('relu')(x)))\n",
    "    def get_config(self):\n",
    "        c=super().get_config()\n",
    "        c.update({'f':self.f,'k':self.k,'p':self.p,'d':self.d,'wd':self.wd})\n",
    "        return c\n",
    "    \n",
    "class TransformerEncoderKeras(tf.keras.layers.Layer):\n",
    "    def __init__(self,hs,nh,ffd,d=0.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hs,self.nh,self.ffd,self.d=hs,nh,ffd,d\n",
    "        self.mha=MultiHeadAttention(key_dim=hs,num_heads=nh,dropout=d)\n",
    "        self.d1=Dropout(d)\n",
    "        self.ln1=LayerNormalization(epsilon=1e-6)\n",
    "        self.d_ff1=Dense(ffd,activation=\"relu\")\n",
    "        self.d_ff2=Dense(ffd)\n",
    "        self.d2=Dropout(d)\n",
    "        self.ln2=LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def build(self,s):\n",
    "        self.out_d=Dense(s[-1])\n",
    "        super().build(s)\n",
    "    \n",
    "    def call(self,i):\n",
    "        x=self.ln1(i)\n",
    "        x=self.mha(x,x)\n",
    "        x=self.d1(x)\n",
    "        res=x+i\n",
    "        x=self.ln2(res)\n",
    "        x=self.d_ff1(x)\n",
    "        x=self.d_ff2(x)\n",
    "        x=self.d2(x)\n",
    "        x=self.out_d(x)\n",
    "        return x+res\n",
    "    \n",
    "    def get_config(self):\n",
    "        c=super().get_config()\n",
    "        c.update({'hs':self.hs,'nh':self.nh,'ffd':self.ffd,'d':self.d})\n",
    "        return c\n",
    "\n",
    "def build_transformer_model(pad_len,imu_dim,tof_dim,n_classes,wd=1e-4):\n",
    "    inp=Input(shape=(pad_len,imu_dim+tof_dim))\n",
    "    x=GaussianNoise(0.01)(inp)\n",
    "    imu,tof=Lambda(lambda t:t[:,:,:imu_dim])(x),Lambda(lambda t:t[:,:,imu_dim:])(x)\n",
    "    x1=ResidualSECNNBlockKeras(64,3,d=0.2,wd=wd)(imu)\n",
    "    x1=ResidualSECNNBlockKeras(128,5,d=0.2,wd=wd)(x1)\n",
    "    x2_base=ResidualSECNNBlockKeras(64,3,d=0.25,wd=wd)(tof)\n",
    "    x2_base=ResidualSECNNBlockKeras(128,3,d=0.25,wd=wd)(x2_base)\n",
    "    gate=Dense(1,'sigmoid',name='tof_gate')(GlobalAveragePooling1D()(tof))\n",
    "    x2=Multiply()([x2_base,gate])\n",
    "    x=Concatenate()([x1,x2])\n",
    "    x=Bidirectional(LSTM(256,return_sequences=True,kernel_regularizer=l2(wd)))(x)\n",
    "    x=TransformerEncoderKeras(128,4,x.shape[-1],d=0.3)(x)\n",
    "    x=GlobalAveragePooling1D()(x)\n",
    "    for u,d in[(512,0.5),(128,0.3)]:x=Dropout(d)(Activation('relu')(BatchNormalization()(Dense(u,use_bias=False,kernel_regularizer=l2(wd))(x))))\n",
    "    return Model(inputs=inp,outputs=[Dense(n_classes,'softmax',name='main_output')(x),gate])\n",
    "\n",
    "model = build_transformer_model(pad_len, imu_dim, tof_dim, len(le.classes_), wd=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 95      \n",
    "LR_INIT = 5e-4 \n",
    "WD = 3e-3      \n",
    "MIXUP_ALPHA = 0.4       \n",
    "EPOCHS = 200   \n",
    "PATIENCE = 60  \n",
    "N_SPLITS = 5   \n",
    "MASKING_PROB = 0.25      \n",
    "GATE_LOSS_WEIGHT = 0.2  \n",
    "\n",
    "if TRAIN:\n",
    "    print(\"▶ 学習モード開始\")\n",
    "    # (このセクションの大部分は変更ありません)\n",
    "    df = pd.read_csv(RAW_DIR/\"train.csv\").merge(pd.read_csv(RAW_DIR/\"train_demographics.csv\"), on='subject')\n",
    "    le = LabelEncoder()\n",
    "    df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "    \n",
    "    print(\"  特徴量生成中...\")\n",
    "    all_sequences = []\n",
    "    # (特徴量生成のループ... 変更なし)\n",
    "    for _, seq_df in tqdm(df.groupby('sequence_id'), desc=\"特徴量生成\"):\n",
    "        s = seq_df.copy().fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "        s[['linear_acc_x','linear_acc_y','linear_acc_z']] = remove_gravity_from_acc(s)\n",
    "        s[['angular_vel_x','angular_vel_y','angular_vel_z']] = calculate_angular_velocity_from_quat(s)\n",
    "        s['linear_acc_mag'] = np.linalg.norm(s[['linear_acc_x','linear_acc_y','linear_acc_z']].values, axis=1)\n",
    "        s['linear_acc_mag_jerk'] = s['linear_acc_mag'].diff().fillna(0)\n",
    "        s['angular_distance'] = calculate_angular_distance(s)\n",
    "        for i in range(1, 6):\n",
    "            if f'tof_{i}_v0' in s.columns:\n",
    "                pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "                tof_data = s[pixel_cols].replace(-1, np.nan)\n",
    "                s[f\"tof_{i}_mean\"], s[f\"tof_{i}_std\"] = tof_data.mean(axis=1), tof_data.std(axis=1)\n",
    "        all_sequences.append(s)\n",
    "    \n",
    "    df = pd.concat(all_sequences).fillna(0)\n",
    "    \n",
    "    imu_cols = [c for c in df.columns if any(s in c for s in ['acc_','rot_','angular_']) and 'uncalib' not in c]\n",
    "    tof_cols = [c for c in df.columns if 'tof_' in c or 'thm_' in c]\n",
    "    final_feature_cols = imu_cols + tof_cols\n",
    "    imu_dim, tof_dim = len(imu_cols), len(tof_cols)\n",
    "    print(f\"  特徴量数: IMU={imu_dim}, TOF/THM={tof_dim}, Total={len(final_feature_cols)}\")\n",
    "    \n",
    "    X_list, y_list, groups, lens = [], [], [], []\n",
    "    for _, seq_df in df.groupby('sequence_id'):\n",
    "        X_list.append(seq_df[final_feature_cols].values.astype('float32'))\n",
    "        y_list.append(seq_df['gesture_int'].iloc[0])\n",
    "        groups.append(seq_df['subject'].iloc[0])\n",
    "        lens.append(len(seq_df))\n",
    "    \n",
    "    scaler = StandardScaler().fit(np.concatenate(X_list, axis=0))\n",
    "    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n",
    "    X = pad_sequences([scaler.transform(x) for x in X_list], maxlen=pad_len, padding='post', dtype='float32')\n",
    "    y_cat, y_stratify = to_categorical(y_list), np.array(y_list)\n",
    "    \n",
    "    oof_A = np.zeros_like(y_cat)\n",
    "    sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y_stratify, groups)):\n",
    "        print(f\"\\n===== FOLD {fold+1}/{N_SPLITS} =====\")\n",
    "        X_tr, X_val, y_tr, y_val = X[train_idx], X[val_idx], y_cat[train_idx], y_cat[val_idx]\n",
    "        model = build_transformer_model(pad_len, imu_dim, tof_dim, len(le.classes_), wd=WD)\n",
    "        model.compile(optimizer=AdamTF(CosineDecay(LR_INIT, len(X_tr)//BATCH_SIZE*EPOCHS)),\n",
    "                      loss={'main_output': 'categorical_crossentropy', 'tof_gate': 'binary_crossentropy'},\n",
    "                      loss_weights={'main_output': 1.0, 'tof_gate': GATE_LOSS_WEIGHT},\n",
    "                      metrics={'main_output': 'accuracy'})\n",
    "        cw = dict(enumerate(compute_class_weight('balanced', classes=np.unique(y_list), y=y_tr.argmax(1))))\n",
    "        train_gen = GatedMixupGenerator(X_tr, y_tr, BATCH_SIZE, imu_dim, w=cw, a=MIXUP_ALPHA, m=MASKING_PROB)\n",
    "        val_gen = GatedMixupGenerator(X_val, y_val, BATCH_SIZE, imu_dim)\n",
    "        cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_main_output_accuracy', mode='max')\n",
    "        model.fit(train_gen, epochs=EPOCHS, validation_data=val_gen, callbacks=[cb], verbose=1)\n",
    "        model.export(EXPORT_DIR / f\"model_A_fold_{fold}\")\n",
    "        \n",
    "        oof_A[val_idx], _ = model.predict(X_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    if CompetitionMetric is not None:\n",
    "        oof_score = CompetitionMetric().calculate_hierarchical_f1(pd.DataFrame({'gesture':le.classes_[y_cat.argmax(1)]}), pd.DataFrame({'gesture':le.classes_[oof_A.argmax(1)]}))\n",
    "        print(f\"\\n\\n=================================================\\n  CVスコア (OOF H-F1 Score): {oof_score:.4f}\\n=================================================\\n\")\n",
    "    \n",
    "    joblib.dump(scaler, EXPORT_DIR/\"scaler.pkl\")\n",
    "    np.save(EXPORT_DIR/\"final_feature_cols.npy\", np.array(final_feature_cols))\n",
    "    np.save(EXPORT_DIR/\"gesture_classes.npy\", le.classes_)\n",
    "    np.save(EXPORT_DIR/\"sequence_maxlen.npy\", pad_len)\n",
    "    print(\"✔ 学習と成果物の保存が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final(sequence:pl.DataFrame,demographics:pl.DataFrame)->str:\n",
    "    import numpy as np_local\n",
    "    from tensorflow.keras.utils import pad_sequences as pad_sequences_local\n",
    "    from scipy.stats import rankdata as rankdata_local\n",
    "    import torch as torch_local\n",
    "    scaler_B=joblib.load(PUBLIC_TF_MODEL_DIR/\"scaler.pkl\")\n",
    "    final_feature_cols_B=np_local.load(PUBLIC_TF_MODEL_DIR/\"feature_cols.npy\",allow_pickle=True).tolist()\n",
    "    pad_len_B=int(np_local.load(PUBLIC_TF_MODEL_DIR/\"sequence_maxlen.npy\"))\n",
    "    scaler_C=joblib.load(PUBLIC_PT_MODEL_DIR/\"scaler.pkl\")\n",
    "    final_feature_cols_C=np_local.load(PUBLIC_PT_MODEL_DIR/\"feature_cols.npy\",allow_pickle=True).tolist()\n",
    "    pad_len_C=int(np_local.load(PUBLIC_PT_MODEL_DIR/\"sequence_maxlen.npy\"))\n",
    "    df=sequence.to_pandas().fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "    df_A=df.copy()\n",
    "    df_A[['linear_acc_x','linear_acc_y','linear_acc_z']]=remove_gravity_from_acc(df_A)\n",
    "    df_A[['angular_vel_x','angular_vel_y','angular_vel_z']]=calculate_angular_velocity_from_quat(df_A)\n",
    "    df_A['linear_acc_mag']=np_local.linalg.norm(df_A[['linear_acc_x','linear_acc_y','linear_acc_z']].values,axis=1)\n",
    "    df_A['linear_acc_mag_jerk']=df_A['linear_acc_mag'].diff().fillna(0)\n",
    "    df_A['angular_distance']=calculate_angular_distance(df_A)\n",
    "\n",
    "    for i in range(1,6):\n",
    "        if f'tof_{i}_v0' in df_A.columns:\n",
    "            p=[f\"tof_{i}_v{p}\"for p in range(64)]\n",
    "            t=df_A[p].replace(-1,np_local.nan)\n",
    "            df_A[f\"tof_{i}_mean\"],df_A[f\"tof_{i}_std\"]=t.mean(axis=1),t.std(axis=1)\n",
    "\n",
    "    df_A=df_A.fillna(0)\n",
    "    mat_A=scaler_A.transform(df_A[final_feature_cols_A].values.astype(np_local.float32))\n",
    "    pad_A=pad_sequences_local([mat_A],maxlen=pad_len_A,padding='post',dtype='float32')\n",
    "    pred_A=np_local.mean([m.predict(pad_A,verbose=0)[0]for m in models_A],axis=0)\n",
    "    df_B=df.copy()\n",
    "    df_B['acc_mag']=np_local.sqrt(df_B['acc_x']**2+df_B['acc_y']**2+df_B['acc_z']**2)\n",
    "    df_B['rot_angle']=2*np_local.arccos(df_B['rot_w'].clip(-1,1))\n",
    "    df_B['acc_mag_jerk']=df_B['acc_mag'].diff().fillna(0)\n",
    "    df_B['rot_angle_vel']=df_B['rot_angle'].diff().fillna(0)\n",
    "    df_B[['linear_acc_x','linear_acc_y','linear_acc_z']]=remove_gravity_from_acc(df_B)\n",
    "    df_B['linear_acc_mag']=np_local.linalg.norm(df_B[['linear_acc_x','linear_acc_y','linear_acc_z']].values,axis=1)\n",
    "    df_B['linear_acc_mag_jerk']=df_B['linear_acc_mag'].diff().fillna(0)\n",
    "    df_B[['angular_vel_x','angular_vel_y','angular_vel_z']]=calculate_angular_velocity_from_quat(df_B)\n",
    "    df_B['angular_distance']=calculate_angular_distance(df_B)\n",
    "    df_B=df_B.fillna(0)\n",
    "    mat_B=scaler_B.transform(df_B[final_feature_cols_B].values.astype(np_local.float32))\n",
    "    pad_B=pad_sequences_local([mat_B],maxlen=pad_len_B,padding='post',dtype='float32')\n",
    "    pred_B=model_B.predict(pad_B,verbose=0)[0]\n",
    "    df_C=df.copy().fillna(0)\n",
    "    mat_C=scaler_C.transform(df_C[final_feature_cols_C].values.astype(np_local.float32))\n",
    "    pad_C=pad_sequences_torch([mat_C],maxlen=pad_len_C,padding='post')\n",
    "    \n",
    "    with torch.no_grad():pt_input=torch.from_numpy(pad_C).to(device)\n",
    "        preds_C=[m(pt_input)for m in pt_models]\n",
    "        pred_C=torch.mean(torch.stack(preds_C),dim=0).cpu().numpy()[0]\n",
    "        final_rank=(rankdata_local(pred_A)+rankdata_local(pred_B)+rankdata_local(pred_C))/3.0\n",
    "        return str(gesture_classes[np_local.argmax(final_rank)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
