{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c7733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset …\n",
      "  Removing gravity and calculating linear acceleration features...\n",
      "  Calculating angular velocity and distance from quaternions...\n",
      "  Total 38 features will be engineered.\n",
      "  Building list of processed sequences...\n",
      "  Concatenating all processed sequences into a single DataFrame...\n",
      "\n",
      "Processing complete. Final DataFrame created.\n",
      "Final DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 574945 entries, 0 to 574944\n",
      "Data columns (total 42 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   sequence_id          574945 non-null  object \n",
      " 1   subject              574945 non-null  object \n",
      " 2   gesture              574945 non-null  object \n",
      " 3   gesture_int          574945 non-null  int64  \n",
      " 4   linear_acc_x         574945 non-null  float64\n",
      " 5   linear_acc_y         574945 non-null  float64\n",
      " 6   linear_acc_z         574945 non-null  float64\n",
      " 7   rot_w                574945 non-null  float64\n",
      " 8   rot_x                574945 non-null  float64\n",
      " 9   rot_y                574945 non-null  float64\n",
      " 10  rot_z                574945 non-null  float64\n",
      " 11  linear_acc_mag       574945 non-null  float64\n",
      " 12  linear_acc_mag_jerk  574945 non-null  float64\n",
      " 13  angular_vel_x        574945 non-null  float64\n",
      " 14  angular_vel_y        574945 non-null  float64\n",
      " 15  angular_vel_z        574945 non-null  float64\n",
      " 16  angular_distance     574945 non-null  float64\n",
      " 17  thm_1                574945 non-null  float64\n",
      " 18  thm_2                574945 non-null  float64\n",
      " 19  thm_3                574945 non-null  float64\n",
      " 20  thm_4                574945 non-null  float64\n",
      " 21  thm_5                574945 non-null  float64\n",
      " 22  tof_1_mean           574945 non-null  float64\n",
      " 23  tof_1_std            574945 non-null  float64\n",
      " 24  tof_1_min            574945 non-null  float64\n",
      " 25  tof_1_max            574945 non-null  float64\n",
      " 26  tof_2_mean           574945 non-null  float64\n",
      " 27  tof_2_std            574945 non-null  float64\n",
      " 28  tof_2_min            574945 non-null  float64\n",
      " 29  tof_2_max            574945 non-null  float64\n",
      " 30  tof_3_mean           574945 non-null  float64\n",
      " 31  tof_3_std            574945 non-null  float64\n",
      " 32  tof_3_min            574945 non-null  float64\n",
      " 33  tof_3_max            574945 non-null  float64\n",
      " 34  tof_4_mean           574945 non-null  float64\n",
      " 35  tof_4_std            574945 non-null  float64\n",
      " 36  tof_4_min            574945 non-null  float64\n",
      " 37  tof_4_max            574945 non-null  float64\n",
      " 38  tof_5_mean           574945 non-null  float64\n",
      " 39  tof_5_std            574945 non-null  float64\n",
      " 40  tof_5_min            574945 non-null  float64\n",
      " 41  tof_5_max            574945 non-null  float64\n",
      "dtypes: float64(38), int64(1), object(3)\n",
      "memory usage: 184.2+ MB\n",
      "\n",
      "Final DataFrame Head:\n",
      "  sequence_id      subject             gesture  gesture_int  linear_acc_x  \\\n",
      "0  SEQ_000007  SUBJ_059520  Cheek - pinch skin            1     -0.138540   \n",
      "1  SEQ_000007  SUBJ_059520  Cheek - pinch skin            1      0.237503   \n",
      "2  SEQ_000007  SUBJ_059520  Cheek - pinch skin            1     -0.469262   \n",
      "3  SEQ_000007  SUBJ_059520  Cheek - pinch skin            1      0.619349   \n",
      "4  SEQ_000007  SUBJ_059520  Cheek - pinch skin            1      1.226582   \n",
      "\n",
      "   linear_acc_y  linear_acc_z     rot_w     rot_x     rot_y  ...  tof_3_min  \\\n",
      "0      0.044578     -0.053696  0.134399 -0.355164 -0.447327  ...       55.0   \n",
      "1      0.238219     -0.808055  0.143494 -0.340271 -0.428650  ...       61.0   \n",
      "2      0.526305     -0.412869  0.219055 -0.274231 -0.356934  ...       73.0   \n",
      "3      0.933462     -0.871046  0.297546 -0.264160 -0.238159  ...      113.0   \n",
      "4      0.567647      0.839761  0.333557 -0.218628 -0.063538  ...      143.0   \n",
      "\n",
      "   tof_3_max  tof_4_mean  tof_4_std  tof_4_min  tof_4_max  tof_5_mean  \\\n",
      "0      113.0   99.942857  34.670671       51.0      148.0  134.891892   \n",
      "1      130.0  107.613636  33.115173       60.0      157.0  137.054054   \n",
      "2      158.0  115.056604  29.669601       71.0      174.0  138.615385   \n",
      "3      202.0  144.901961  27.564655      100.0      210.0  143.947368   \n",
      "4      237.0  160.820000  30.573224      116.0      229.0  167.629630   \n",
      "\n",
      "   tof_5_std  tof_5_min  tof_5_max  \n",
      "0  16.160280      112.0      166.0  \n",
      "1  15.753211      116.0      174.0  \n",
      "2  20.668582       92.0      187.0  \n",
      "3  24.712342      101.0      203.0  \n",
      "4  34.750925      101.0      219.0  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "Saving final DataFrame to 'output/final_processed_train_data.parquet'...\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import gc # Import gc for memory management\n",
    "\n",
    "# --- Configuration ---\n",
    "# RAW_DIR = Path(\"input/cmi-detect-behavior-with-sensor-data\")\n",
    "RAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\n",
    "EXPORT_DIR = Path(\"./\")\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True) # Ensure export directory exists\n",
    "\n",
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "    acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "    for i in range(len(acc_values)):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :]\n",
    "            continue\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/100): # Corrected sampling rate to 100Hz\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    angular_vel = np.zeros((len(quat_values), 3))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q_t, q_t_plus_dt = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isnan(q_t_plus_dt)): continue\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError: pass\n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    angular_dist = np.zeros(len(quat_values))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q1, q2 = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isnan(q2)): continue\n",
    "        try:\n",
    "            r1, r2 = R.from_quat(q1), R.from_quat(q2)\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            angular_dist[i] = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "        except ValueError: pass\n",
    "    return angular_dist\n",
    "\n",
    "\n",
    "df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "df = pd.merge(df, train_dem_df, on='subject', how='left')\n",
    "le = LabelEncoder()\n",
    "df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "\n",
    "print(\"  Removing gravity and calculating linear acceleration features...\")\n",
    "linear_accel_list = [pd.DataFrame(remove_gravity_from_acc(group[['acc_x', 'acc_y', 'acc_z']], group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "df = pd.concat([df, pd.concat(linear_accel_list)], axis=1)\n",
    "df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n",
    "\n",
    "print(\"  Calculating angular velocity and distance from quaternions...\")\n",
    "angular_vel_list = [pd.DataFrame(calculate_angular_velocity_from_quat(group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "df = pd.concat([df, pd.concat(angular_vel_list)], axis=1)\n",
    "angular_dist_list = [pd.DataFrame(calculate_angular_distance(group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['angular_distance'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "df = pd.concat([df, pd.concat(angular_dist_list)], axis=1)\n",
    "\n",
    "# --- Define Feature Columns ---\n",
    "imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z'] + [c for c in df.columns if c.startswith('rot_')]\n",
    "imu_engineered = ['linear_acc_mag', 'linear_acc_mag_jerk', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance']\n",
    "imu_cols = list(dict.fromkeys(imu_cols_base + imu_engineered))\n",
    "thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n",
    "tof_aggregated_cols_template = []\n",
    "for i in range(1, 6): tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n",
    "metadata_cols = ['sequence_id', 'subject', 'gesture', 'gesture_int']\n",
    "\n",
    "print(f\"  Total {len(final_feature_cols)} features will be engineered.\")\n",
    "np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "\n",
    "# --- MODIFICATION START: Build a list of processed DataFrames ---\n",
    "print(\"  Building list of processed sequences...\")\n",
    "seq_gp = df.groupby('sequence_id') \n",
    "processed_sequences_dfs = [] # Initialize a list to hold processed DataFrames\n",
    "\n",
    "for seq_id, seq_df in seq_gp:\n",
    "    seq_df_copy = seq_df.copy()\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "        tof_data = seq_df_copy[pixel_cols].replace(-1, np.nan)\n",
    "        seq_df_copy[f'tof_{i}_mean'] = tof_data.mean(axis=1)\n",
    "        seq_df_copy[f'tof_{i}_std'] = tof_data.std(axis=1)\n",
    "        seq_df_copy[f'tof_{i}_min'] = tof_data.min(axis=1)\n",
    "        seq_df_copy[f'tof_{i}_max'] = tof_data.max(axis=1)\n",
    "        \n",
    "    seq_df_copy[final_feature_cols] = seq_df_copy[final_feature_cols].ffill().bfill().fillna(0)\n",
    "    cols_to_keep = metadata_cols + final_feature_cols\n",
    "    processed_seq = seq_df_copy[cols_to_keep]\n",
    "    \n",
    "    # 4. Append the fully processed DataFrame for this sequence to our list\n",
    "    processed_sequences_dfs.append(processed_seq)\n",
    "\n",
    "# --- New Final Step: Concatenate all processed sequences into a single DataFrame ---\n",
    "print(\"  Concatenating all processed sequences into a single DataFrame...\")\n",
    "final_df = pd.concat(processed_sequences_dfs, ignore_index=True)\n",
    "gc.collect()\n",
    "\n",
    "# --- Verification and Saving ---\n",
    "print(\"\\nProcessing complete. Final DataFrame created.\")\n",
    "print(\"Final DataFrame Info:\")\n",
    "final_df.info()\n",
    "\n",
    "print(\"\\nFinal DataFrame Head:\")\n",
    "print(final_df.head())\n",
    "\n",
    "# Save the final DataFrame to a memory-efficient Parquet file\n",
    "output_path = EXPORT_DIR / \"final_processed_train_data.parquet\"\n",
    "print(f\"\\nSaving final DataFrame to '{output_path}'...\")\n",
    "final_df.to_parquet(output_path)\n",
    "print(\"Save complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
